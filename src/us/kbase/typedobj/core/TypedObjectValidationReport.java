package us.kbase.typedobj.core;

import java.util.ArrayList;
import java.util.Iterator;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;

import us.kbase.typedobj.core.validatorconfig.IdRefValidationBuilder;
import us.kbase.typedobj.exceptions.RelabelIdReferenceException;
import us.kbase.typedobj.idref.IdReference;
import us.kbase.typedobj.idref.IdReferenceManager;
import us.kbase.typedobj.idref.WsIdReference;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.node.ArrayNode;
import com.fasterxml.jackson.databind.node.JsonNodeFactory;
import com.fasterxml.jackson.databind.node.ObjectNode;
import com.github.fge.jsonschema.report.LogLevel;
import com.github.fge.jsonschema.report.ProcessingMessage;
import com.github.fge.jsonschema.report.ProcessingReport;


/**
 * The report generated when a typed object instance is validated.  If the type definition indicates
 * that fields are ID references, those ID references can be extracted from this report.  If a
 * searchable subset flag is set in the type definition, you can extract that too.
 *
 * @author msneddon
 */
public class TypedObjectValidationReport {

	/**
	 * the report object generated by the json-schema-validator library, which is the core object we are wrapping
	 */
	protected ProcessingReport processingReport;
	
	/**
	 * This is the ID of the type definition used in validation - it is an AbsoluteTypeDefId so you always have full version info
	 */
	private final AbsoluteTypeDefId validationTypeDefId;
	
	/**
	 * Used to keep track of the IDs that were parsed from the 
	 */
	private IdReferenceManager idRefManager;

	/**
	 * we keep a reference to the original instance that was validated so we can later easily rename labels or extract
	 * the ws searchable subset
	 */
	private JsonNode originalInstance;
	
	
	/**
	 * Initialize with the given processingReport (created when a JsonSchema is used to validate) and the
	 * typeDefId of the typed object definition used when validating.
	 * @param processingReport
	 * @param validationTypeDefId
	 */
	public TypedObjectValidationReport(ProcessingReport processingReport, AbsoluteTypeDefId validationTypeDefId, JsonNode originalInstance) {
		this.processingReport=processingReport;
		this.validationTypeDefId=validationTypeDefId;
		this.idRefManager= new IdReferenceManager(processingReport);
		this.originalInstance=originalInstance;
	}
	
	/**
	 * Get the absolute ID of the typedef that was used to validate the instance
	 * @return
	 */
	public AbsoluteTypeDefId getValidationTypeDefId() {
		return validationTypeDefId;
	}
	
	/**
	 * @return boolean true if the instance is valid, false otherwise
	 */
	public boolean isInstanceValid() {
		return processingReport.isSuccess();
	}
	
	/**
	 * Iterate over all items in the report and count the errors.
	 * @return n_errors
	 */
	public int getErrorCount() {
		if(isInstanceValid()) { return 0; }
		Iterator<ProcessingMessage> mssgs = processingReport.iterator();
		int n_errors=0;
		while(mssgs.hasNext()) {
			ProcessingMessage pm = mssgs.next();
			if(pm.getLogLevel().equals(LogLevel.ERROR)) {
				n_errors++;
			}
		}
		return n_errors;
	}
	
	/**
	 * Iterate over all items in the report and return the error messages.
	 * @return n_errors
	 */
	public List <String> getErrorMessagesAsList() {
		ArrayList <String> errMssgs = new ArrayList<String>();
		if(isInstanceValid()) { return errMssgs; }
		
		Iterator<ProcessingMessage> mssgs = processingReport.iterator();
		while(mssgs.hasNext()) {
			ProcessingMessage pm = mssgs.next();
			if(pm.getLogLevel().equals(LogLevel.ERROR)) {
				errMssgs.add(pm.getMessage());
			}
		}
		return errMssgs;
	}
	
	public String [] getErrorMessages() {
		List <String> errMssgs = getErrorMessagesAsList();
		return errMssgs.toArray(new String [errMssgs.size()]);
	}
	
	/**
	 * This method returns the raw report generated by the JsonSchema, useful in some cases if
	 * you need to dig down into the guts of keywords or to investigate why something failed.
	 */
	public ProcessingReport getRawProcessingReport() {
		return processingReport;
	}
	
	/**
	 * use getWsIdReferences() or getAllIdReferences() instead 
	 * @deprecated
	**/
	public List <String> getListOfIdReferences() {
		return idRefManager.getAllIds();
		
	}
	
	public List<WsIdReference> getWsIdReferences() {
		return idRefManager.getAllWsIdReferences();
	}
	
	public List<IdReference> getAllIdReferences() {
		return idRefManager.getAllIdReferences();
	}
	
	public List<String> getAllIds() {
		return idRefManager.getAllIds();
	}
	
	public List<IdReference> getAllIdReferencesOfType(String type) {
		return idRefManager.getAllIdReferencesOfType(type);
	}
	
	
	
	/**
	 * Use relabelWsIdReferences for relabeling ws id references from now on. You no
	 * longer need to call this method (although it still works)
	 * @deprecated
	 */
	public void setAbsoluteIdReferences(Map<String,String> absoluteIdRefMapping) {
		idRefManager.setWsReplacementNames(absoluteIdRefMapping);
	}
	
	/**
	 * Relabel the WS IDs in the original Json document based on the specified set of
	 * ID Mappings, where keys are the original ids and values are the replacement ids.
	 * 
	 * Caution: this relabeling happens in-place, so if you have modified the structure
	 * of the JSON node between validation and invocation of this method, you will likely
	 * get many runtime errors.  You should make a deep copy first if you indent to do this.
	 * 
	 * Memory of the original ids is not changed by this operation.  Thus, if you need
	 * to rename the ids a second time, you must still refer to the id as its original name,
	 * not necessarily be the name in the current version of the object.
	 */
	public JsonNode relabelWsIdReferences(Map<String,String> absoluteIdRefMapping) throws RelabelIdReferenceException {
		idRefManager.setWsReplacementNames(absoluteIdRefMapping);
		idRefManager.relabelWsIds(originalInstance);
		return originalInstance;
	}
	
	public JsonNode getJsonInstance() {
		return originalInstance;
	}
	
	
	
	
	
	
	public JsonNode extractSearchableWsSubset() {
		if(!isInstanceValid()) {
			ObjectMapper mapper = new ObjectMapper();
			return mapper.createObjectNode();
		}
		// temporary hack until subset extraction is updated...
		///processingReport
		
		// Create the new node to store our subset
		ObjectMapper mapper = new ObjectMapper();
		ObjectNode subset = mapper.createObjectNode();
		
		// Identify what we need to extract
		JsonNode keys_of = null;
		JsonNode fields = null;
		
		Iterator<ProcessingMessage> mssgs = processingReport.iterator();
		while(mssgs.hasNext()) {
			ProcessingMessage m = mssgs.next();
			if( m.getMessage().compareTo("searchable-ws-subset") == 0 ) {
				JsonNode searchData = m.asJson().get("search-data");
				keys_of = searchData.get("keys");
				fields = searchData.get("fields");
				//there can only one per report, so we can break as soon as we got it!
				break;
			}
		}
		
		System.out.println("extracting subset");
		subset = extractFields(subset, 
				(JsonNode)originalInstance, 
				(ObjectNode)fields);
		
		
		return subset;
	}
	
	
	
	
	private ObjectNode extractFields(ObjectNode subset, JsonNode element, ObjectNode selection) {
		
		System.out.println("here");
		System.out.println(" - subset: "+subset);
		System.out.println(" - element: "+element);
		System.out.println(" - selection: " + selection);
		Iterator <Map.Entry<String,JsonNode>> selectedFields = selection.fields();
		
		//if the selection is empty, we return nothing
		if(!selectedFields.hasNext()) return null;
		
		//otherwise we need to get everything in the selection
		while(selectedFields.hasNext()) {
			Map.Entry<String,JsonNode> selectedField = selectedFields.next();
			System.out.println("looking at: "+selectedField.getKey());
			// first we split the name to determine if it is a mapping or not...
			boolean isMapping = false;
			String selectedFieldName = selectedField.getKey();
			String [] splitFieldName = selectedFieldName.split("\\.");
			if(splitFieldName.length==2) {
				if(splitFieldName[0].equals("mapping")) {
					isMapping=true;
					selectedFieldName = splitFieldName[1];
				}
			}
			
			JsonNode fieldData = element.get(selectedFieldName);
			if(fieldData!=null) {
				if(fieldData.isObject()) {
					// TODO make sure node in subset does not already exist..
					// TODO if the object is a kbase type 'map' we must detect it and recurse down each field instead of looking
					// at field names
					if(isMapping) {
						// if there is nothing in the mapping we want, then we take the entire thing
						if(selectedField.getValue().size()==0) {
							subset.set(selectedFieldName, element.get(selectedFieldName));
						} else {
							// we must go through each value in the mapping, and add it
							ObjectMapper mapper = new ObjectMapper();
							ObjectNode newMappingSubset = mapper.createObjectNode();
							
							Iterator <Map.Entry<String,JsonNode>> mappingElements = fieldData.fields();
							while(mappingElements.hasNext()) {
								Map.Entry<String,JsonNode> mappingElement = mappingElements.next();
								ObjectNode emptyMappingSubset = mapper.createObjectNode();
								JsonNode elementSubData = extractFields(emptyMappingSubset, mappingElement.getValue(), (ObjectNode)selectedField.getValue());
								newMappingSubset.set(mappingElement.getKey(),elementSubData);
							}
							subset.set(selectedFieldName, newMappingSubset);
							
						}
					} else {
						ObjectMapper mapper = new ObjectMapper();
						ObjectNode newsubset = mapper.createObjectNode();
						JsonNode moreSubData = extractFields(newsubset, fieldData, (ObjectNode)selectedField.getValue());
						if(moreSubData!=null) {
							subset.set(selectedFieldName,moreSubData);
						} else {
							subset.set(selectedFieldName, element.get(selectedFieldName));
						}
					}
				} else if(fieldData.isValueNode()) {
					subset.set(selectedField.getKey(), element.get(selectedField.getKey()));
					System.out.println("adding, new subset:" +subset);
				} else if(fieldData.isArray()) {
					// TODO make sure node in subset does not already exist...
					// first, check if there are any sub fields-- if there aren't, then we can add the entire list
					if(selectedField.getValue().size()==0) {
						subset.set(selectedFieldName, element.get(selectedFieldName));
					} else {
						// otherwise, we have to create a new arraynode, populate it with just what we need, then return
						ArrayNode newSubArray = JsonNodeFactory.instance.arrayNode();
						ObjectMapper mapper = new ObjectMapper();
						for(int k=0; k<fieldData.size(); k++) {
							ObjectNode emptySubset = mapper.createObjectNode();
							JsonNode newSubArrayElement = extractFields(emptySubset, fieldData.get(k), (ObjectNode)selectedField.getValue());
							// since the size of the selected_field is not zero, we should always be pulling some sub data, but if we do not
							// for whatever failure (optional fields should still get us an empty object, so it must be some other failure), we add an empty object
							if(newSubArrayElement!=null) {
								newSubArray.add(newSubArrayElement);
							} else {
								ObjectNode nothing = mapper.createObjectNode();
								newSubArray.add(nothing);
							}
						}
						subset.set(selectedFieldName, newSubArray);
					}
				}
			}
			
		}
		return subset;
	}
	
	
	
	
	
	
	
	@Override
	public String toString() {
		StringBuilder mssg = new StringBuilder();
		mssg.append("TYPED OBJECT VALIDATION REPORT\n");
		mssg.append(" -validated instance against: '"+validationTypeDefId.getTypeString()+"'\n");
		mssg.append(" -status: ");
		if(this.isInstanceValid()) {
			mssg.append("pass\n");
			mssg.append(" -id refs extracted: "+idRefManager.getAllIds().size());
			mssg.append(" -ws id refs extracted: "+idRefManager.getAllWsIdReferences().size());
		}
		else {
			List<String> errs = getErrorMessagesAsList();
			mssg.append("fail ("+errs.size()+" error(s))\n");
			for(int k=0; k<errs.size(); k++) {
				mssg.append(" -["+(k+1)+"]:"+errs.get(k));
			}
		}
		return mssg.toString();
	}
	
	
}
