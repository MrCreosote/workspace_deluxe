package us.kbase.workspace.database.mongo;

import static org.hamcrest.CoreMatchers.is;
import static org.junit.Assert.assertThat;

import java.io.File;
import java.io.IOException;
import java.net.MalformedURLException;
import java.net.URL;
import java.net.UnknownHostException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Date;
import java.util.HashMap;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;

import org.apache.commons.lang3.StringUtils;
import org.bson.types.ObjectId;
import org.jongo.FindAndModify;
import org.jongo.Jongo;
import org.jongo.MongoCollection;
import org.jongo.marshall.MarshallingException;
import org.junit.BeforeClass;
import org.junit.Test;
import org.junit.experimental.runners.Enclosed;
import org.junit.runner.RunWith;

import us.kbase.common.mongo.GetMongoDB;
import us.kbase.common.mongo.exceptions.InvalidHostException;
import us.kbase.common.mongo.exceptions.MongoAuthException;
import us.kbase.typedobj.core.AbsoluteTypeDefId;
import us.kbase.typedobj.core.MD5;
import us.kbase.typedobj.core.TypeDefId;
import us.kbase.typedobj.core.TypeDefName;
import us.kbase.typedobj.core.TypedObjectValidator;
import us.kbase.typedobj.db.MongoTypeStorage;
import us.kbase.typedobj.db.TypeDefinitionDB;
import us.kbase.typedobj.db.UserInfoProviderForTests;
import us.kbase.typedobj.exceptions.TypeStorageException;
import us.kbase.typedobj.tests.DummyTypedObjectValidationReport;
import us.kbase.workspace.database.AllUsers;
import us.kbase.workspace.database.ObjectIDNoWSNoVer;
import us.kbase.workspace.database.ObjectIDResolvedWS;
import us.kbase.workspace.database.ObjectInformation;
import us.kbase.workspace.database.Permission;
import us.kbase.workspace.database.PermissionSet;
import us.kbase.workspace.database.Provenance;
import us.kbase.workspace.database.Reference;
import us.kbase.workspace.database.ResolvedWorkspaceID;
import us.kbase.workspace.database.TypeAndReference;
import us.kbase.workspace.database.User;
import us.kbase.workspace.database.WorkspaceDatabase;
import us.kbase.workspace.database.WorkspaceIdentifier;
import us.kbase.workspace.database.WorkspaceInformation;
import us.kbase.workspace.database.WorkspaceObjectData;
import us.kbase.workspace.database.WorkspaceUser;
import us.kbase.workspace.database.exceptions.CorruptWorkspaceDBException;
import us.kbase.workspace.database.exceptions.DBAuthorizationException;
import us.kbase.workspace.database.exceptions.NoSuchObjectException;
import us.kbase.workspace.database.exceptions.NoSuchWorkspaceException;
import us.kbase.workspace.database.exceptions.PreExistingWorkspaceException;
import us.kbase.workspace.database.exceptions.UninitializedWorkspaceDBException;
import us.kbase.workspace.database.exceptions.WorkspaceCommunicationException;
import us.kbase.workspace.database.exceptions.WorkspaceDBException;
import us.kbase.workspace.database.exceptions.WorkspaceDBInitializationException;
import us.kbase.workspace.database.mongo.exceptions.BlobStoreAuthorizationException;
import us.kbase.workspace.database.mongo.exceptions.BlobStoreCommunicationException;
import us.kbase.workspace.database.mongo.exceptions.BlobStoreException;
import us.kbase.workspace.database.mongo.exceptions.NoSuchBlobException;
import us.kbase.workspace.kbase.Util;
import us.kbase.workspace.test.WorkspaceTestCommon;
import us.kbase.workspace.workspaces.ResolvedSaveObject;
import us.kbase.workspace.workspaces.WorkspaceSaveObject;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.mongodb.BasicDBObject;
import com.mongodb.DB;
import com.mongodb.DBCursor;
import com.mongodb.DBObject;
import com.mongodb.MongoException;

@RunWith(Enclosed.class)
public class MongoWorkspaceDB implements WorkspaceDatabase {

	//TODO query user metadata
	//TODO save set of objects with same provenance if they were generated by same fn
	//TODO lose UUID index/field etc?
	
	private static final String COL_SETTINGS = "settings";
	private static final String COL_WS_CNT = "workspaceCounter";
	private static final String COL_WORKSPACES = "workspaces";
	private static final String COL_WS_ACLS = "workspaceACLs";
	private static final String COL_WORKSPACE_OBJS = "workspaceObjects";
	private static final String COL_WORKSPACE_VERS = "workspaceObjVersions";
	private static final String COL_PROVENANCE = "provenance";
	private static final String COL_SHOCK_PREFIX = "shock_";
	private static final User allUsers = new AllUsers('*');
	
	private static final long MAX_OBJECT_SIZE = 1000000000;
	private static final long MAX_SUBDATA_SIZE = 15000000;
	private static final long MAX_PROV_SIZE = 1000000;
	
	private final DB wsmongo;
	private final Jongo wsjongo;
	private final BlobStore blob;
	private final QueryMethods query;
	private final FindAndModify updateWScounter;
	private final TypedObjectValidator typeValidator;
	
	private final Set<String> typeIndexEnsured = new HashSet<String>();
	
	//TODO constants class

	private static final Map<String, Map<List<String>, List<String>>> INDEXES;
	private static final String IDX_UNIQ = "unique";
	private static final String IDX_SPARSE = "sparse";
	static {
		//hardcoded indexes
		INDEXES = new HashMap<String, Map<List<String>, List<String>>>();
		
		//workspaces indexes
		Map<List<String>, List<String>> ws = new HashMap<List<String>, List<String>>();
		//find workspaces you own
		ws.put(Arrays.asList(Fields.WS_OWNER), Arrays.asList(""));
		//find workspaces by permanent id
		ws.put(Arrays.asList(Fields.WS_ID), Arrays.asList(IDX_UNIQ));
		//find workspaces by mutable name
		ws.put(Arrays.asList(Fields.WS_NAME), Arrays.asList(IDX_UNIQ));
		INDEXES.put(COL_WORKSPACES, ws);
		
		//workspace acl indexes
		Map<List<String>, List<String>> wsACL = new HashMap<List<String>, List<String>>();
		//get a user's permission for a workspace, index covers queries
		wsACL.put(Arrays.asList(Fields.ACL_WSID, Fields.ACL_USER, Fields.ACL_PERM), Arrays.asList(IDX_UNIQ));
		//find workspaces to which a user has some level of permission, index coves queries
		wsACL.put(Arrays.asList(Fields.ACL_USER, Fields.ACL_PERM, Fields.ACL_WSID), Arrays.asList(""));
		INDEXES.put(COL_WS_ACLS, wsACL);
		
		//workspace object indexes
		Map<List<String>, List<String>> wsObj = new HashMap<List<String>, List<String>>();
		//find objects by workspace id & name
		wsObj.put(Arrays.asList(Fields.OBJ_WS_ID, Fields.OBJ_NAME), Arrays.asList(IDX_UNIQ));
		//find object by workspace id & object id
		wsObj.put(Arrays.asList(Fields.OBJ_WS_ID, Fields.OBJ_ID), Arrays.asList(IDX_UNIQ));
		//find recently modified objects
		wsObj.put(Arrays.asList(Fields.OBJ_MODDATE), Arrays.asList(""));
		//find object to garbage collect
		wsObj.put(Arrays.asList(Fields.OBJ_DEL, Fields.OBJ_REFCOUNTS), Arrays.asList(""));
		INDEXES.put(COL_WORKSPACE_OBJS, wsObj);

		//workspace object version indexes
		Map<List<String>, List<String>> wsVer = new HashMap<List<String>, List<String>>();
		//find versions
		wsVer.put(Arrays.asList(Fields.VER_WS_ID, Fields.VER_ID,
				Fields.VER_VER), Arrays.asList(IDX_UNIQ));
		//find versions by data object
		wsVer.put(Arrays.asList(Fields.VER_TYPE, Fields.VER_CHKSUM), Arrays.asList(""));
		//find objects by legacy UUID
		wsVer.put(Arrays.asList(Fields.VER_UUID), Arrays.asList(IDX_SPARSE));
		//determine whether a particular object is referenced by this object
		wsVer.put(Arrays.asList(Fields.VER_REF), Arrays.asList(""));
		//determine whether a particular object is included in this object's provenance
		wsVer.put(Arrays.asList(Fields.VER_PROVREF), Arrays.asList(""));
		//find objects that have the same provenance
		wsVer.put(Arrays.asList(Fields.VER_PROV), Arrays.asList(""));
		INDEXES.put(COL_WORKSPACE_VERS, wsVer);
		
		//no indexes needed for provenance since all lookups are by _id
	}

	public MongoWorkspaceDB(final String host, final String database,
			final String backendSecret, final String kidlpath,
			final String typeDBdir)
			throws UnknownHostException, IOException, InvalidHostException,
			WorkspaceDBException, TypeStorageException {
		wsmongo = GetMongoDB.getDB(host, database);
		wsjongo = new Jongo(wsmongo);
		query = new QueryMethods(wsmongo, (AllUsers) allUsers, COL_WORKSPACES,
				COL_WORKSPACE_OBJS, COL_WORKSPACE_VERS, COL_WS_ACLS);
		final Settings settings = getSettings();
		blob = setupBlobStore(settings, backendSecret);
		updateWScounter = buildCounterQuery(wsjongo);
		//TODO check a few random types and make sure they exist
		this.typeValidator = new TypedObjectValidator(
				new TypeDefinitionDB(
						new MongoTypeStorage(
								GetMongoDB.getDB(host, settings.getTypeDatabase())),
								typeDBdir == null ? null : new File(typeDBdir),
								new UserInfoProviderForTests(null), kidlpath, null));
		ensureIndexes();
		ensureTypeIndexes();
	}

	public MongoWorkspaceDB(final String host, final String database,
			final String backendSecret, final String kidlpath,
			final String typeDBdir, final String user, final String password)
			throws UnknownHostException, IOException,
			WorkspaceDBException, InvalidHostException, MongoAuthException,
			TypeStorageException {
		wsmongo = GetMongoDB.getDB(host, database, user, password);
		wsjongo = new Jongo(wsmongo);
		query = new QueryMethods(wsmongo, (AllUsers) allUsers, COL_WORKSPACES,
				COL_WORKSPACE_OBJS, COL_WORKSPACE_VERS, COL_WS_ACLS);
		final Settings settings = getSettings();
		blob = setupBlobStore(settings, backendSecret);
		updateWScounter = buildCounterQuery(wsjongo);
		this.typeValidator = new TypedObjectValidator(
				new TypeDefinitionDB(
						new MongoTypeStorage(
								GetMongoDB.getDB(host, settings.getTypeDatabase(),
										user, password)),
								typeDBdir == null ? null : new File(typeDBdir),
								new UserInfoProviderForTests(null), kidlpath, null));
		ensureIndexes();
		ensureTypeIndexes();
	}
	
	private void ensureIndexes() {
		for (String col: INDEXES.keySet()) {
			for (List<String> idx: INDEXES.get(col).keySet()) {
				final DBObject index = new BasicDBObject();
				final DBObject opts = new BasicDBObject();
				for (String field: idx) {
					index.put(field, 1);
				}
				for (String option: INDEXES.get(col).get(idx)) {
					if (!option.equals("")) {
						opts.put(option, 1);
					}
				}
				wsmongo.getCollection(col).ensureIndex(index, opts);
			}
		}
	}
	
	private void ensureTypeIndexes() {
		for (final String col: wsmongo.getCollectionNames()) {
			if (col.startsWith(TypeData.TYPE_COL_PREFIX)) {
				ensureTypeIndex(col);
			}
		}
	}
	
	private void ensureTypeIndex(final TypeDefId type) {
		ensureTypeIndex(TypeData.getTypeCollection(type));
	}

	private void ensureTypeIndex(String col) {
		if (typeIndexEnsured.contains(col)) {
			return;
		}
		final DBObject chksum = new BasicDBObject();
		chksum.put(Fields.TYPE_CHKSUM, 1);
		final DBObject unique = new BasicDBObject();
		unique.put(IDX_UNIQ, 1);
		wsmongo.getCollection(col).ensureIndex(chksum, unique);
		typeIndexEnsured.add(col);
	}
	
	private static FindAndModify buildCounterQuery(final Jongo j) {
		return j.getCollection(COL_WS_CNT)
				.findAndModify(String.format("{%s: #}",
						Fields.CNT_ID), Fields.CNT_ID_VAL)
				.upsert().returnNew()
				.with("{$inc: {" + Fields.CNT_NUM + ": #}}", 1L)
				.projection(String.format("{%s: 1, %s: 0}",
						Fields.CNT_NUM, Fields.MONGO_ID));
	}

	private Settings getSettings() throws UninitializedWorkspaceDBException,
			CorruptWorkspaceDBException {
		if (!wsmongo.collectionExists(COL_SETTINGS)) {
			throw new UninitializedWorkspaceDBException(
					"No settings collection exists");
		}
		MongoCollection settings = wsjongo.getCollection(COL_SETTINGS);
		if (settings.count() != 1) {
			throw new CorruptWorkspaceDBException(
					"More than one settings document exists");
		}
		Settings wsSettings = null;
		try {
			wsSettings = settings.findOne().as(Settings.class);
		} catch (MarshallingException me) {
			Throwable ex = me.getCause();
			if (ex == null) {
				throw new CorruptWorkspaceDBException(
						"Unable to unmarshal settings document", me);
			}
			ex = ex.getCause();
			if (ex == null || !(ex instanceof CorruptWorkspaceDBException)) {
				throw new CorruptWorkspaceDBException(
						"Unable to unmarshal settings document", me);
			}
			throw (CorruptWorkspaceDBException) ex;
		}
		return wsSettings;
	}

	private BlobStore setupBlobStore(final Settings settings,
			final String backendSecret) throws CorruptWorkspaceDBException,
			DBAuthorizationException, WorkspaceDBInitializationException {
		if (settings.isGridFSBackend()) {
			return new GridFSBackend(wsmongo);
		}
		if (settings.isShockBackend()) {
			URL shockurl = null;
			try {
				shockurl = new URL(settings.getShockUrl());
			} catch (MalformedURLException mue) {
				throw new CorruptWorkspaceDBException(
						"Settings has bad shock url: "
								+ settings.getShockUrl(), mue);
			}
			BlobStore bs;
			try {
				bs = new ShockBackend(wsmongo, COL_SHOCK_PREFIX,
						shockurl, settings.getShockUser(), backendSecret);
			} catch (BlobStoreAuthorizationException e) {
				throw new DBAuthorizationException(
						"Not authorized to access the blob store database", e);
			} catch (BlobStoreException e) {
				throw new WorkspaceDBInitializationException(
						"The database could not be initialized: " +
						e.getLocalizedMessage(), e);
			}
			// TODO if shock, check a few random nodes to make sure they match
			// the internal representation, die otherwise
			return bs;
		}
		throw new RuntimeException("Something's real broke y'all");
	}
	
	@Override
	public TypedObjectValidator getTypeValidator() {
		return typeValidator;
	}

	@Override
	public String getBackendType() {
		return blob.getStoreType();
	}
	
	private static final String M_CREATE_WS_QRY = String.format("{%s: #}",
			Fields.WS_NAME);

	@Override
	public WorkspaceInformation createWorkspace(final WorkspaceUser user,
			final String wsname, final boolean globalRead,
			final String description) throws PreExistingWorkspaceException,
			WorkspaceCommunicationException, CorruptWorkspaceDBException {
		//avoid incrementing the counter if we don't have to
		try {
			if (wsjongo.getCollection(COL_WORKSPACES).count(
					M_CREATE_WS_QRY, wsname) > 0) {
				throw new PreExistingWorkspaceException(String.format(
						"Workspace %s already exists", wsname));
			}
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		final long count; 
		try {
			count = ((Number) updateWScounter.as(DBObject.class)
					.get(Fields.CNT_NUM)).longValue();
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		final DBObject ws = new BasicDBObject();
		ws.put(Fields.WS_OWNER, user.getUser());
		ws.put(Fields.WS_ID, count);
		Date moddate = new Date();
		ws.put(Fields.WS_MODDATE, moddate);
		ws.put(Fields.WS_NAME, wsname);
		ws.put(Fields.WS_DEL, false);
		ws.put(Fields.WS_NUMOBJ, 0L);
		ws.put(Fields.WS_DESC, description);
		try {
			wsmongo.getCollection(COL_WORKSPACES).insert(ws);
		} catch (MongoException.DuplicateKey mdk) {
			//this is almost impossible to test and will probably almost never happen
			throw new PreExistingWorkspaceException(String.format(
					"Workspace %s already exists", wsname));
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		setPermissionsForWorkspaceUsers(new ResolvedMongoWSID(wsname, count),
				Arrays.asList(user), Permission.OWNER, false);
		if (globalRead) {
			setPermissions(new ResolvedMongoWSID(wsname, count),
					Arrays.asList(allUsers), Permission.READ, false);
		}
		return new MongoWSInfo(count, wsname, user, moddate, 0L,
				Permission.OWNER, globalRead);
	}
	
	private static final Set<String> FLDS_VER_COPYOBJ = newHashSet(
			Fields.VER_WS_ID, Fields.VER_ID, Fields.VER_VER,
			Fields.VER_TYPE, Fields.VER_CHKSUM, Fields.VER_SIZE,
			Fields.VER_PROV, Fields.VER_REF, Fields.VER_PROVREF,
			Fields.VER_COPIED, Fields.VER_UUID, Fields.VER_META); //TODO remove UUID?
	
	@Override
	public ObjectInformation copyObject(final WorkspaceUser user,
			final ObjectIDResolvedWS from, final ObjectIDResolvedWS to)
			throws NoSuchObjectException, WorkspaceCommunicationException {
		return copyOrRevert(user, from, to, false);
	}
	
	@Override
	public ObjectInformation revertObject(final WorkspaceUser user,
			final ObjectIDResolvedWS oi)
			throws NoSuchObjectException, WorkspaceCommunicationException {
		return copyOrRevert(user, oi, null, true);
	}
		
	private ObjectInformation copyOrRevert(final WorkspaceUser user,
			final ObjectIDResolvedWS from, ObjectIDResolvedWS to,
			final boolean revert)
			throws NoSuchObjectException, WorkspaceCommunicationException {
		//TODO update WS moddate?
		final ResolvedMongoObjectID rfrom = resolveObjectIDs(
				new HashSet<ObjectIDResolvedWS>(Arrays.asList(from))).get(from);
		final ResolvedMongoObjectID rto;
		if (revert) {
			to = from;
			rto = rfrom;
		} else {
			rto = resolveObjectIDs(
					new HashSet<ObjectIDResolvedWS>(Arrays.asList(to)),
					true, false).get(to); //don't except if there's no object
		}
		if (rto == null && to.getId() != null) {
			throw new NoSuchObjectException(String.format(
					"Copy destination is specified as object id %s in workspace %s which does not exist.",
					to.getId(), to.getWorkspaceIdentifier().getID()));
		}
		final List<Map<String, Object>> versions;
		if (rto == null && from.getVersion() == null) {
			final ResolvedMongoObjectIDNoVer o =
					new ResolvedMongoObjectIDNoVer(rfrom);
			versions = query.queryAllVersions(
					new HashSet<ResolvedMongoObjectIDNoVer>(Arrays.asList(o)),
					FLDS_VER_COPYOBJ).get(o);
		} else {
			versions = Arrays.asList(query.queryVersions(
					new HashSet<ResolvedMongoObjectID>(Arrays.asList(rfrom)),
					FLDS_VER_COPYOBJ).get(rfrom));
		}
		for (final Map<String, Object> v: versions) {
			int ver = (Integer) v.get(Fields.VER_VER);
			v.remove(Fields.MONGO_ID);
			v.put(Fields.VER_SAVEDBY, user.getUser());
			if (revert) {
				v.put(Fields.VER_RVRT, ver);
				v.put(Fields.VER_COPIED, null);
			} else {
				v.put(Fields.VER_RVRT, null);
				//TODO test copy saved in internals
				v.put(Fields.VER_COPIED, new MongoReference(
						rfrom.getWorkspaceIdentifier().getID(), rfrom.getId(),
						ver).toString());
			}
		}
		//TODO test copy ref counts works in internals
		updateReferenceCountsForVersions(versions);
		final ResolvedMongoWSID toWS = query.convertResolvedWSID(
				to.getWorkspaceIdentifier());
		final long objid;
		if (rto == null) { //need to make a new object
			final long id = incrementWorkspaceCounter(toWS, 1);
			objid = saveWorkspaceObject(toWS, id, to.getName()).id;
		} else {
			objid = rto.getId();
		}
		saveObjectVersions(user, toWS, objid, versions,
				false);
		final Map<String, Object> info = versions.get(versions.size() - 1);
		info.remove(Fields.VER_META);
		return generateUserMetaInfo(toWS, objid, rto == null ? to.getName() :
				rto.getName(), info);
	}
	
	final private static String M_RENAME_QRY = String.format(
			"{%s: #, %s: #}", Fields.OBJ_WS_ID, Fields.OBJ_ID);
	final private static String M_RENAME_WTH = String.format(
			"{$set: {%s: #}}", Fields.OBJ_NAME);
	
	@Override
	public ObjectInformation renameObject(final ObjectIDResolvedWS oi,
			final String newname)
			throws NoSuchObjectException, WorkspaceCommunicationException {
		final Set<ObjectIDResolvedWS> input = new HashSet<ObjectIDResolvedWS>(
				Arrays.asList(oi));
		final ResolvedMongoObjectID roi = resolveObjectIDs(input).get(oi);
		if (newname.equals(roi.getName())) {
			throw new IllegalArgumentException("Object is already named " +
					newname);
		}
		try {
			wsjongo.getCollection(COL_WORKSPACE_OBJS)
					.update(M_RENAME_QRY, roi.getWorkspaceIdentifier().getID(),
							roi.getId())
					.with(M_RENAME_WTH, newname);
		} catch (MongoException.DuplicateKey medk) {
			throw new IllegalArgumentException(
					"There is already an object in the workspace named " +
							newname);
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		return getObjectInformation(input, false).get(oi);
	}
	
	//projection lists
	private static final Set<String> FLDS_WS_DESC = newHashSet(Fields.WS_DESC);
	private static final Set<String> FLDS_WS_OWNER = newHashSet(Fields.WS_OWNER);
	
	//http://stackoverflow.com/questions/2041778/initialize-java-hashset-values-by-construction
	@SafeVarargs
	private static <T> Set<T> newHashSet(T... objs) {
		Set<T> set = new HashSet<T>();
		for (T o : objs) {
			set.add(o);
		}
		return set;
	}
	
	@Override
	public String getWorkspaceDescription(final ResolvedWorkspaceID rwsi) throws
			CorruptWorkspaceDBException, WorkspaceCommunicationException {
		return (String) query.queryWorkspace(query.convertResolvedWSID(rwsi),
				FLDS_WS_DESC).get(Fields.WS_DESC);
	}
	
	private final static String M_WS_ID_QRY = String.format("{%s: #}",
			Fields.WS_ID);
	private final static String M_WS_ID_WTH = String.format("{$set: {%s: #}}",
			Fields.WS_DESC);
	
	@Override
	public void setWorkspaceDescription(final ResolvedWorkspaceID rwsi,
			final String description) throws WorkspaceCommunicationException {
		//TODO generalized method for setting fields?
		//TODO set workspace change date
		try {
			wsjongo.getCollection(COL_WORKSPACES)
				.update(M_WS_ID_QRY, rwsi.getID())
				.with(M_WS_ID_WTH, description);
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
	}
	
	@Override
	public ResolvedWorkspaceID resolveWorkspace(final WorkspaceIdentifier wsi)
			throws NoSuchWorkspaceException, WorkspaceCommunicationException {
		return resolveWorkspace(wsi, false);
	}
	
	@Override
	public ResolvedWorkspaceID resolveWorkspace(final WorkspaceIdentifier wsi,
			final boolean allowDeleted)
			throws NoSuchWorkspaceException, WorkspaceCommunicationException {
		Set<WorkspaceIdentifier> wsiset = new HashSet<WorkspaceIdentifier>();
		wsiset.add(wsi);
		return resolveWorkspaces(wsiset, allowDeleted).get(wsi);
				
	}
	
	@Override
	public Map<WorkspaceIdentifier, ResolvedWorkspaceID> resolveWorkspaces(
			final Set<WorkspaceIdentifier> wsis) throws NoSuchWorkspaceException,
			WorkspaceCommunicationException {
		return resolveWorkspaces(wsis, false);
	}
	
	private static final Set<String> FLDS_WS_ID_NAME_DEL =
			newHashSet(Fields.WS_ID, Fields.WS_NAME, Fields.WS_DEL);
	
	@Override
	public Map<WorkspaceIdentifier, ResolvedWorkspaceID> resolveWorkspaces(
			final Set<WorkspaceIdentifier> wsis, final boolean allowDeleted)
			throws NoSuchWorkspaceException, WorkspaceCommunicationException {
		final Map<WorkspaceIdentifier, ResolvedWorkspaceID> ret =
				new HashMap<WorkspaceIdentifier, ResolvedWorkspaceID>();
		if (wsis.isEmpty()) {
			return ret;
		}
		final Map<WorkspaceIdentifier, Map<String, Object>> res =
				query.queryWorkspacesByIdentifier(wsis, FLDS_WS_ID_NAME_DEL);
		for (final WorkspaceIdentifier wsi: wsis) {
			if (!res.containsKey(wsi)) {
				throw new NoSuchWorkspaceException(String.format(
						"No workspace with %s exists", getWSErrorId(wsi)),
						wsi);
			}
			if (!allowDeleted && (Boolean) res.get(wsi).get(Fields.WS_DEL)) {
				throw new NoSuchWorkspaceException("Workspace " +
						wsi.getIdentifierString() + " is deleted", wsi);
			}
			ResolvedMongoWSID r = new ResolvedMongoWSID(
					(String) res.get(wsi).get(Fields.WS_NAME),
					(Long) res.get(wsi).get(Fields.WS_ID));
			ret.put(wsi, r);
		}
		return ret;
	}
	
	@Override
	public PermissionSet getWorkspacesWithPermission(
			final WorkspaceUser user, final Permission perm)
			throws WorkspaceCommunicationException,
			CorruptWorkspaceDBException {
		//TODO exclude global read here
		if (perm == null || Permission.NONE.equals(perm)) {
			throw new IllegalArgumentException(
					"Permission cannot be null or NONE");
		}
		final Set<User> u = new HashSet<User>();
		if (user != null) {
			u.add(user);
		}
		u.add(allUsers);
		final Map<ResolvedMongoWSID, Map<User, Permission>> perms =
				query.queryPermissions(u, perm);
		final MongoPermissionSet pset = new MongoPermissionSet(user, allUsers);
		for (final ResolvedMongoWSID rwsi: perms.keySet()) {
			pset.setPermission(rwsi, perms.get(rwsi).get(user), perms.get(rwsi)
					.get(allUsers));
		}
		return pset;
	}
	
	private static String getWSErrorId(final WorkspaceIdentifier wsi) {
		if (wsi.getId() == null) {
			return "name " + wsi.getName();
		}
		return "id " + wsi.getId();
	}
	
	@Override
	public void setPermissions(final ResolvedWorkspaceID rwsi,
			final List<WorkspaceUser> users, final Permission perm) throws
			WorkspaceCommunicationException, CorruptWorkspaceDBException {
		setPermissionsForWorkspaceUsers(query.convertResolvedWSID(rwsi),
				users, perm, true);
	}
	
	@Override
	public void setGlobalPermission(final ResolvedWorkspaceID rwsi,
			final Permission perm)
			throws WorkspaceCommunicationException,
			CorruptWorkspaceDBException {
		//TODO should update workspace change date?
		setPermissions(query.convertResolvedWSID(rwsi),
				Arrays.asList(allUsers), perm, false);
	}
	
	//wsid must exist as a workspace
	private void setPermissionsForWorkspaceUsers(final ResolvedMongoWSID wsid,
			final List<WorkspaceUser> users, final Permission perm, 
			final boolean checkowner) throws WorkspaceCommunicationException,
			CorruptWorkspaceDBException {
		List<User> u = new ArrayList<User>();
		for (User user: users) {
			u.add(user);
		}
		setPermissions(wsid, u, perm, checkowner);
		
	}
	
	private static final String M_PERMS_QRY = String.format("{%s: #, %s: #}",
			Fields.ACL_WSID, Fields.ACL_USER);
	private static final String M_PERMS_UPD = String.format("{$set: {%s: #}}",
			Fields.ACL_PERM);
	
	private void setPermissions(final ResolvedMongoWSID wsid, final List<User> users,
			final Permission perm, final boolean checkowner) throws
			WorkspaceCommunicationException, CorruptWorkspaceDBException {
		final WorkspaceUser owner;
		if (checkowner) {
			final Map<String, Object> ws =
					query.queryWorkspace(wsid, FLDS_WS_OWNER);
			if (ws == null) {
				throw new CorruptWorkspaceDBException(String.format(
						"Workspace %s was unexpectedly deleted from the database",
						wsid.getID()));
			}
			owner = new WorkspaceUser((String) ws.get(Fields.WS_OWNER));
		} else {
			owner = null;
		}
		for (User user: users) {
			if (owner != null && owner.getUser().equals(user.getUser())) {
				continue; // can't change owner permissions
			}
			try {
				if (perm.equals(Permission.NONE)) {
					wsjongo.getCollection(COL_WS_ACLS).remove(
							M_PERMS_QRY, wsid.getID(), user.getUser());
				} else {
					wsjongo.getCollection(COL_WS_ACLS).update(
							M_PERMS_QRY, wsid.getID(), user.getUser())
							.upsert().with(M_PERMS_UPD, perm.getPermission());
				}
			} catch (MongoException me) {
				throw new WorkspaceCommunicationException(
						"There was a problem communicating with the database", me);
			}
		}
	}
	
	@Override
	public Permission getPermission(final WorkspaceUser user,
			final ResolvedWorkspaceID wsi) throws 
			WorkspaceCommunicationException, CorruptWorkspaceDBException {
		final Set<ResolvedWorkspaceID> wsis =
				new HashSet<ResolvedWorkspaceID>();
		wsis.add(wsi);
		return getPermissions(user, wsis).getPermission(wsi);
	}
	
	public PermissionSet getPermissions(final WorkspaceUser user,
			final ResolvedWorkspaceID rwsi) throws 
			WorkspaceCommunicationException, CorruptWorkspaceDBException {
		final Set<ResolvedWorkspaceID> wsis =
				new HashSet<ResolvedWorkspaceID>();
		wsis.add(rwsi);
		return getPermissions(user, wsis);
	}
	
	@Override
	public PermissionSet getPermissions(
			final WorkspaceUser user, final Set<ResolvedWorkspaceID> rwsis)
			throws WorkspaceCommunicationException, 
			CorruptWorkspaceDBException {
		final Set<User> users = new HashSet<User>();
		if (user != null) {
			users.add(user);
		}
		users.add(allUsers);
		final Set<ResolvedMongoWSID> rm = new HashSet<ResolvedMongoWSID>();
		for (final ResolvedWorkspaceID r: rwsis) {
			rm.add(query.convertResolvedWSID(r));
		}
		final Map<ResolvedMongoWSID, Map<User, Permission>> perms = 
				query.queryPermissions(rm, users);
		final MongoPermissionSet pset = new MongoPermissionSet(user, allUsers);
		for (ResolvedMongoWSID r: perms.keySet()) {
			pset.setPermission(r, perms.get(r).get(user),
					perms.get(r).get(allUsers));
		}
		return pset;
	}
	
	@Override
	public Map<User, Permission> getAllPermissions(
			final ResolvedWorkspaceID rwsi) throws
			WorkspaceCommunicationException, CorruptWorkspaceDBException {
		return query.queryPermissions(query.convertResolvedWSID(rwsi));
	}

	private static final Set<String> FLDS_WS_NO_DESC = 
			newHashSet(Fields.WS_ID, Fields.WS_NAME, Fields.WS_OWNER,
					Fields.WS_MODDATE, Fields.WS_NUMOBJ, Fields.WS_DEL);
	
	@Override
	public List<WorkspaceInformation> getWorkspaceInformation(
			final PermissionSet pset, final boolean excludeGlobal,
			final boolean showDeleted)
			throws WorkspaceCommunicationException,
			CorruptWorkspaceDBException {
		if (!(pset instanceof MongoPermissionSet)) {
			throw new IllegalArgumentException(
					"Illegal implementation of PermissionSet: " +
					pset.getClass().getName());
		}
		final Set<ResolvedMongoWSID> rwsis = new HashSet<ResolvedMongoWSID>();
		for (final ResolvedWorkspaceID rwsi: pset.getWorkspaces()) {
			if (pset.hasUserPermission(rwsi, Permission.READ) ||
				(!excludeGlobal && pset.isWorldReadable(rwsi))) {
				rwsis.add(query.convertResolvedWSID(rwsi));
			}
		}
		final Map<ResolvedMongoWSID, Map<String, Object>> ws =
				query.queryWorkspacesByResolvedID(rwsis,
						FLDS_WS_NO_DESC);
		final List<WorkspaceInformation> ret =
				new LinkedList<WorkspaceInformation>();
		for (final ResolvedWorkspaceID rwsi: ws.keySet()) {
			if (!(Boolean) ws.get(rwsi).get(Fields.WS_DEL) ||
					(showDeleted &&
					pset.hasUserPermission(rwsi, Permission.OWNER))) {
				ret.add(generateWSInfo(pset.getUser(), rwsi, pset,
						ws.get(rwsi)));
			}
		}
		return ret;
	}
	
	@Override
	public WorkspaceInformation getWorkspaceInformation(
			final WorkspaceUser user, final ResolvedWorkspaceID rwsi)
			throws WorkspaceCommunicationException,
			CorruptWorkspaceDBException {
		final ResolvedMongoWSID m = query.convertResolvedWSID(rwsi);
		final Map<String, Object> ws = query.queryWorkspace(m,
				FLDS_WS_NO_DESC);
		final PermissionSet perms = getPermissions(user, m);
		return generateWSInfo(user, rwsi, perms, ws);
	}

	private WorkspaceInformation generateWSInfo(final WorkspaceUser user,
			final ResolvedWorkspaceID rwsi, final PermissionSet perms,
			final Map<String, Object> wsdata) {
		return new MongoWSInfo((Long) wsdata.get(Fields.WS_ID),
				(String) wsdata.get(Fields.WS_NAME),
				new WorkspaceUser((String) wsdata.get(Fields.WS_OWNER)),
				(Date) wsdata.get(Fields.WS_MODDATE),
				(Long) wsdata.get(Fields.WS_NUMOBJ),
				perms.getUserPermission(rwsi),
				perms.isWorldReadable(rwsi));
	}
	
	private Map<ObjectIDNoWSNoVer, ResolvedMongoObjectID> resolveObjectIDs(
			final ResolvedMongoWSID workspaceID,
			final Set<ObjectIDNoWSNoVer> objects) throws
			WorkspaceCommunicationException {
		
		final Map<ObjectIDNoWSNoVer, ObjectIDResolvedWS> queryobjs = 
				new HashMap<ObjectIDNoWSNoVer, ObjectIDResolvedWS>();
		for (final ObjectIDNoWSNoVer o: objects) {
			queryobjs.put(o, new ObjectIDResolvedWS(workspaceID, o));
		}
		final Map<ObjectIDResolvedWS, ResolvedMongoObjectID> res;
		try {
			res = resolveObjectIDs(
					new HashSet<ObjectIDResolvedWS>(queryobjs.values()),
					false, false);
		} catch (NoSuchObjectException nsoe) {
			throw new RuntimeException(
					"Threw a NoSuchObjectException when explicitly told not to");
		}
		final Map<ObjectIDNoWSNoVer, ResolvedMongoObjectID> ret = 
				new HashMap<ObjectIDNoWSNoVer, ResolvedMongoObjectID>();
		for (final ObjectIDNoWSNoVer o: objects) {
			if (res.containsKey(queryobjs.get(o))) {
				ret.put(o, res.get(queryobjs.get(o)));
			}
		}
		return ret;
	}
	
	// save object in preexisting object container
	private ObjectInformation saveObjectVersion(final WorkspaceUser user,
			final ResolvedMongoWSID wsid, final long objectid,
			final ObjectSavePackage pkg)
			throws WorkspaceCommunicationException {
		final Map<String, Object> version = new HashMap<String, Object>();
		version.put(Fields.VER_SAVEDBY, user.getUser());
		version.put(Fields.VER_CHKSUM, pkg.td.getChksum());
		final List<Map<String, String>> meta = 
				new ArrayList<Map<String, String>>();
		if (pkg.wo.getUserMeta() != null) {
			for (String key: pkg.wo.getUserMeta().keySet()) {
				Map<String, String> m = new HashMap<String, String>();
				m.put(Fields.VER_META_KEY, key);
				m.put(Fields.VER_META_VALUE, pkg.wo.getUserMeta().get(key));
				meta.add(m);
			}
		}
		version.put(Fields.VER_META, meta);
		version.put(Fields.VER_REF, pkg.refs);
		version.put(Fields.VER_PROVREF, pkg.provrefs);
		version.put(Fields.VER_PROV, pkg.mprov.getMongoId());
		version.put(Fields.VER_TYPE, pkg.wo.getRep().getValidationTypeDefId()
				.getTypeString());
		version.put(Fields.VER_SIZE, pkg.td.getSize());
		version.put(Fields.VER_RVRT, null);
		version.put(Fields.VER_COPIED, null);
		saveObjectVersions(user, wsid, objectid, Arrays.asList(version),
				pkg.wo.isHidden());
		
		return new MongoObjectInfo(objectid, pkg.name,
				pkg.wo.getRep().getValidationTypeDefId().getTypeString(),
				(Date) version.get(Fields.VER_SAVEDATE),
				(Integer) version.get(Fields.VER_VER),
				user, wsid, pkg.td.getChksum(), pkg.td.getSize(),
				pkg.wo.getUserMeta());
	}
	

	private static final String M_SAVEINS_QRY = String.format("{%s: #, %s: #}",
			Fields.OBJ_WS_ID, Fields.OBJ_ID);
	private static final String M_SAVEINS_PROJ = String.format("{%s: 1, %s: 0}",
			Fields.OBJ_VCNT, Fields.MONGO_ID);
	private static final String M_SAVEINS_WTH = String.format(
			"{$inc: {%s: #}, $set: {%s: false, %s: #, %s: null, %s: #}, $push: {%s: 0}}",
			Fields.OBJ_VCNT, Fields.OBJ_DEL, Fields.OBJ_MODDATE,
			Fields.OBJ_LATEST, Fields.OBJ_HIDE, Fields.OBJ_REFCOUNTS);
	
	private void saveObjectVersions(final WorkspaceUser user,
			final ResolvedMongoWSID wsid, final long objectid,
			final List<Map<String, Object>> versions, final boolean hidden)
			throws WorkspaceCommunicationException {
		// collection objects might be batchable if saves are slow
		/* TODO deal with rare failure modes below as much as possible at some point. Not high prio since rare
		 * 1) save an object, crash w/ 0 versions. 2) increment versions, crash w/o saving
		 * check all places counter incremented (ws, obj, ver) to see if any other problems
		 * known issues in resolveObjects and listObjects
		 * can't necc count on the fact that vercount or latestVersion is accurate
		 * ignore listObjs for now, in resolveObjs mark vers with class and
		 * have queryVersions pull the right version if it's missing. Make a test for this.
		 * Have queryVersions revert to the newest version if the latest is missing, autorevert
		 * 
		 * None of the above addresses the objedt w/ 0 versions failure. Not sure what to do about that.
		 * 
		*/
		int ver;
		final Date saved = new Date();
		try {
			ver = (Integer) wsjongo.getCollection(COL_WORKSPACE_OBJS)
					.findAndModify(M_SAVEINS_QRY, wsid.getID(), objectid)
					.returnNew()
					.with(M_SAVEINS_WTH, versions.size(), saved, hidden)
					.projection(M_SAVEINS_PROJ).as(DBObject.class)
					.get(Fields.OBJ_VCNT)
					- versions.size() + 1;
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		//TODO look into why saving array of maps via List.ToArray() /w Jongo makes Lazy*Objects return, which screw up everything
		final List<DBObject> dbo = new LinkedList<DBObject>();
		for (final Map<String, Object> v: versions) {
			v.put(Fields.VER_SAVEDATE, saved);
			v.put(Fields.VER_WS_ID, wsid.getID());
			v.put(Fields.VER_ID, objectid);
			v.put(Fields.VER_VER, ver++);
			final DBObject d = new BasicDBObject();
			for (final Entry<String, Object> e: v.entrySet()) {
				d.put(e.getKey(), e.getValue());
			}
			dbo.add(d);
		}

		try {
			wsmongo.getCollection(COL_WORKSPACE_VERS).insert(dbo);
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
	}
	
	//TODO make all projections not include _id unless specified
	
	private static final String M_UNIQ_NAME_QRY = String.format(
			"{%s: #, %s: {$regex: '^#(-\\\\d+)?$'}}", Fields.OBJ_WS_ID,
			Fields.OBJ_NAME);
	private static final String M_UNIQ_NAME_PROJ = String.format(
			"{%s: 1, %s: 0}", Fields.OBJ_NAME, Fields.MONGO_ID);
	
	private String generateUniqueNameForObject(final ResolvedWorkspaceID wsid,
			final long objectid) throws WorkspaceCommunicationException {
		final String prefix = "auto" + objectid;
		@SuppressWarnings("rawtypes")
		Iterable<Map> ids;
		try {
			ids = wsjongo.getCollection(COL_WORKSPACE_OBJS)
					.find(M_UNIQ_NAME_QRY, wsid.getID(), prefix)
					.projection(M_UNIQ_NAME_PROJ).as(Map.class);
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		boolean exact = false;
		final Set<Long> suffixes = new HashSet<Long>();
		for (@SuppressWarnings("rawtypes") Map m: ids) {
			
			final String[] id = ((String) m.get(Fields.OBJ_NAME)).split("-");
			if (id.length == 2) {
				try {
					suffixes.add(Long.parseLong(id[1]));
				} catch (NumberFormatException e) {
					// do nothing
				}
			} else if (id.length == 1) {
				try {
					exact = exact || prefix.equals(id[0]);
				} catch (NumberFormatException e) {
					// do nothing
				}
			}
		}
		if (!exact) {
			return prefix;
		}
		long counter = 1;
		while (suffixes.contains(counter)) {
			counter++;
		}
		return prefix + "-" + counter;
	}
	
	//save brand new object - create container
	//objectid *must not exist* in the workspace otherwise this method will recurse indefinitely
	//the workspace must exist
	private IDName saveWorkspaceObject(
			final ResolvedMongoWSID wsid, final long objectid,
			final String name)
			throws WorkspaceCommunicationException {
		String newName = name;
		if (name == null) {
			newName = generateUniqueNameForObject(wsid, objectid);
		}
		final DBObject dbo = new BasicDBObject();
		dbo.put(Fields.OBJ_WS_ID, wsid.getID());
		dbo.put(Fields.OBJ_ID, objectid);
		dbo.put(Fields.OBJ_VCNT, 0); //Integer
		dbo.put(Fields.OBJ_REFCOUNTS, new LinkedList<Integer>());
		dbo.put(Fields.OBJ_NAME, newName);
		dbo.put(Fields.OBJ_LATEST, null);
		dbo.put(Fields.OBJ_DEL, false);
		dbo.put(Fields.OBJ_HIDE, false);
		try {
			//maybe could speed things up with batch inserts but dealing with
			//errors would really suck
			//do this later if it becomes a bottleneck
			wsmongo.getCollection(COL_WORKSPACE_OBJS).insert(dbo);
		} catch (MongoException.DuplicateKey dk) {
			//ok, someone must've just this second added this name to an object
			//asshole
			//this should be a rare event
			//TODO is this a name or id clash? if the latter, something is broken
			if (name == null) {
				//not much chance of this happening again, let's just recurse
				//and make a new name again
				return saveWorkspaceObject(wsid, objectid, name);
			}
			final ObjectIDNoWSNoVer o = new ObjectIDNoWSNoVer(name);
			final Map<ObjectIDNoWSNoVer, ResolvedMongoObjectID> objID =
					resolveObjectIDs(wsid,
							new HashSet<ObjectIDNoWSNoVer>(Arrays.asList(o)));
			if (objID.isEmpty()) {
				//oh ffs, name deleted again, try again
				return saveWorkspaceObject(wsid, objectid, name);
			}
			//save version via the id associated with our name which already exists
			return new IDName(objID.get(o).getId(), objID.get(o).getName());
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		return new IDName(objectid, newName);
	}
	
	private class IDName {
		
		public long id;
		public String name;
		
		public IDName(long id, String name) {
			super();
			this.id = id;
			this.name = name;
		}

		@Override
		public String toString() {
			return "IDName [id=" + id + ", name=" + name + "]";
		}
	}
	
	private static class ObjectSavePackage {
		
		public ResolvedSaveObject wo;
		public String name;
		public TypeData td;
		public Set<String> refs;
		public List<String> provrefs;
		public MongoProvenance mprov;
		
		@Override
		public String toString() {
			return "ObjectSavePackage [wo=" + wo + ", name=" + name + ", td="
					+ td + ", mprov =" + mprov +  "]";
		}
	}
	
	private static final ObjectMapper MAPPER = new ObjectMapper();
	
	private static String getObjectErrorId(final ObjectIDNoWSNoVer oi,
			final int objcount) {
		String objErrId = "#" + objcount;
		objErrId += oi == null ? "" : ", " + oi.getIdentifierString();
		return objErrId;
	}
	
	//at this point the objects are expected to be validated and references rewritten
	private List<ObjectSavePackage> saveObjectsBuildPackages(
			final List<ResolvedSaveObject> objects) {
		//this method must maintain the order of the objects
		int objnum = 1;
		final List<ObjectSavePackage> ret = new LinkedList<ObjectSavePackage>();
		for (ResolvedSaveObject o: objects) {
			if (o.getRep().getValidationTypeDefId().getMd5() != null) {
				throw new RuntimeException("MD5 types are not accepted");
			}
			final ObjectSavePackage pkg = new ObjectSavePackage();
			pkg.refs = checkRefsAreMongo(o.getRefs());
			//cannot do by combining in one set since a non-MongoReference
			//could be overwritten by a MongoReference if they have the same
			//hash
			pkg.provrefs = checkRefsAreMongo(o.getProvRefs());
			pkg.wo = o;
			checkObjectLength(o.getProvenance(), MAX_PROV_SIZE,
					o.getObjectIdentifier(), objnum, "provenance");
			
			final Map<String, Object> subdata;
			try {
				@SuppressWarnings("unchecked")
				final Map<String, Object> subdata2 = (Map<String, Object>)
						MAPPER.treeToValue(
								o.getRep().extractSearchableWsSubset(),
								Map.class);
				subdata = subdata2;
			} catch (JsonProcessingException jpe) {
				throw new RuntimeException(
						"Should never get a JSON exception here", jpe);
			}
			
			escapeSubdata(subdata);
			checkObjectLength(subdata, MAX_SUBDATA_SIZE,
					o.getObjectIdentifier(), objnum, "subdata");
			//could save time by making type->data->TypeData map and reusing
			//already calced TDs, but hardly seems worth it - unlikely event
			pkg.td = new TypeData(o.getRep().getJsonInstance(),
					o.getRep().getValidationTypeDefId(), subdata);
			if (pkg.td.getSize() > MAX_OBJECT_SIZE) {
				throw new IllegalArgumentException(String.format(
						"Object %s data size %s exceeds limit of %s",
						getObjectErrorId(o.getObjectIdentifier(), objnum),
						pkg.td.getSize(), MAX_OBJECT_SIZE));
			}
			ret.add(pkg);
			objnum++;
		}
		return ret;
	}
	
	//is there some way to combine these with generics?
	private Set<String> checkRefsAreMongo(final Set<Reference> refs) {
		final Set<String> newrefs = new HashSet<String>();
		checkRefsAreMongoInternal(refs, newrefs);
		return newrefs;
	}
	
	//order must be maintained
	private List<String> checkRefsAreMongo(final List<Reference> refs) {
		final List<String> newrefs = new LinkedList<String>();
		checkRefsAreMongoInternal(refs, newrefs);
		return newrefs;
	}

	private void checkRefsAreMongoInternal(final Collection<Reference> refs,
			final Collection<String> newrefs) {
		for (final Reference r: refs) {
			if (!(r instanceof MongoReference)) {
				throw new RuntimeException(
						"Improper reference implementation: " +
						(r == null ? null : r.getClass()));
			}
			newrefs.add(r.toString());
		}
	}

	private void checkObjectLength(final Object o, final long max,
			final ObjectIDNoWSNoVer oi, final int objnum,
			final String objtype) {
		final CountingOutputStream cos = new CountingOutputStream();
		try {
			//writes in UTF8
			MAPPER.writeValue(cos, o);
		} catch (IOException ioe) {
			throw new RuntimeException("something's broken", ioe);
		} finally {
			try {
				cos.close();
			} catch (IOException ioe) {
				throw new RuntimeException("something's broken", ioe);
			}
		}
		if (cos.getSize() > max) {
			throw new IllegalArgumentException(String.format(
					"Object %s %s size %s exceeds limit of %s",
					getObjectErrorId(oi, objnum), objtype, cos.getSize(), max));
		}
	}
	
	private void escapeSubdata(final Map<String, Object> subdata) {
		escapeSubdataInternal(subdata);
	}
	
	private void escapeSubdataInternal(final Object o) {
		if (o instanceof String || o instanceof Number ||
				o instanceof Boolean || o == null) {
			return;
		} else if (o instanceof List) {
			@SuppressWarnings("unchecked")
			final List<Object> l = (List<Object>)o;
			for (Object lo: l) {
				escapeSubdataInternal(lo);
			}
			return;
		} else if (o instanceof Map) {
			@SuppressWarnings("unchecked")
			final Map<String, Object> m = (Map<String, Object>)o;
			//save updated keys in separate map so we don't overwrite
			//keys before they're escaped
			final Map<String, Object> newm = new HashMap<String, Object>();
			for (final String k: m.keySet()) {
				escapeSubdataInternal(m.get(k));
				newm.put(mongoHTMLEscape(k), m.get(k));
			}
			m.clear();
			m.putAll(newm);
			return;
		} else {
			throw new RuntimeException("Unsupported class: " + o.getClass());
		}
	}
	
	private static final int CODEPOINT_PERC = new String("%").codePointAt(0);
	private static final int CODEPOINT_DLR = new String("$").codePointAt(0);
	private static final int CODEPOINT_PNT = new String(".").codePointAt(0);
	
	private String mongoHTMLEscape(final String s) {
		final StringBuilder ret = new StringBuilder();
		for (int offset = 0; offset < s.length(); ) {
			final int codepoint = s.codePointAt(offset);
			if (codepoint == CODEPOINT_PERC) {
				ret.append("%25");
			} else if (codepoint == CODEPOINT_DLR) {
				ret.append("%24");
			} else if (codepoint == CODEPOINT_PNT) {
				ret.append("%2e");
			} else {
				ret.appendCodePoint(codepoint);
			}
			offset += Character.charCount(codepoint);
		}
		return ret.toString();
	}
	
	private static final String M_SAVE_QRY = String.format("{%s: #}",
					Fields.WS_ID);
	private static final String M_SAVE_WTH = String.format("{$inc: {%s: #}}",
					Fields.WS_NUMOBJ);
	private static final String M_SAVE_PROJ = String.format("{%s: 1, %s: 0}",
			Fields.WS_NUMOBJ, Fields.MONGO_ID);
			
	//at this point the objects are expected to be validated and references rewritten
	@Override
	public List<ObjectInformation> saveObjects(final WorkspaceUser user, 
			final ResolvedWorkspaceID rwsi,
			final List<ResolvedSaveObject> objects)
			throws WorkspaceCommunicationException,
			NoSuchObjectException {
		//TODO break this up
		//this method must maintain the order of the objects
		
		final ResolvedMongoWSID wsidmongo = query.convertResolvedWSID(rwsi);
		final List<ObjectSavePackage> packages = saveObjectsBuildPackages(
				objects);
		final Map<ObjectIDNoWSNoVer, List<ObjectSavePackage>> idToPkg =
				new HashMap<ObjectIDNoWSNoVer, List<ObjectSavePackage>>();
		int newobjects = 0;
		for (final ObjectSavePackage p: packages) {
			final ObjectIDNoWSNoVer o = p.wo.getObjectIdentifier();
			if (o != null) {
				if (idToPkg.get(o) == null) {
					idToPkg.put(o, new ArrayList<ObjectSavePackage>());
				}
				idToPkg.get(o).add(p);
			} else {
				newobjects++;
			}
		}
		final Map<ObjectIDNoWSNoVer, ResolvedMongoObjectID> objIDs =
				resolveObjectIDs(wsidmongo, idToPkg.keySet());
		for (ObjectIDNoWSNoVer o: idToPkg.keySet()) {
			if (!objIDs.containsKey(o)) {
				if (o.getId() != null) {
					throw new NoSuchObjectException(
							"There is no object with id " + o.getId());
				} else {
					for (ObjectSavePackage pkg: idToPkg.get(o)) {
						pkg.name = o.getName();
					}
					newobjects++;
				}
			} else {
				for (ObjectSavePackage pkg: idToPkg.get(o)) {
					pkg.name = objIDs.get(o).getName();
				}
			}
		}
		//at this point everything should be ready to save, only comm errors
		//can stop us now, the world is doomed
		saveData(wsidmongo, packages);
		saveProvenance(packages);
		updateReferenceCounts(packages);
		long newid = incrementWorkspaceCounter(wsidmongo, newobjects);
		/*  alternate impl: 1) make all save objects 2) increment all version
		 *  counters 3) batch save versions
		 *  This probably won't help much. Firstly, saving the same object
		 *  multiple times (e.g. save over the same object in the same
		 *  saveObjects call) is going to be a rare op - who wants to do that?
		 *  Hence batching up the version increments is probably not going to
		 *  help much.
		 *  Secondly, the write lock is on a per document basis, so batching
		 *  writes has no effect on write locking.
		 *  That means that the gain from batching writes is removal of the 
		 *  flight time to/from the server between each object. This may
		 *  be significant for many small objects, but is probably
		 *  insignificant for a few objects, or many large objects.
		 *  Summary: probably not worth the trouble and increase in code
		 *  complexity.
		 */
		final List<ObjectInformation> ret = new ArrayList<ObjectInformation>();
		final Map<String, Long> seenNames = new HashMap<String, Long>();
		for (final ObjectSavePackage p: packages) {
			final ObjectIDNoWSNoVer oi = p.wo.getObjectIdentifier();
			if (oi == null) { //no name given, need to generate one
				final IDName obj = saveWorkspaceObject(wsidmongo, newid++,
						null);
				p.name = obj.name;
				ret.add(saveObjectVersion(user, wsidmongo, obj.id, p));
			} else if (oi.getId() != null) { //confirmed ok id
				ret.add(saveObjectVersion(user, wsidmongo, oi.getId(), p));
			} else if (objIDs.get(oi) != null) {//given name translated to id
				ret.add(saveObjectVersion(user, wsidmongo, objIDs.get(oi).getId(), p));
			} else if (seenNames.containsKey(oi.getName())) {
				//we've already generated an id for this name
				ret.add(saveObjectVersion(user, wsidmongo, seenNames.get(oi.getName()), p));
			} else {//new name, need to generate new id
				final IDName obj = saveWorkspaceObject(wsidmongo, newid++,
						oi.getName());
				p.name = obj.name;
				seenNames.put(obj.name, obj.id);
				ret.add(saveObjectVersion(user, wsidmongo, obj.id, p));
			}
		}
		return ret;
	}

	//returns starting object number
	private long incrementWorkspaceCounter(final ResolvedMongoWSID wsidmongo,
			final int newobjects) throws WorkspaceCommunicationException {
		final long lastid;
		try {
			lastid = ((Number) wsjongo.getCollection(COL_WORKSPACES)
					.findAndModify(M_SAVE_QRY, wsidmongo.getID())
					.returnNew().with(M_SAVE_WTH, (long) newobjects)
					.projection(M_SAVE_PROJ)
					.as(DBObject.class).get(Fields.WS_NUMOBJ)).longValue();
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		long newid = lastid - newobjects + 1;
		return newid;
	}
	
	private void saveProvenance(final List<ObjectSavePackage> packages)
			throws WorkspaceCommunicationException {
		final List<MongoProvenance> prov = new LinkedList<MongoProvenance>();
		for (final ObjectSavePackage p: packages) {
			final MongoProvenance mp = new MongoProvenance(
					p.wo.getProvenance());
			prov.add(mp);
			p.mprov = mp;
		}
		try {
			wsjongo.getCollection(COL_PROVENANCE).insert((Object[])
					prov.toArray(new MongoProvenance[prov.size()]));
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
	}

	private class VerCount {
		final public int ver;
		final public int count;

		public VerCount (final int ver, final int count) {
			this.ver = ver;
			this.count = count;
		}
		
		@Override
		public String toString() {
			return "VerCount [ver=" + ver + ", count=" + count + "]";
		}

		@Override
		public int hashCode() {
			final int prime = 31;
			int result = 1;
			result = prime * result + getOuterType().hashCode();
			result = prime * result + count;
			result = prime * result + ver;
			return result;
		}
		
		@Override
		public boolean equals(Object obj) {
			if (this == obj) {
				return true;
			}
			if (obj == null) {
				return false;
			}
			if (!(obj instanceof VerCount)) {
				return false;
			}
			VerCount other = (VerCount) obj;
			if (!getOuterType().equals(other.getOuterType())) {
				return false;
			}
			if (count != other.count) {
				return false;
			}
			if (ver != other.ver) {
				return false;
			}
			return true;
		}

		private MongoWorkspaceDB getOuterType() {
			return MongoWorkspaceDB.this;
		}
	}
	
	private void updateReferenceCounts(final List<ObjectSavePackage> packages)
			throws WorkspaceCommunicationException {
		//TODO when garbage collection working much more testing of these methods
		final Map<Long, Map<Long, Map<Integer, Counter>>> refcounts = 
				countReferences(packages);
		/* since the version numbers are probably highly skewed towards 1 and
		 * the reference counts are also highly skewed towards 1 we can 
		 * probably minimize the number of updates by running one update
		 * per version/count combination
		 */
		updateReferenceCounts(refcounts);
	}
	
	private void updateReferenceCountsForVersions(
			final List<Map<String, Object>> versions)
			throws WorkspaceCommunicationException {
		//TODO when garbage collection working much more testing of these methods
		final Map<Long, Map<Long, Map<Integer, Counter>>> refcounts = 
				countReferencesForVersions(versions);
		/* since the version numbers are probably highly skewed towards 1 and
		 * the reference counts are also highly skewed towards 1 we can 
		 * probably minimize the number of updates by running one update
		 * per version/count combination
		 */
		updateReferenceCounts(refcounts);
	}

	private void updateReferenceCounts(
			final Map<Long, Map<Long, Map<Integer, Counter>>> refcounts)
			throws WorkspaceCommunicationException {
		final Map<VerCount, Map<Long, List<Long>>> queries = 
				new HashMap<VerCount, Map<Long,List<Long>>>();
		for (final Long ws: refcounts.keySet()) {
			for (final Long obj: refcounts.get(ws).keySet()) {
				for (final Integer ver: refcounts.get(ws).get(obj).keySet()) {
					final VerCount vc = new VerCount(ver,
							refcounts.get(ws).get(obj).get(ver).getValue());
					if (!queries.containsKey(vc)) {
						queries.put(vc, new HashMap<Long, List<Long>>());
					}
					if (!queries.get(vc).containsKey(ws)) {
						queries.get(vc).put(ws, new LinkedList<Long>());
					}
					queries.get(vc).get(ws).add(obj);
				}
			}
		}
		for (final VerCount vc: queries.keySet()) {
			updateReferenceCounts(vc, queries.get(vc));
		}
	}

	private void updateReferenceCounts(final VerCount vc,
			final Map<Long, List<Long>> wsToObjs)
			throws WorkspaceCommunicationException {
		final DBObject update = new BasicDBObject("$inc",
				new BasicDBObject(Fields.OBJ_REFCOUNTS + "." + (vc.ver - 1),
						vc.count));
		final List<DBObject> orquery = new LinkedList<DBObject>();
		for (final Long ws: wsToObjs.keySet()) {
			final DBObject query = new BasicDBObject(Fields.OBJ_WS_ID, ws);
			query.put(Fields.OBJ_ID, new BasicDBObject("$in",
					wsToObjs.get(ws)));
			orquery.add(query);
		}
		try {
			wsmongo.getCollection(COL_WORKSPACE_OBJS).update(
					new BasicDBObject("$or", orquery), update, false, true);
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
	}

	private Map<Long, Map<Long, Map<Integer, Counter>>> countReferences(
			final List<ObjectSavePackage> packages) {
		final Map<Long, Map<Long, Map<Integer, Counter>>> refcounts =
				new HashMap<Long, Map<Long,Map<Integer,Counter>>>();
		for (final ObjectSavePackage p: packages) {
			//these were checked to be MongoReferences in saveObjectBuildPackages
			final Set<Reference> refs = new HashSet<Reference>();
			refs.addAll(p.wo.getRefs());
			refs.addAll(p.wo.getProvRefs());
			countReferences(refcounts, refs);
		}
		return refcounts;
	}
	
	private Map<Long, Map<Long, Map<Integer, Counter>>> countReferencesForVersions(
			final List<Map<String, Object>> versions) {
		final Map<Long, Map<Long, Map<Integer, Counter>>> refcounts =
				new HashMap<Long, Map<Long,Map<Integer,Counter>>>();
		for (final Map<String, Object> p: versions) {
			//these were checked to be MongoReferences in saveObjectBuildPackages
			final Set<Reference> refs = new HashSet<Reference>();
			@SuppressWarnings("unchecked")
			final List<String> objrefs = (List<String>) p.get(Fields.VER_REF);
			@SuppressWarnings("unchecked")
			final List<String> provrefs = (List<String>) p.get(Fields.VER_PROVREF);
//			objrefs.addAll(provrefs); //DON'T DO THIS YOU MORON
			for (final String s: objrefs) {
				refs.add(new MongoReference(s));
			}
			for (final String s: provrefs) {
				refs.add(new MongoReference(s));
			}
			countReferences(refcounts, refs);
		}
		return refcounts;
	}

	private void countReferences(
			final Map<Long, Map<Long, Map<Integer, Counter>>> refcounts,
			final Set<Reference> refs) {
		for (final Reference r: refs) {
			if (!refcounts.containsKey(r.getWorkspaceID())) {
				refcounts.put(r.getWorkspaceID(),
						new HashMap<Long, Map<Integer, Counter>>());
			}
			if (!refcounts.get(r.getWorkspaceID())
					.containsKey(r.getObjectID())) {
				refcounts.get(r.getWorkspaceID()).put(r.getObjectID(),
						new HashMap<Integer, Counter>());
			}
			if (!refcounts.get(r.getWorkspaceID()).get(r.getObjectID())
					.containsKey(r.getVersion())) {
				refcounts.get(r.getWorkspaceID()).get(r.getObjectID())
					.put(r.getVersion(), new Counter());
			}
			refcounts.get(r.getWorkspaceID()).get(r.getObjectID())
				.get(r.getVersion()).increment();
		}
	}

	private void saveData(final ResolvedMongoWSID workspaceid,
			final List<ObjectSavePackage> data) throws
			WorkspaceCommunicationException {
		final Map<TypeDefId, List<ObjectSavePackage>> pkgByType =
				new HashMap<TypeDefId, List<ObjectSavePackage>>();
		for (final ObjectSavePackage p: data) {
			if (pkgByType.get(p.td.getType()) == null) {
				pkgByType.put(p.td.getType(), new ArrayList<ObjectSavePackage>());
			}
			pkgByType.get(p.td.getType()).add(p);
		}
		for (final TypeDefId type: pkgByType.keySet()) {
			ensureTypeIndex(type);
			final String col = TypeData.getTypeCollection(type);
			final Map<String, TypeData> chksum = new HashMap<String, TypeData>();
			for (ObjectSavePackage p: pkgByType.get(type)) {
				chksum.put(p.td.getChksum(), p.td);
			}
			final DBObject query = new BasicDBObject(Fields.TYPE_CHKSUM,
					new BasicDBObject("$in", new ArrayList<String>(
							chksum.keySet())));
			final DBObject proj = new BasicDBObject(Fields.TYPE_CHKSUM, 1);
			proj.put(Fields.MONGO_ID, 0);
			DBCursor res;
			try {
				res = wsmongo.getCollection(col).find(query, proj);
			} catch (MongoException me) {
				throw new WorkspaceCommunicationException(
						"There was a problem communicating with the database", me);
			}
			final Set<String> existChksum = new HashSet<String>();
			for (DBObject dbo: res) {
				existChksum.add((String)dbo.get(Fields.TYPE_CHKSUM));
			}
			
			final List<TypeData> newdata = new ArrayList<TypeData>();
			for (String md5: chksum.keySet()) {
				if (existChksum.contains(md5)) {
					continue;
				}
				newdata.add(chksum.get(md5));
				try {
					//this is kind of stupid, but no matter how you slice it you have
					//to calc md5s before you save the data
					blob.saveBlob(new MD5(md5), chksum.get(md5).getData());
				} catch (BlobStoreCommunicationException e) {
					throw new WorkspaceCommunicationException(
							e.getLocalizedMessage(), e);
				} catch (BlobStoreAuthorizationException e) {
					throw new WorkspaceCommunicationException(
							"Authorization error communicating with the backend storage system",
							e);
				}
			}
			try {
				wsjongo.getCollection(col).insert((Object[]) newdata.toArray(
						new TypeData[newdata.size()]));
			} catch (MongoException.DuplicateKey dk) {
				//At least one of the data objects was just inserted by another
				//thread, which is fine - do nothing
			} catch (MongoException me) {
				throw new WorkspaceCommunicationException(
						"There was a problem communicating with the database", me);
			}
		}
	}
	
	private static final Set<String> FLDS_VER_META_PROV = newHashSet(
			Fields.VER_VER, Fields.VER_META, Fields.VER_TYPE,
			Fields.VER_SAVEDATE, Fields.VER_SAVEDBY,
			Fields.VER_CHKSUM, Fields.VER_SIZE, Fields.VER_PROV,
			Fields.VER_PROVREF, Fields.VER_REF);
	
	public Map<ObjectIDResolvedWS, WorkspaceObjectData> getObjects(
			final Set<ObjectIDResolvedWS> objectIDs) throws
			NoSuchObjectException, WorkspaceCommunicationException,
			CorruptWorkspaceDBException {
		final Map<ObjectIDResolvedWS, ResolvedMongoObjectID> oids =
				resolveObjectIDs(objectIDs);
		final Map<ResolvedMongoObjectID, Map<String, Object>> vers = 
				query.queryVersions(
						new HashSet<ResolvedMongoObjectID>(oids.values()),
						FLDS_VER_META_PROV);
		final Map<ObjectId, MongoProvenance> provs = getProvenance(vers);
		final Map<String, JsonNode> chksumToData = new HashMap<String, JsonNode>();
		final Map<ObjectIDResolvedWS, WorkspaceObjectData> ret =
				new HashMap<ObjectIDResolvedWS, WorkspaceObjectData>();
		for (ObjectIDResolvedWS o: objectIDs) {
			final ResolvedMongoObjectID roi = oids.get(o);
			if (!vers.containsKey(roi)) {
				throw new NoSuchObjectException(String.format(
						"No object with id %s (name %s) and version %s exists "
						+ "in workspace %s", roi.getId(), roi.getName(), 
						roi.getVersion(), 
						roi.getWorkspaceIdentifier().getID()), o);
			}
			final MongoProvenance prov = provs.get((ObjectId) vers.get(roi)
					.get(Fields.VER_PROV));
			@SuppressWarnings("unchecked")
			final List<String> refs =
					(List<String>) vers.get(roi).get(Fields.VER_REF);
			final MongoObjectInfo meta = generateUserMetaInfo(
					roi, vers.get(roi));
			if (chksumToData.containsKey(meta.getCheckSum())) {
				ret.put(o, new WorkspaceObjectData(
						chksumToData.get(meta.getCheckSum()), meta, prov, refs));
			} else {
				final JsonNode data;
				try {
					data = blob.getBlob(new MD5(meta.getCheckSum()));
				} catch (BlobStoreCommunicationException e) {
					throw new WorkspaceCommunicationException(
							e.getLocalizedMessage(), e);
				} catch (BlobStoreAuthorizationException e) {
					throw new WorkspaceCommunicationException(
							"Authorization error communicating with the backend storage system",
							e);
				} catch (NoSuchBlobException e) {
					throw new CorruptWorkspaceDBException(String.format(
							"No data present for valid object %s.%s.%s",
							meta.getWorkspaceId(), meta.getObjectId(),
							meta.getVersion()), e);
				}
				chksumToData.put(meta.getCheckSum(), data);
				ret.put(o, new WorkspaceObjectData(data, meta, prov, refs));
			}
		}
		return ret;
	}
	
	private Map<ObjectId, MongoProvenance> getProvenance(
			final Map<ResolvedMongoObjectID, Map<String, Object>> vers)
			throws WorkspaceCommunicationException {
		final Map<ObjectId, Map<String, Object>> provIDs =
				new HashMap<ObjectId, Map<String,Object>>();
		for (final ResolvedMongoObjectID id: vers.keySet()) {
			provIDs.put((ObjectId) vers.get(id).get(Fields.VER_PROV),
					vers.get(id));
		}
		final Iterable<MongoProvenance> provs;
		try {
			provs = wsjongo.getCollection(COL_PROVENANCE)
					.find("{_id: {$in: #}}", provIDs.keySet())
					.as(MongoProvenance.class);
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		final Map<ObjectId, MongoProvenance> ret =
				new HashMap<ObjectId, MongoProvenance>();
		for (MongoProvenance p: provs) {
			@SuppressWarnings("unchecked")
			final List<String> resolvedRefs = (List<String>) provIDs
					.get(p.getMongoId()).get(Fields.VER_PROVREF);
			ret.put(p.getMongoId(), p);
			p.resolveReferences(resolvedRefs); //this is a gross hack. I'm rather proud of it actually
		}
		return ret;
	}
	
	private MongoObjectInfo generateUserMetaInfo(
			final ResolvedMongoObjectID roi, final Map<String, Object> ver) {
		return generateUserMetaInfo(roi.getWorkspaceIdentifier(), roi.getId(),
				roi.getName(), ver);
	}

	private MongoObjectInfo generateUserMetaInfo(
			final ResolvedMongoWSID rwsi, final long objid, final String name,
			final Map<String, Object> ver) {
		@SuppressWarnings("unchecked")
		final List<Map<String, String>> meta =
				(List<Map<String, String>>) ver.get(Fields.VER_META);
		return new MongoObjectInfo(
				objid,
				name,
				(String) ver.get(Fields.VER_TYPE),
				(Date) ver.get(Fields.VER_SAVEDATE),
				(Integer) ver.get(Fields.VER_VER),
				new WorkspaceUser((String) ver.get(Fields.VER_SAVEDBY)),
				rwsi,
				(String) ver.get(Fields.VER_CHKSUM),
				(Long) ver.get(Fields.VER_SIZE),
				meta == null ? null : metaMongoArrayToHash(meta));
	}
	
	private static final Set<String> FLDS_VER_TYPE = newHashSet(
			Fields.VER_TYPE, Fields.VER_VER);
	
	public Map<ObjectIDResolvedWS, TypeAndReference> getObjectType(
			final Set<ObjectIDResolvedWS> objectIDs) throws
			NoSuchObjectException, WorkspaceCommunicationException {
		//this method is a pattern - generalize somehow?
		final Map<ObjectIDResolvedWS, ResolvedMongoObjectID> oids =
				resolveObjectIDs(objectIDs);
		final Map<ResolvedMongoObjectID, Map<String, Object>> vers = 
				query.queryVersions(
						new HashSet<ResolvedMongoObjectID>(oids.values()),
						FLDS_VER_TYPE);
		final Map<ObjectIDResolvedWS, TypeAndReference> ret =
				new HashMap<ObjectIDResolvedWS, TypeAndReference>();
		for (ObjectIDResolvedWS o: objectIDs) {
			final ResolvedMongoObjectID roi = oids.get(o);
			if (!vers.containsKey(roi)) {
				throw new NoSuchObjectException(String.format(
						"No object with id %s (name %s) and version %s exists "
						+ "in workspace %s", roi.getId(), roi.getName(), 
						roi.getVersion(), 
						roi.getWorkspaceIdentifier().getID()), o);
			}
			ret.put(o, new TypeAndReference(
					AbsoluteTypeDefId.fromAbsoluteTypeString(
							(String) vers.get(roi).get(Fields.VER_TYPE)),
					new MongoReference(roi.getWorkspaceIdentifier().getID(),
							roi.getId(),
							(Integer) vers.get(roi).get(Fields.VER_VER))));
		}
		return ret;
	}
	
	private static final Set<String> FLDS_LIST_OBJ_VER = newHashSet(
			Fields.VER_VER, Fields.VER_TYPE, Fields.VER_SAVEDATE,
			Fields.VER_SAVEDBY, Fields.VER_VER, Fields.VER_CHKSUM,
			Fields.VER_SIZE, Fields.VER_ID, Fields.VER_WS_ID);
	
	private static final Set<String> FLDS_LIST_OBJ = newHashSet(
			Fields.OBJ_ID, Fields.OBJ_NAME, Fields.OBJ_DEL, Fields.OBJ_HIDE,
			Fields.OBJ_LATEST, Fields.OBJ_VCNT, Fields.OBJ_WS_ID);
	
	private static final String LATEST_VERSION = "latestVersion";

	@Override
	public List<ObjectInformation> getObjectInformation(
			final PermissionSet pset, final TypeDefId type,
			final boolean showHidden, final boolean showDeleted,
			final boolean showAllVers, final boolean includeMetadata)
			throws WorkspaceCommunicationException {
		//TODO yet another long method that needs pruning
		/* Could make this method more efficient by doing different queries
		 * based on the filters. If there's no filters except the workspace,
		 * for example, just grab all the objects for the workspaces,
		 * filtering out hidden and deleted in the query and pull the most
		 * recent versions for the remaining objects. For now, just go
		 * with a dumb general method and add smarter heuristics as needed.
		 */
		if (!(pset instanceof MongoPermissionSet)) {
			throw new IllegalArgumentException(
					"Illegal implementation of PermissionSet: " +
					pset.getClass().getName());
		}
		if (pset.isEmpty()) {
			return new LinkedList<ObjectInformation>();
		}
		if (pset.hasUnreadableWorkspace()) {
			throw new IllegalArgumentException(
					"All workspaces in the permission set must be readable");
		}
		final DBObject verq = new BasicDBObject();
		final Map<Long, ResolvedWorkspaceID> ids =
				new HashMap<Long, ResolvedWorkspaceID>();
		for (final ResolvedWorkspaceID rwsi: pset.getWorkspaces()) {
			final ResolvedMongoWSID rm = query.convertResolvedWSID(rwsi);
			ids.put(rm.getID(), rm);
		}
		verq.put(Fields.VER_WS_ID, new BasicDBObject("$in", ids.keySet()));
		if (type != null) {
			verq.put(Fields.VER_TYPE,
					new BasicDBObject("$regex", "^" + type.getTypePrefix()));
		}
		final Set<String> fields;
		if (includeMetadata) {
			fields = new HashSet<String>(FLDS_LIST_OBJ_VER);
			fields.add(Fields.VER_META);
		} else {
			fields = FLDS_LIST_OBJ_VER;
		}
		final List<Map<String, Object>> verobjs = query.queryCollection(
				COL_WORKSPACE_VERS, verq, fields);
		if (verobjs.isEmpty()) {
			return new LinkedList<ObjectInformation>();
		}
		//wsid -> obj ids
		final Map<Long, Set<Long>> verdata = getObjectIDsFromVersions(verobjs);
		//TODO This $or query might be better as multiple individual queries, test
		final List<DBObject> orquery = new LinkedList<DBObject>();
		for (final Long wsid: verdata.keySet()) {
			final DBObject query = new BasicDBObject(Fields.VER_WS_ID, wsid);
			query.put(Fields.VER_ID, new BasicDBObject(
					"$in", verdata.get(wsid)));
			orquery.add(query);
		}
		final DBObject objq = new BasicDBObject("$or", orquery);
		//could exclude hidden and deleted objects here?
		final Map<Long, Map<Long, Map<String, Object>>> objdata =
				organizeObjData(query.queryCollection(
						COL_WORKSPACE_OBJS, objq, FLDS_LIST_OBJ));
		final List<ObjectInformation> ret = new LinkedList<ObjectInformation>();
		for (final Map<String, Object> vo: verobjs) {
			final long wsid = (Long) vo.get(Fields.VER_WS_ID);
			final long id = (Long) vo.get(Fields.VER_ID);
			final int ver = (Integer) vo.get(Fields.VER_VER);
			final Map<String, Object> obj = objdata.get(wsid).get(id);
			final int lastver = (Integer) obj.get(LATEST_VERSION);
			final ResolvedMongoWSID rwsi = (ResolvedMongoWSID) ids.get(wsid);
			if (!showAllVers && lastver != ver) {
				/* this is tricky. As is, if there's a failure between incrementing
				 * an object ver count and saving the object version no latest
				 * ver will be listed. On the other hand, if we just take
				 * the max ver we'd be adding incorrect latest vers when filters
				 * exclude the real max ver. To do this correctly we've have to
				 * get the max ver for all objects which is really expensive.
				 * Since the failure mode should be very rare and it fixable
				 * by simply reverting the object do nothing for now.
				 */
				continue;
			}
			if ((Boolean) obj.get(Fields.OBJ_HIDE) && !showHidden) {
				continue;
			}
			if ((Boolean) obj.get(Fields.OBJ_DEL) && (!showDeleted ||
					!pset.hasPermission(rwsi, Permission.WRITE))) {
				continue;
			}
			ret.add(generateUserMetaInfo(rwsi, id,
					(String) obj.get(Fields.OBJ_NAME), vo));
		}
		return ret;
	}
	
	private Map<Long, Map<Long, Map<String, Object>>> organizeObjData(
			final List<Map<String, Object>> objs) {
		final Map<Long, Map<Long, Map<String, Object>>> ret =
				new HashMap<Long, Map<Long,Map<String,Object>>>();
		for (final Map<String, Object> o: objs) {
			final long wsid = (Long) o.get(Fields.OBJ_WS_ID);
			final long objid = (Long) o.get(Fields.OBJ_ID);
			final int latestVersion;
			if ((Integer) o.get(Fields.OBJ_LATEST) == null) {
				latestVersion = (Integer) o.get(Fields.OBJ_VCNT);
			} else {
				//TODO check this works with GC
				latestVersion = (Integer) o.get(Fields.OBJ_LATEST);
			}
			o.put(LATEST_VERSION, latestVersion);
			if (!ret.containsKey(wsid)) {
				ret.put(wsid, new HashMap<Long, Map<String, Object>>());
			}
			ret.get(wsid).put(objid, o);
		}
		return ret;
	}

	private Map<Long, Set<Long>> getObjectIDsFromVersions(
			final List<Map<String, Object>> objs) {
		final Map<Long, Set<Long>> ret = new HashMap<Long, Set<Long>>();
		for (final Map<String, Object> o: objs) {
			final long wsid = (Long) o.get(Fields.VER_WS_ID);
			final long objid = (Long) o.get(Fields.VER_ID);
			if (!ret.containsKey(wsid)) {
				ret.put(wsid, new HashSet<Long>());
			}
			ret.get(wsid).add(objid);
		}
		return ret;
	}

	private static final Set<String> FLDS_VER_META = newHashSet(
			Fields.VER_VER, Fields.VER_TYPE,
			Fields.VER_SAVEDATE, Fields.VER_SAVEDBY,
			Fields.VER_CHKSUM, Fields.VER_SIZE);
	
	@Override
	public Map<ObjectIDResolvedWS, ObjectInformation> getObjectInformation(
			final Set<ObjectIDResolvedWS> objectIDs,
			final boolean includeMetadata) throws
			NoSuchObjectException, WorkspaceCommunicationException {
		final Map<ObjectIDResolvedWS, ResolvedMongoObjectID> oids =
				resolveObjectIDs(objectIDs);
		final Set<String> fields;
		if (includeMetadata) {
			fields = new HashSet<String>(FLDS_VER_META);
			fields.add(Fields.VER_META);
		} else {
			fields = FLDS_VER_META;
		}
		final Map<ResolvedMongoObjectID, Map<String, Object>> vers = 
				query.queryVersions(
						new HashSet<ResolvedMongoObjectID>(oids.values()),
						fields);
		final Map<ObjectIDResolvedWS, ObjectInformation> ret =
				new HashMap<ObjectIDResolvedWS, ObjectInformation>();
		for (ObjectIDResolvedWS o: objectIDs) {
			final ResolvedMongoObjectID roi = oids.get(o);
			if (!vers.containsKey(roi)) {
				throw new NoSuchObjectException(String.format(
						"No object with id %s (name %s) and version %s exists "
						+ "in workspace %s", roi.getId(), roi.getName(), 
						roi.getVersion(), 
						roi.getWorkspaceIdentifier().getID()), o);
			}
			ret.put(o, generateUserMetaInfo(roi, vers.get(roi)));
		}
		return ret;
	}
	
	private Map<String, String> metaMongoArrayToHash(
			final List<Map<String, String>> meta) {
		final Map<String, String> ret = new HashMap<String, String>();
		for (final Map<String, String> m: meta) {
			ret.put(m.get(Fields.VER_META_KEY),
					m.get(Fields.VER_META_VALUE));
		}
		return ret;
	}
	
	private static final Set<String> FLDS_RESOLVE_OBJS =
			newHashSet(Fields.OBJ_ID, Fields.OBJ_NAME, Fields.OBJ_DEL,
					Fields.OBJ_LATEST, Fields.OBJ_VCNT);
	
	private Map<ObjectIDResolvedWS, ResolvedMongoObjectID> resolveObjectIDs(
			final Set<ObjectIDResolvedWS> objectIDs)
			throws NoSuchObjectException, WorkspaceCommunicationException {
		return resolveObjectIDs(objectIDs, true, true);
	}
	
	private Map<ObjectIDResolvedWS, ResolvedMongoObjectID> resolveObjectIDs(
			final Set<ObjectIDResolvedWS> objectIDs,
			final boolean exceptIfDeleted, final boolean exceptIfMissing)
			throws NoSuchObjectException, WorkspaceCommunicationException {
		final Map<ObjectIDResolvedWS, ObjectIDResolvedWSNoVer> nover =
				new HashMap<ObjectIDResolvedWS, ObjectIDResolvedWSNoVer>();
		for (final ObjectIDResolvedWS o: objectIDs) {
			nover.put(o, new ObjectIDResolvedWSNoVer(o));
		}
		final Map<ObjectIDResolvedWSNoVer, Map<String, Object>> ids = 
				query.queryObjects(
						new HashSet<ObjectIDResolvedWSNoVer>(nover.values()),
						FLDS_RESOLVE_OBJS);
		final Map<ObjectIDResolvedWS, ResolvedMongoObjectID> ret =
				new HashMap<ObjectIDResolvedWS, ResolvedMongoObjectID>();
		for (final ObjectIDResolvedWS oid: nover.keySet()) {
			final ObjectIDResolvedWSNoVer o = nover.get(oid);
			if (!ids.containsKey(o)) {
				if (exceptIfMissing) {
					final String err = oid.getId() == null ? "name" : "id";
					throw new NoSuchObjectException(String.format(
							"No object with %s %s exists in workspace %s",
							err, oid.getIdentifierString(),
							oid.getWorkspaceIdentifier().getID()), oid);
				} else {
					continue;
				}
			}
			final String name = (String) ids.get(o).get(Fields.OBJ_NAME);
			final long id = (Long) ids.get(o).get(Fields.OBJ_ID);
			if (exceptIfDeleted && (Boolean) ids.get(o).get(Fields.OBJ_DEL)) {
				throw new NoSuchObjectException(String.format(
						"Object %s (name %s) in workspace %s has been deleted",
						id, name, oid.getWorkspaceIdentifier().getID()), oid);
			}
			final Integer latestVersion;
			if ((Integer) ids.get(o).get(Fields.OBJ_LATEST) == null) {
				latestVersion = (Integer) ids.get(o).get(Fields.OBJ_VCNT);
			} else {
				//TODO check this works with GC
				latestVersion = (Integer) ids.get(o).get(Fields.OBJ_LATEST);
			}
			if (oid.getVersion() == null ||
					oid.getVersion().equals(latestVersion)) {
				//TODO this could be wrong if the vercount was incremented without a ver save, should verify and then sort if needed
				ret.put(oid, new ResolvedMongoOIDWithObjLastVer(
						query.convertResolvedWSID(oid.getWorkspaceIdentifier()),
						name, id, latestVersion));
			} else {
				if (oid.getVersion().compareTo(latestVersion) > 0) {
					throw new NoSuchObjectException(String.format(
							"No object with id %s (name %s) and version %s" +
							" exists in workspace %s", id, name,
							oid.getVersion(), 
							oid.getWorkspaceIdentifier().getID()), oid);
				} else {
					ret.put(oid, new ResolvedMongoObjectID(
							query.convertResolvedWSID(
									oid.getWorkspaceIdentifier()),
							name, id, oid.getVersion().intValue()));
				}
			}
		}
		return ret;
	}

	@Override
	public void setObjectsHidden(final Set<ObjectIDResolvedWS> objectIDs,
			final boolean hide)
			throws NoSuchObjectException, WorkspaceCommunicationException {
		//TODO nearly identical to delete objects, generalize
		final Map<ObjectIDResolvedWS, ResolvedMongoObjectID> ids =
				resolveObjectIDs(objectIDs);
		final Map<ResolvedMongoWSID, List<Long>> toModify =
				new HashMap<ResolvedMongoWSID, List<Long>>();
		for (final ObjectIDResolvedWS o: objectIDs) {
			final ResolvedMongoWSID ws = query.convertResolvedWSID(
					o.getWorkspaceIdentifier());
			if (!toModify.containsKey(ws)) {
				toModify.put(ws, new ArrayList<Long>());
			}
			toModify.get(ws).add(ids.get(o).getId());
		}
		//Do this by workspace since per mongo docs nested $ors are crappy
		for (final ResolvedMongoWSID ws: toModify.keySet()) {
			setObjectsHidden(ws, toModify.get(ws), hide);
		}
	}
	
	private static final String M_HIDOBJ_WTH = String.format(
			"{$set: {%s: #}}", Fields.OBJ_HIDE);
	private static final String M_HIDOBJ_QRY = String.format(
			"{%s: #, %s: {$in: #}}", Fields.OBJ_WS_ID, Fields.OBJ_ID);
	
	private void setObjectsHidden(final ResolvedMongoWSID ws,
			final List<Long> objectIDs, final boolean hide)
			throws WorkspaceCommunicationException {
		//TODO make general set field method?
		if (objectIDs.isEmpty()) {
			throw new IllegalArgumentException("Object IDs cannot be empty");
		}
		try {
			wsjongo.getCollection(COL_WORKSPACE_OBJS)
					.update(M_HIDOBJ_QRY, ws.getID(), objectIDs).multi()
					.with(M_HIDOBJ_WTH, hide);
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
	}
	
	@Override
	public void setObjectsDeleted(final Set<ObjectIDResolvedWS> objectIDs,
			final boolean delete)
			throws NoSuchObjectException, WorkspaceCommunicationException {
		//TODO should set workspace change date?
		final Map<ObjectIDResolvedWS, ResolvedMongoObjectID> ids =
				resolveObjectIDs(objectIDs, delete, true);
		final Map<ResolvedMongoWSID, List<Long>> toModify =
				new HashMap<ResolvedMongoWSID, List<Long>>();
		for (final ObjectIDResolvedWS o: objectIDs) {
			final ResolvedMongoWSID ws = query.convertResolvedWSID(
					o.getWorkspaceIdentifier());
			if (!toModify.containsKey(ws)) {
				toModify.put(ws, new ArrayList<Long>());
			}
			toModify.get(ws).add(ids.get(o).getId());
		}
		//Do this by workspace since per mongo docs nested $ors are crappy
		for (final ResolvedMongoWSID ws: toModify.keySet()) {
			setObjectsDeleted(ws, toModify.get(ws), delete);
		}
	}
	
	private static final String M_DELOBJ_WTH = String.format(
			"{$set: {%s: #, %s: #}}", Fields.OBJ_DEL, Fields.OBJ_MODDATE);
	
	private void setObjectsDeleted(final ResolvedMongoWSID ws,
			final List<Long> objectIDs, final boolean delete)
			throws WorkspaceCommunicationException {
		final String query;
		if (objectIDs.isEmpty()) {
			query = String.format(
					"{%s: %s, %s: %s}", Fields.OBJ_WS_ID, ws.getID(),
					Fields.OBJ_DEL, !delete);
		} else {
			query = String.format(
					"{%s: %s, %s: {$in: [%s]}, %s: %s}",
					Fields.OBJ_WS_ID, ws.getID(), Fields.OBJ_ID,
					StringUtils.join(objectIDs, ", "), Fields.OBJ_DEL, !delete);
		}
		try {
			wsjongo.getCollection(COL_WORKSPACE_OBJS).update(query).multi()
					.with(M_DELOBJ_WTH, delete, new Date());
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
	}
	
	private static final String M_DELWS_UPD = String.format("{%s: #}",
						Fields.WS_ID);
	private static final String M_DELWS_WTH = String.format(
			"{$set: {%s: #, %s: #}}", Fields.WS_DEL, Fields.WS_MODDATE);
	
	public void setWorkspaceDeleted(final ResolvedWorkspaceID rwsi,
			final boolean delete) throws WorkspaceCommunicationException {
		//there's a possibility of a race condition here if a workspace is
		//deleted and undeleted or vice versa in a very short amount of time,
		//but that seems so unlikely it's not worth the code
		final ResolvedMongoWSID mrwsi = query.convertResolvedWSID(rwsi);
		try {
			wsjongo.getCollection(COL_WORKSPACES).update(
							M_DELWS_UPD, mrwsi.getID())
					.with(M_DELWS_WTH, delete, new Date());
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		setObjectsDeleted(mrwsi, new ArrayList<Long>(), delete);
	}
	
	public static class TestMongoInternals {
		
		//screwy tests for methods that can't be tested in a black box manner
	
		private static MongoWorkspaceDB testdb;
		
		@BeforeClass
		public static void setUpClass() throws Exception {
			WorkspaceTestCommon.destroyAndSetupDB(1, "gridFS", "foo");
			String host = WorkspaceTestCommon.getHost();
			String db1 = WorkspaceTestCommon.getDB1();
			String mUser = WorkspaceTestCommon.getMongoUser();
			String mPwd = WorkspaceTestCommon.getMongoPwd();
			final String kidlpath = new Util().getKIDLpath();
			if (mUser == null || mUser == "") {
				testdb = new MongoWorkspaceDB(host, db1, kidlpath, "foo", null);
			} else {
				testdb = new MongoWorkspaceDB(host, db1, kidlpath, "foo", null,
						mUser, mPwd);
			}
		}
		
		@Test
		public void createObject() throws Exception {
			testdb.createWorkspace(new WorkspaceUser("u"), "ws", false, null);
			Map<String, Object> data = new HashMap<String, Object>();
			Map<String, String> meta = new HashMap<String, String>();
			Map<String, Object> moredata = new HashMap<String, Object>();
			moredata.put("foo", "bar");
			data.put("fubar", moredata);
			meta.put("metastuff", "meta");
			Provenance p = new Provenance(new WorkspaceUser("kbasetest2"));
			TypeDefId t = new TypeDefId(new TypeDefName("SomeModule", "AType"), 0, 1);
			AbsoluteTypeDefId at = new AbsoluteTypeDefId(new TypeDefName("SomeModule", "AType"), 0, 1);
			WorkspaceSaveObject wo = new WorkspaceSaveObject(
					new ObjectIDNoWSNoVer("testobj"),
					MAPPER.valueToTree(data), t, meta, p, false);
			List<ResolvedSaveObject> wco = new ArrayList<ResolvedSaveObject>();
			wco.add(wo.resolve(new DummyTypedObjectValidationReport(at, wo.getData()),
					new HashSet<Reference>(), new LinkedList<Reference>()));
			ObjectSavePackage pkg = new ObjectSavePackage();
			pkg.wo = wo.resolve(new DummyTypedObjectValidationReport(at, wo.getData()),
					new HashSet<Reference>(), new LinkedList<Reference>());
			ResolvedMongoWSID rwsi = new ResolvedMongoWSID("ws", 1);
			pkg.td = new TypeData(MAPPER.valueToTree(data), at, data);
			testdb.saveObjects(new WorkspaceUser("u"), rwsi, wco);
			IDName r = testdb.saveWorkspaceObject(rwsi, 3, "testobj");
			pkg.name = r.name;
			testdb.saveProvenance(Arrays.asList(pkg));
			ObjectInformation md = testdb.saveObjectVersion(new WorkspaceUser("u"), rwsi, r.id, pkg);
			assertThat("objectid is revised to existing object", md.getObjectId(), is(1L));
		}
	}
}
