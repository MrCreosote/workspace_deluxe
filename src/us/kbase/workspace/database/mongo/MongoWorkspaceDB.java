package us.kbase.workspace.database.mongo;

import static org.hamcrest.CoreMatchers.is;
import static org.junit.Assert.assertThat;
import static us.kbase.workspace.database.Util.checkSize;

import java.io.File;
import java.io.IOException;
import java.net.MalformedURLException;
import java.net.URL;
import java.net.UnknownHostException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Date;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.LinkedHashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;

import org.apache.commons.lang3.StringUtils;
import org.bson.types.ObjectId;
import org.jongo.FindAndModify;
import org.jongo.Jongo;
import org.jongo.MongoCollection;
import org.jongo.marshall.MarshallingException;
import org.junit.BeforeClass;
import org.junit.Test;
import org.junit.experimental.runners.Enclosed;
import org.junit.runner.RunWith;

import us.kbase.common.mongo.GetMongoDB;
import us.kbase.common.mongo.exceptions.InvalidHostException;
import us.kbase.common.mongo.exceptions.MongoAuthException;
import us.kbase.typedobj.core.AbsoluteTypeDefId;
import us.kbase.typedobj.core.MD5;
import us.kbase.typedobj.core.ObjectPaths;
import us.kbase.typedobj.core.TypeDefId;
import us.kbase.typedobj.core.TypeDefName;
import us.kbase.typedobj.core.TypedObjectExtractor;
import us.kbase.typedobj.core.TypedObjectValidator;
import us.kbase.typedobj.db.MongoTypeStorage;
import us.kbase.typedobj.db.TypeDefinitionDB;
import us.kbase.typedobj.exceptions.TypeStorageException;
import us.kbase.typedobj.exceptions.TypedObjectExtractionException;
import us.kbase.typedobj.tests.DummyTypedObjectValidationReport;
import us.kbase.workspace.database.AllUsers;
import us.kbase.workspace.database.CountingOutputStream;
import us.kbase.workspace.database.ObjectIDNoWSNoVer;
import us.kbase.workspace.database.ObjectIDResolvedWS;
import us.kbase.workspace.database.ObjectInformation;
import us.kbase.workspace.database.Permission;
import us.kbase.workspace.database.PermissionSet;
import us.kbase.workspace.database.Provenance;
import us.kbase.workspace.database.Reference;
import us.kbase.workspace.database.ResolvedWorkspaceID;
import us.kbase.workspace.database.TypeAndReference;
import us.kbase.workspace.database.User;
import us.kbase.workspace.database.WorkspaceDatabase;
import us.kbase.workspace.database.WorkspaceIdentifier;
import us.kbase.workspace.database.WorkspaceInformation;
import us.kbase.workspace.database.WorkspaceObjectData;
import us.kbase.workspace.database.WorkspaceUser;
import us.kbase.workspace.database.exceptions.CorruptWorkspaceDBException;
import us.kbase.workspace.database.exceptions.DBAuthorizationException;
import us.kbase.workspace.database.exceptions.NoSuchObjectException;
import us.kbase.workspace.database.exceptions.NoSuchWorkspaceException;
import us.kbase.workspace.database.exceptions.PreExistingWorkspaceException;
import us.kbase.workspace.database.exceptions.UninitializedWorkspaceDBException;
import us.kbase.workspace.database.exceptions.WorkspaceCommunicationException;
import us.kbase.workspace.database.exceptions.WorkspaceDBException;
import us.kbase.workspace.database.exceptions.WorkspaceDBInitializationException;
import us.kbase.workspace.database.mongo.exceptions.BlobStoreAuthorizationException;
import us.kbase.workspace.database.mongo.exceptions.BlobStoreCommunicationException;
import us.kbase.workspace.database.mongo.exceptions.BlobStoreException;
import us.kbase.workspace.database.mongo.exceptions.NoSuchBlobException;
import us.kbase.workspace.kbase.Util;
import us.kbase.workspace.lib.ResolvedSaveObject;
import us.kbase.workspace.lib.WorkspaceSaveObject;
import us.kbase.workspace.test.WorkspaceTestCommon;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.mongodb.BasicDBObject;
import com.mongodb.DB;
import com.mongodb.DBCursor;
import com.mongodb.DBObject;
import com.mongodb.MongoException;

@RunWith(Enclosed.class)
public class MongoWorkspaceDB implements WorkspaceDatabase {

	//TODO save set of objects with same provenance if they were generated by same fn
	
	private static final String COL_ADMINS = "admins";
	private static final String COL_SETTINGS = "settings";
	private static final String COL_WS_CNT = "workspaceCounter";
	private static final String COL_WORKSPACES = "workspaces";
	private static final String COL_WS_ACLS = "workspaceACLs";
	private static final String COL_WORKSPACE_OBJS = "workspaceObjects";
	private static final String COL_WORKSPACE_VERS = "workspaceObjVersions";
	private static final String COL_PROVENANCE = "provenance";
	private static final String COL_SHOCK_PREFIX = "shock_";
	private static final User ALL_USERS = new AllUsers('*');
	
	private static final long MAX_OBJECT_SIZE = 200005000;
	private static final long MAX_SUBDATA_SIZE = 15000000;
	private static final long MAX_PROV_SIZE = 1000000;
	private static final int MAX_WS_META_SIZE = 16000;
	
	private final DB wsmongo;
	private final Jongo wsjongo;
	private final BlobStore blob;
	private final QueryMethods query;
	private final FindAndModify updateWScounter;
	private final TypedObjectValidator typeValidator;
	
	private final Set<String> typeIndexEnsured = new HashSet<String>();
	
	//TODO constants class

	private static final Map<String, Map<List<String>, List<String>>> INDEXES;
	private static final String IDX_UNIQ = "unique";
	private static final String IDX_SPARSE = "sparse";
	static {
		//hardcoded indexes
		INDEXES = new HashMap<String, Map<List<String>, List<String>>>();
		
		//workspaces indexes
		Map<List<String>, List<String>> ws = new HashMap<List<String>, List<String>>();
		//find workspaces you own
		ws.put(Arrays.asList(Fields.WS_OWNER), Arrays.asList(""));
		//find workspaces by permanent id
		ws.put(Arrays.asList(Fields.WS_ID), Arrays.asList(IDX_UNIQ));
		//find workspaces by mutable name
		ws.put(Arrays.asList(Fields.WS_NAME), Arrays.asList(IDX_UNIQ));
		//find workspaces by metadata
		ws.put(Arrays.asList(Fields.WS_META), Arrays.asList(IDX_SPARSE));
		INDEXES.put(COL_WORKSPACES, ws);
		
		//workspace acl indexes
		Map<List<String>, List<String>> wsACL = new HashMap<List<String>, List<String>>();
		//get a user's permission for a workspace, index covers queries
		wsACL.put(Arrays.asList(Fields.ACL_WSID, Fields.ACL_USER, Fields.ACL_PERM), Arrays.asList(IDX_UNIQ));
		//find workspaces to which a user has some level of permission, index coves queries
		wsACL.put(Arrays.asList(Fields.ACL_USER, Fields.ACL_PERM, Fields.ACL_WSID), Arrays.asList(""));
		INDEXES.put(COL_WS_ACLS, wsACL);
		
		//workspace object indexes
		Map<List<String>, List<String>> wsObj = new HashMap<List<String>, List<String>>();
		//find objects by workspace id & name
		wsObj.put(Arrays.asList(Fields.OBJ_WS_ID, Fields.OBJ_NAME), Arrays.asList(IDX_UNIQ));
		//find object by workspace id & object id
		wsObj.put(Arrays.asList(Fields.OBJ_WS_ID, Fields.OBJ_ID), Arrays.asList(IDX_UNIQ));
		//find recently modified objects
		wsObj.put(Arrays.asList(Fields.OBJ_MODDATE), Arrays.asList(""));
		//find object to garbage collect
		wsObj.put(Arrays.asList(Fields.OBJ_DEL, Fields.OBJ_REFCOUNTS), Arrays.asList(""));
		INDEXES.put(COL_WORKSPACE_OBJS, wsObj);

		//workspace object version indexes
		Map<List<String>, List<String>> wsVer = new HashMap<List<String>, List<String>>();
		//find versions
		wsVer.put(Arrays.asList(Fields.VER_WS_ID, Fields.VER_ID,
				Fields.VER_VER), Arrays.asList(IDX_UNIQ));
		//find versions by data object
		wsVer.put(Arrays.asList(Fields.VER_TYPE, Fields.VER_CHKSUM), Arrays.asList(""));
		//determine whether a particular object is referenced by this object
		wsVer.put(Arrays.asList(Fields.VER_REF), Arrays.asList(IDX_SPARSE));
		//determine whether a particular object is included in this object's provenance
		wsVer.put(Arrays.asList(Fields.VER_PROVREF), Arrays.asList(IDX_SPARSE));
		//find objects that have the same provenance
		wsVer.put(Arrays.asList(Fields.VER_PROV), Arrays.asList(""));
		//find objects by saved date
		wsVer.put(Arrays.asList(Fields.VER_SAVEDATE), Arrays.asList(""));
		//find objects by metadata
		wsVer.put(Arrays.asList(Fields.VER_META), Arrays.asList(IDX_SPARSE));
		INDEXES.put(COL_WORKSPACE_VERS, wsVer);
		
		//no indexes needed for provenance since all lookups are by _id
		
		//admin indexes
		Map<List<String>, List<String>> admin = new HashMap<List<String>, List<String>>();
		//find admins by name
		admin.put(Arrays.asList(Fields.ADMIN_NAME), Arrays.asList(IDX_UNIQ));
		INDEXES.put(COL_ADMINS, admin);
	}

	public MongoWorkspaceDB(final String host, final String database,
			final String backendSecret)
			throws UnknownHostException, IOException, InvalidHostException,
			WorkspaceDBException, TypeStorageException {
		wsmongo = GetMongoDB.getDB(host, database);
		wsjongo = new Jongo(wsmongo);
		query = new QueryMethods(wsmongo, (AllUsers) ALL_USERS, COL_WORKSPACES,
				COL_WORKSPACE_OBJS, COL_WORKSPACE_VERS, COL_WS_ACLS);
		final Settings settings = getSettings();
		blob = setupBlobStore(settings, backendSecret);
		updateWScounter = buildCounterQuery(wsjongo);
		//TODO check a few random types and make sure they exist
		this.typeValidator = new TypedObjectValidator(
				new TypeDefinitionDB(
						new MongoTypeStorage(
								GetMongoDB.getDB(host, settings.getTypeDatabase()))));
		ensureIndexes();
		ensureTypeIndexes();
	}
	
	public MongoWorkspaceDB(final String host, final String database,
			final String backendSecret, final String user,
			final String password)
			throws UnknownHostException, WorkspaceDBException,
			TypeStorageException, IOException, InvalidHostException,
			MongoAuthException {
		wsmongo = GetMongoDB.getDB(host, database, user, password);
		wsjongo = new Jongo(wsmongo);
		query = new QueryMethods(wsmongo, (AllUsers) ALL_USERS, COL_WORKSPACES,
				COL_WORKSPACE_OBJS, COL_WORKSPACE_VERS, COL_WS_ACLS);
		final Settings settings = getSettings();
		blob = setupBlobStore(settings, backendSecret);
		updateWScounter = buildCounterQuery(wsjongo);
		this.typeValidator = new TypedObjectValidator(
				new TypeDefinitionDB(
						new MongoTypeStorage(
								GetMongoDB.getDB(host, settings.getTypeDatabase(),
										user, password))));
		ensureIndexes();
		ensureTypeIndexes();
	}
	
	//test constructor - runs both the java and perl type compilers
	public MongoWorkspaceDB(final String host, final String database,
			final String backendSecret, final String user,
			final String password, final String kidlpath,
			final String typeDBdir)
			throws UnknownHostException, IOException,
			WorkspaceDBException, InvalidHostException, MongoAuthException,
			TypeStorageException {
		wsmongo = GetMongoDB.getDB(host, database, user, password);
		wsjongo = new Jongo(wsmongo);
		query = new QueryMethods(wsmongo, (AllUsers) ALL_USERS, COL_WORKSPACES,
				COL_WORKSPACE_OBJS, COL_WORKSPACE_VERS, COL_WS_ACLS);
		final Settings settings = getSettings();
		blob = setupBlobStore(settings, backendSecret);
		updateWScounter = buildCounterQuery(wsjongo);
		this.typeValidator = new TypedObjectValidator(
				new TypeDefinitionDB(
						new MongoTypeStorage(
								GetMongoDB.getDB(host, settings.getTypeDatabase(),
										user, password)),
								typeDBdir == null ? null : new File(typeDBdir), kidlpath, "both"));
		ensureIndexes();
		ensureTypeIndexes();
	}
	
	private void ensureIndexes() {
		for (String col: INDEXES.keySet()) {
			wsmongo.getCollection(col).resetIndexCache();
			for (List<String> idx: INDEXES.get(col).keySet()) {
				final DBObject index = new BasicDBObject();
				final DBObject opts = new BasicDBObject();
				for (String field: idx) {
					index.put(field, 1);
				}
				for (String option: INDEXES.get(col).get(idx)) {
					if (!option.equals("")) {
						opts.put(option, 1);
					}
				}
				wsmongo.getCollection(col).ensureIndex(index, opts);
			}
		}
	}
	
	private void ensureTypeIndexes() {
		for (final String col: wsmongo.getCollectionNames()) {
			if (col.startsWith(TypeData.TYPE_COL_PREFIX)) {
				ensureTypeIndex(col);
			}
		}
	}
	
	private void ensureTypeIndex(final TypeDefId type) {
		ensureTypeIndex(TypeData.getTypeCollection(type));
	}

	private void ensureTypeIndex(String col) {
		if (typeIndexEnsured.contains(col)) {
			return;
		}
		final DBObject chksum = new BasicDBObject();
		chksum.put(Fields.TYPE_CHKSUM, 1);
		final DBObject unique = new BasicDBObject();
		unique.put(IDX_UNIQ, 1);
		wsmongo.getCollection(col).resetIndexCache();
		wsmongo.getCollection(col).ensureIndex(chksum, unique);
		typeIndexEnsured.add(col);
	}
	
	private static FindAndModify buildCounterQuery(final Jongo j) {
		return j.getCollection(COL_WS_CNT)
				.findAndModify(String.format("{%s: #}",
						Fields.CNT_ID), Fields.CNT_ID_VAL)
				.upsert().returnNew()
				.with("{$inc: {" + Fields.CNT_NUM + ": #}}", 1L)
				.projection(String.format("{%s: 1, %s: 0}",
						Fields.CNT_NUM, Fields.MONGO_ID));
	}

	private Settings getSettings() throws UninitializedWorkspaceDBException,
			CorruptWorkspaceDBException {
		if (!wsmongo.collectionExists(COL_SETTINGS)) {
			throw new UninitializedWorkspaceDBException(
					"No settings collection exists");
		}
		MongoCollection settings = wsjongo.getCollection(COL_SETTINGS);
		if (settings.count() != 1) {
			throw new CorruptWorkspaceDBException(
					"More than one settings document exists");
		}
		Settings wsSettings = null;
		try {
			wsSettings = settings.findOne().as(Settings.class);
		} catch (MarshallingException me) {
			Throwable ex = me.getCause();
			if (ex == null) {
				throw new CorruptWorkspaceDBException(
						"Unable to unmarshal settings document", me);
			}
			ex = ex.getCause();
			if (ex == null || !(ex instanceof CorruptWorkspaceDBException)) {
				throw new CorruptWorkspaceDBException(
						"Unable to unmarshal settings document", me);
			}
			throw (CorruptWorkspaceDBException) ex;
		}
		return wsSettings;
	}

	private BlobStore setupBlobStore(final Settings settings,
			final String backendSecret) throws CorruptWorkspaceDBException,
			DBAuthorizationException, WorkspaceDBInitializationException {
		if (settings.isGridFSBackend()) {
			return new GridFSBackend(wsmongo);
		}
		if (settings.isShockBackend()) {
			URL shockurl = null;
			try {
				shockurl = new URL(settings.getShockUrl());
			} catch (MalformedURLException mue) {
				throw new CorruptWorkspaceDBException(
						"Settings has bad shock url: "
								+ settings.getShockUrl(), mue);
			}
			BlobStore bs;
			try {
				bs = new ShockBackend(wsmongo, COL_SHOCK_PREFIX,
						shockurl, settings.getShockUser(), backendSecret);
			} catch (BlobStoreAuthorizationException e) {
				throw new DBAuthorizationException(
						"Not authorized to access the blob store database", e);
			} catch (BlobStoreException e) {
				throw new WorkspaceDBInitializationException(
						"The database could not be initialized: " +
						e.getLocalizedMessage(), e);
			}
			// TODO if shock, check a few random nodes to make sure they match
			// the internal representation, die otherwise
			return bs;
		}
		throw new RuntimeException("Something's real broke y'all");
	}
	
	@Override
	public TypedObjectValidator getTypeValidator() {
		return typeValidator;
	}

	@Override
	public String getBackendType() {
		return blob.getStoreType();
	}
	
	private static final String M_CREATE_WS_QRY = String.format("{%s: #}",
			Fields.WS_NAME);

	@Override
	public WorkspaceInformation createWorkspace(final WorkspaceUser user,
			final String wsname, final boolean globalRead,
			final String description, final Map<String, String> meta)
			throws PreExistingWorkspaceException,
			WorkspaceCommunicationException, CorruptWorkspaceDBException {
		checkSize(meta, "Metadata", MAX_WS_META_SIZE);
		//avoid incrementing the counter if we don't have to
		try {
			if (wsjongo.getCollection(COL_WORKSPACES).count(
					M_CREATE_WS_QRY, wsname) > 0) {
				throw new PreExistingWorkspaceException(String.format(
						"Workspace %s already exists", wsname));
			}
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		final long count; 
		try {
			count = ((Number) updateWScounter.as(DBObject.class)
					.get(Fields.CNT_NUM)).longValue();
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		final DBObject ws = new BasicDBObject();
		ws.put(Fields.WS_OWNER, user.getUser());
		ws.put(Fields.WS_ID, count);
		Date moddate = new Date();
		ws.put(Fields.WS_MODDATE, moddate);
		ws.put(Fields.WS_NAME, wsname);
		ws.put(Fields.WS_DEL, false);
		ws.put(Fields.WS_NUMOBJ, 0L);
		ws.put(Fields.WS_DESC, description);
		ws.put(Fields.WS_LOCKED, false);
		if (meta != null) {
			ws.put(Fields.WS_META, metaHashToMongoArray(meta));
		}
		try {
			wsmongo.getCollection(COL_WORKSPACES).insert(ws);
		} catch (MongoException.DuplicateKey mdk) {
			//this is almost impossible to test and will probably almost never happen
			throw new PreExistingWorkspaceException(String.format(
					"Workspace %s already exists", wsname));
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		setPermissionsForWorkspaceUsers(
				new ResolvedMongoWSID(wsname, count, false),
				Arrays.asList(user), Permission.OWNER, false);
		if (globalRead) {
			setPermissions(new ResolvedMongoWSID(wsname, count, false),
					Arrays.asList(ALL_USERS), Permission.READ, false);
		}
		return new MongoWSInfo(count, wsname, user, moddate, 0L,
				Permission.OWNER, globalRead, false);
	}
	
	private static final Set<String> FLDS_CLONE_WS =
			newHashSet(Fields.OBJ_ID, Fields.OBJ_NAME, Fields.OBJ_DEL,
					Fields.OBJ_HIDE);

	@Override
	public WorkspaceInformation cloneWorkspace(final WorkspaceUser user,
			final ResolvedWorkspaceID wsid, final String newname,
			final boolean globalRead, final String description)
			throws PreExistingWorkspaceException,
			WorkspaceCommunicationException, CorruptWorkspaceDBException {
		// looked at using copyObject to do this but was too messy
		final ResolvedMongoWSID fromWS = query.convertResolvedWSID(wsid);
		final WorkspaceInformation wsinfo =
				createWorkspace(user, newname, globalRead, description, null); //TODO deal with meta on cloning
		final ResolvedMongoWSID toWS = new ResolvedMongoWSID(wsinfo.getName(),
				wsinfo.getId(), wsinfo.isLocked());
		final DBObject q = new BasicDBObject(Fields.OBJ_WS_ID, fromWS.getID());
		final List<Map<String, Object>> wsobjects =
				query.queryCollection(COL_WORKSPACE_OBJS, q, FLDS_CLONE_WS);
		for (Map<String, Object> o: wsobjects) {
			if ((Boolean) o.get(Fields.OBJ_DEL)) {
				continue;
			}
			final long oldid = (Long) o.get(Fields.OBJ_ID);
			final String name = (String) o.get(Fields.OBJ_NAME);
			final boolean hidden = (Boolean) o.get(Fields.OBJ_HIDE);
			final ResolvedMongoObjectIDNoVer roi = 
					new ResolvedMongoObjectIDNoVer(fromWS, name, oldid);
			final List<Map<String, Object>> versions = query.queryAllVersions(
					new HashSet<ResolvedMongoObjectIDNoVer>(Arrays.asList(roi)),
					FLDS_VER_COPYOBJ).get(roi);
			for (final Map<String, Object> v: versions) {
				final int ver = (Integer) v.get(Fields.VER_VER);
				v.remove(Fields.MONGO_ID);
				v.put(Fields.VER_SAVEDBY, user.getUser());
				v.put(Fields.VER_RVRT, null);
				v.put(Fields.VER_COPIED, new MongoReference(
						fromWS.getID(), oldid, ver).toString());
			}
			updateReferenceCountsForVersions(versions);
			final long newid = incrementWorkspaceCounter(toWS, 1);
			final long objid = saveWorkspaceObject(toWS, newid, name).id;
			saveObjectVersions(user, toWS, objid, versions, hidden);
		}
		return getWorkspaceInformation(user, toWS);
	}
	
	private final static String M_LOCK_WS_QRY = String.format("{%s: #}",
			Fields.WS_ID);
	private final static String M_LOCK_WS_WTH = String.format("{$set: {%s: #}}",
			Fields.WS_LOCKED);
	
	@Override
	public WorkspaceInformation lockWorkspace(final WorkspaceUser user,
			final ResolvedWorkspaceID rwsi)
			throws WorkspaceCommunicationException,
			CorruptWorkspaceDBException {
		try {
			wsjongo.getCollection(COL_WORKSPACES)
				.update(M_LOCK_WS_QRY, rwsi.getID())
				.with(M_LOCK_WS_WTH, true);
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		return getWorkspaceInformation(user, rwsi);
	}
	
	private static final Set<String> FLDS_VER_COPYOBJ = newHashSet(
			Fields.VER_WS_ID, Fields.VER_ID, Fields.VER_VER,
			Fields.VER_TYPE, Fields.VER_CHKSUM, Fields.VER_SIZE,
			Fields.VER_PROV, Fields.VER_REF, Fields.VER_PROVREF,
			Fields.VER_COPIED, Fields.VER_META);
	
	@Override
	public ObjectInformation copyObject(final WorkspaceUser user,
			final ObjectIDResolvedWS from, final ObjectIDResolvedWS to)
			throws NoSuchObjectException, WorkspaceCommunicationException {
		return copyOrRevert(user, from, to, false);
	}
	
	@Override
	public ObjectInformation revertObject(final WorkspaceUser user,
			final ObjectIDResolvedWS oi)
			throws NoSuchObjectException, WorkspaceCommunicationException {
		return copyOrRevert(user, oi, null, true);
	}
		
	private ObjectInformation copyOrRevert(final WorkspaceUser user,
			final ObjectIDResolvedWS from, ObjectIDResolvedWS to,
			final boolean revert)
			throws NoSuchObjectException, WorkspaceCommunicationException {
		final ResolvedMongoObjectID rfrom = resolveObjectIDs(
				new HashSet<ObjectIDResolvedWS>(Arrays.asList(from))).get(from);
		final ResolvedMongoObjectID rto;
		if (revert) {
			to = from;
			rto = rfrom;
		} else {
			rto = resolveObjectIDs(
					new HashSet<ObjectIDResolvedWS>(Arrays.asList(to)),
					true, false).get(to); //don't except if there's no object
		}
		if (rto == null && to.getId() != null) {
			throw new NoSuchObjectException(String.format(
					"Copy destination is specified as object id %s in workspace %s which does not exist.",
					to.getId(), to.getWorkspaceIdentifier().getID()));
		}
		final List<Map<String, Object>> versions;
		if (rto == null && from.getVersion() == null) {
			final ResolvedMongoObjectIDNoVer o =
					new ResolvedMongoObjectIDNoVer(rfrom);
			versions = query.queryAllVersions(
					new HashSet<ResolvedMongoObjectIDNoVer>(Arrays.asList(o)),
					FLDS_VER_COPYOBJ).get(o);
		} else {
			versions = Arrays.asList(query.queryVersions(
					new HashSet<ResolvedMongoObjectID>(Arrays.asList(rfrom)),
					FLDS_VER_COPYOBJ).get(rfrom));
		}
		for (final Map<String, Object> v: versions) {
			int ver = (Integer) v.get(Fields.VER_VER);
			v.remove(Fields.MONGO_ID);
			v.put(Fields.VER_SAVEDBY, user.getUser());
			if (revert) {
				v.put(Fields.VER_RVRT, ver);
			} else {
				v.put(Fields.VER_RVRT, null);
				v.put(Fields.VER_COPIED, new MongoReference(
						rfrom.getWorkspaceIdentifier().getID(), rfrom.getId(),
						ver).toString());
			}
		}
		updateReferenceCountsForVersions(versions);
		final ResolvedMongoWSID toWS = query.convertResolvedWSID(
				to.getWorkspaceIdentifier());
		final long objid;
		if (rto == null) { //need to make a new object
			final long id = incrementWorkspaceCounter(toWS, 1);
			objid = saveWorkspaceObject(toWS, id, to.getName()).id;
		} else {
			objid = rto.getId();
		}
		saveObjectVersions(user, toWS, objid, versions, null);
		final Map<String, Object> info = versions.get(versions.size() - 1);
		return generateObjectInfo(toWS, objid, rto == null ? to.getName() :
				rto.getName(), info);
	}
	
	final private static String M_RENAME_WS_QRY = String.format(
			"{%s: #}", Fields.WS_ID);
	final private static String M_RENAME_WS_WTH = String.format(
			"{$set: {%s: #, %s: #}}", Fields.WS_NAME, Fields.WS_MODDATE);
	
	@Override
	public WorkspaceInformation renameWorkspace(final WorkspaceUser user,
			final ResolvedWorkspaceID rwsi, final String newname)
			throws WorkspaceCommunicationException,
			CorruptWorkspaceDBException {
		if (newname.equals(rwsi.getName())) {
			throw new IllegalArgumentException("Workspace is already named " +
					newname);
		}
		try {
			wsjongo.getCollection(COL_WORKSPACES)
					.update(M_RENAME_WS_QRY, rwsi.getID())
					.with(M_RENAME_WS_WTH, newname, new Date());
		} catch (MongoException.DuplicateKey medk) {
			throw new IllegalArgumentException(
					"There is already a workspace named " + newname);
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		return getWorkspaceInformation(user, rwsi);
	}
	
	final private static String M_RENAME_OBJ_QRY = String.format(
			"{%s: #, %s: #}", Fields.OBJ_WS_ID, Fields.OBJ_ID);
	final private static String M_RENAME_OBJ_WTH = String.format(
			"{$set: {%s: #, %s: #}}", Fields.OBJ_NAME, Fields.OBJ_MODDATE);
	
	@Override
	public ObjectInformation renameObject(final ObjectIDResolvedWS oi,
			final String newname)
			throws NoSuchObjectException, WorkspaceCommunicationException {
		Set<ObjectIDResolvedWS> input = new HashSet<ObjectIDResolvedWS>(
				Arrays.asList(oi));
		final ResolvedMongoObjectID roi = resolveObjectIDs(input).get(oi);
		if (newname.equals(roi.getName())) {
			throw new IllegalArgumentException("Object is already named " +
					newname);
		}
		try {
			wsjongo.getCollection(COL_WORKSPACE_OBJS)
					.update(M_RENAME_OBJ_QRY,
							roi.getWorkspaceIdentifier().getID(), roi.getId())
					.with(M_RENAME_OBJ_WTH, newname, new Date());
		} catch (MongoException.DuplicateKey medk) {
			throw new IllegalArgumentException(
					"There is already an object in the workspace named " +
							newname);
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		final ObjectIDResolvedWS oid = new ObjectIDResolvedWS(
				roi.getWorkspaceIdentifier(), roi.getId(), roi.getVersion());
		input = new HashSet<ObjectIDResolvedWS>(Arrays.asList(oid));
		return getObjectInformation(input, false).get(oid);
	}
	
	//projection lists
	private static final Set<String> FLDS_WS_DESC = newHashSet(Fields.WS_DESC);
	private static final Set<String> FLDS_WS_OWNER = newHashSet(Fields.WS_OWNER);
	
	//http://stackoverflow.com/questions/2041778/initialize-java-hashset-values-by-construction
	@SafeVarargs
	private static <T> Set<T> newHashSet(T... objs) {
		Set<T> set = new HashSet<T>();
		for (T o : objs) {
			set.add(o);
		}
		return set;
	}
	
	@Override
	public String getWorkspaceDescription(final ResolvedWorkspaceID rwsi) throws
			CorruptWorkspaceDBException, WorkspaceCommunicationException {
		return (String) query.queryWorkspace(query.convertResolvedWSID(rwsi),
				FLDS_WS_DESC).get(Fields.WS_DESC);
	}
	
	private final static String M_WS_ID_QRY = String.format("{%s: #}",
			Fields.WS_ID);
	private final static String M_WS_ID_WTH = String.format(
			"{$set: {%s: #, %s: #}}", Fields.WS_DESC, Fields.WS_MODDATE);
	
	@Override
	public void setWorkspaceDescription(final ResolvedWorkspaceID rwsi,
			final String description) throws WorkspaceCommunicationException {
		//TODO generalized method for setting fields?
		try {
			wsjongo.getCollection(COL_WORKSPACES)
				.update(M_WS_ID_QRY, rwsi.getID())
				.with(M_WS_ID_WTH, description, new Date());
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
	}
	
	@Override
	public ResolvedWorkspaceID resolveWorkspace(final WorkspaceIdentifier wsi)
			throws NoSuchWorkspaceException, WorkspaceCommunicationException {
		return resolveWorkspace(wsi, false);
	}
	
	@Override
	public ResolvedWorkspaceID resolveWorkspace(final WorkspaceIdentifier wsi,
			final boolean allowDeleted)
			throws NoSuchWorkspaceException, WorkspaceCommunicationException {
		Set<WorkspaceIdentifier> wsiset = new HashSet<WorkspaceIdentifier>();
		wsiset.add(wsi);
		return resolveWorkspaces(wsiset, allowDeleted).get(wsi);
				
	}
	
	@Override
	public Map<WorkspaceIdentifier, ResolvedWorkspaceID> resolveWorkspaces(
			final Set<WorkspaceIdentifier> wsis) throws NoSuchWorkspaceException,
			WorkspaceCommunicationException {
		return resolveWorkspaces(wsis, false);
	}
	
	private static final Set<String> FLDS_WS_ID_NAME_DEL =
			newHashSet(Fields.WS_ID, Fields.WS_NAME, Fields.WS_DEL,
					Fields.WS_LOCKED);
	
	@Override
	public Map<WorkspaceIdentifier, ResolvedWorkspaceID> resolveWorkspaces(
			final Set<WorkspaceIdentifier> wsis, final boolean allowDeleted)
			throws NoSuchWorkspaceException, WorkspaceCommunicationException {
		final Map<WorkspaceIdentifier, ResolvedWorkspaceID> ret =
				new HashMap<WorkspaceIdentifier, ResolvedWorkspaceID>();
		if (wsis.isEmpty()) {
			return ret;
		}
		final Map<WorkspaceIdentifier, Map<String, Object>> res =
				query.queryWorkspacesByIdentifier(wsis, FLDS_WS_ID_NAME_DEL);
		for (final WorkspaceIdentifier wsi: wsis) {
			if (!res.containsKey(wsi)) {
				throw new NoSuchWorkspaceException(String.format(
						"No workspace with %s exists", getWSErrorId(wsi)),
						wsi);
			}
			if (!allowDeleted && (Boolean) res.get(wsi).get(Fields.WS_DEL)) {
				throw new NoSuchWorkspaceException("Workspace " +
						wsi.getIdentifierString() + " is deleted", wsi);
			}
			ResolvedMongoWSID r = new ResolvedMongoWSID(
					(String) res.get(wsi).get(Fields.WS_NAME),
					(Long) res.get(wsi).get(Fields.WS_ID),
					(Boolean) res.get(wsi).get(Fields.WS_LOCKED));
			ret.put(wsi, r);
		}
		return ret;
	}
	
	@Override
	public PermissionSet getPermissions(
			final WorkspaceUser user, final Permission perm,
			final boolean excludeGlobalRead)
			throws WorkspaceCommunicationException,
			CorruptWorkspaceDBException {
		return getPermissions(user,
				new HashSet<ResolvedWorkspaceID>(), perm, excludeGlobalRead);
	}
	
	@Override
	public PermissionSet getPermissions(
			final WorkspaceUser user, final Set<ResolvedWorkspaceID> rwsis,
			final Permission perm, final boolean excludeGlobalRead)
			throws WorkspaceCommunicationException,
			CorruptWorkspaceDBException {
		if (perm == null || Permission.NONE.equals(perm)) {
			throw new IllegalArgumentException(
					"Permission cannot be null or NONE");
		}
		Set<ResolvedMongoWSID> rmwsis = query.convertResolvedWSID(rwsis);
		final Map<ResolvedMongoWSID, Map<User, Permission>> userperms;
		if (user != null) {
			userperms = query.queryPermissions(rmwsis, 
					new HashSet<User>(Arrays.asList(user)), perm);
		} else {
			userperms = new HashMap<ResolvedMongoWSID, Map<User,Permission>>();
		}
		final Set<User> allusers = new HashSet<User>(Arrays.asList(ALL_USERS));
		final Map<ResolvedMongoWSID, Map<User, Permission>> globalperms;
		if (excludeGlobalRead || perm.compareTo(Permission.WRITE) >= 0) {
			if (userperms.isEmpty()) {
				globalperms =
						new HashMap<ResolvedMongoWSID, Map<User,Permission>>();
			} else {
				globalperms = query.queryPermissions(userperms.keySet(),
						allusers);
			}
		} else {
			globalperms = query.queryPermissions(rmwsis, allusers,
					Permission.READ);
		}
		final MongoPermissionSet pset = new MongoPermissionSet(user, ALL_USERS);
		for (final ResolvedMongoWSID rwsi: userperms.keySet()) {
			Permission gl = globalperms.get(rwsi) == null ? Permission.NONE :
				globalperms.get(rwsi).get(ALL_USERS);
			gl = gl == null ? Permission.NONE : gl;
			Permission p = userperms.get(rwsi).get(user);
			p = p == null ? Permission.NONE : p;
			if (!p.equals(Permission.NONE) || !gl.equals(Permission.NONE)) {
				pset.setPermission(rwsi, p, gl);
			}
			globalperms.remove(rwsi);
		}
		for (final ResolvedMongoWSID rwsi: globalperms.keySet()) {
			final Permission gl = globalperms.get(rwsi).get(ALL_USERS);
			if (gl != null && !gl.equals(Permission.NONE)) {
				pset.setPermission(rwsi, Permission.NONE, gl);
			}
		}
		return pset;
	}
	
	private static String getWSErrorId(final WorkspaceIdentifier wsi) {
		if (wsi.getId() == null) {
			return "name " + wsi.getName();
		}
		return "id " + wsi.getId();
	}
	
	@Override
	public void setPermissions(final ResolvedWorkspaceID rwsi,
			final List<WorkspaceUser> users, final Permission perm) throws
			WorkspaceCommunicationException, CorruptWorkspaceDBException {
		setPermissionsForWorkspaceUsers(query.convertResolvedWSID(rwsi),
				users, perm, true);
	}
	
	@Override
	public void setGlobalPermission(final ResolvedWorkspaceID rwsi,
			final Permission perm)
			throws WorkspaceCommunicationException,
			CorruptWorkspaceDBException {
		setPermissions(query.convertResolvedWSID(rwsi),
				Arrays.asList(ALL_USERS), perm, false);
	}
	
	//wsid must exist as a workspace
	private void setPermissionsForWorkspaceUsers(final ResolvedMongoWSID wsid,
			final List<WorkspaceUser> users, final Permission perm, 
			final boolean checkowner) throws WorkspaceCommunicationException,
			CorruptWorkspaceDBException {
		List<User> u = new ArrayList<User>();
		for (User user: users) {
			u.add(user);
		}
		setPermissions(wsid, u, perm, checkowner);
		
	}
	
	private static final String M_PERMS_QRY = String.format("{%s: #, %s: #}",
			Fields.ACL_WSID, Fields.ACL_USER);
	private static final String M_PERMS_UPD = String.format("{$set: {%s: #}}",
			Fields.ACL_PERM);
	
	private void setPermissions(final ResolvedMongoWSID wsid, final List<User> users,
			final Permission perm, final boolean checkowner) throws
			WorkspaceCommunicationException, CorruptWorkspaceDBException {
		final WorkspaceUser owner;
		if (checkowner) {
			final Map<String, Object> ws =
					query.queryWorkspace(wsid, FLDS_WS_OWNER);
			if (ws == null) {
				throw new CorruptWorkspaceDBException(String.format(
						"Workspace %s was unexpectedly deleted from the database",
						wsid.getID()));
			}
			owner = new WorkspaceUser((String) ws.get(Fields.WS_OWNER));
		} else {
			owner = null;
		}
		for (User user: users) {
			if (owner != null && owner.getUser().equals(user.getUser())) {
				continue; // can't change owner permissions
			}
			try {
				if (perm.equals(Permission.NONE)) {
					wsjongo.getCollection(COL_WS_ACLS).remove(
							M_PERMS_QRY, wsid.getID(), user.getUser());
				} else {
					wsjongo.getCollection(COL_WS_ACLS).update(
							M_PERMS_QRY, wsid.getID(), user.getUser())
							.upsert().with(M_PERMS_UPD, perm.getPermission());
				}
			} catch (MongoException me) {
				throw new WorkspaceCommunicationException(
						"There was a problem communicating with the database", me);
			}
		}
	}
	
	@Override
	public Permission getPermission(final WorkspaceUser user,
			final ResolvedWorkspaceID wsi) throws 
			WorkspaceCommunicationException, CorruptWorkspaceDBException {
		return getPermissions(user, wsi).getPermission(wsi, true);
	}
	
	public PermissionSet getPermissions(final WorkspaceUser user,
			final ResolvedWorkspaceID rwsi) throws 
			WorkspaceCommunicationException, CorruptWorkspaceDBException {
		final Set<ResolvedWorkspaceID> wsis =
				new HashSet<ResolvedWorkspaceID>();
		wsis.add(rwsi);
		return getPermissions(user, wsis);
	}
	
	@Override
	public PermissionSet getPermissions(
			final WorkspaceUser user, final Set<ResolvedWorkspaceID> rwsis)
			throws WorkspaceCommunicationException, 
			CorruptWorkspaceDBException {
		return getPermissions(user, rwsis, Permission.READ, false);
	}
	
	@Override
	public Map<User, Permission> getAllPermissions(
			final ResolvedWorkspaceID rwsi) throws
			WorkspaceCommunicationException, CorruptWorkspaceDBException {
		return query.queryPermissions(query.convertResolvedWSID(rwsi));
	}

	private static final Set<String> FLDS_WS_NO_DESC = 
			newHashSet(Fields.WS_ID, Fields.WS_NAME, Fields.WS_OWNER,
					Fields.WS_MODDATE, Fields.WS_NUMOBJ, Fields.WS_DEL,
					Fields.WS_LOCKED);
	
	@Override
	public List<WorkspaceInformation> getWorkspaceInformation(
			final PermissionSet pset, final List<WorkspaceUser> owners,
			final boolean showDeleted, final boolean showOnlyDeleted)
			throws WorkspaceCommunicationException,
			CorruptWorkspaceDBException {
		if (!(pset instanceof MongoPermissionSet)) {
			throw new IllegalArgumentException(
					"Illegal implementation of PermissionSet: " +
					pset.getClass().getName());
		}
		final Map<Long, ResolvedMongoWSID> rwsis =
				new HashMap<Long, ResolvedMongoWSID>();
		for (final ResolvedWorkspaceID rwsi: pset.getWorkspaces()) {
			rwsis.put(rwsi.getID(), query.convertResolvedWSID(rwsi));
		}
		final DBObject q = new BasicDBObject(Fields.WS_ID,
				new BasicDBObject("$in", rwsis.keySet()));
		if (owners != null && !owners.isEmpty()) {
			q.put(Fields.WS_OWNER, new BasicDBObject("$in",
					convertWorkspaceUsers(owners)));
		}
		final List<Map<String, Object>> ws = query.queryCollection(
				COL_WORKSPACES, q, FLDS_WS_NO_DESC);
		
		final List<WorkspaceInformation> ret =
				new LinkedList<WorkspaceInformation>();
		for (final Map<String, Object> w: ws) {
			final ResolvedWorkspaceID rwsi =
					rwsis.get((Long) w.get(Fields.WS_ID));
			final boolean isDeleted = (Boolean) w.get(Fields.WS_DEL);
			if (showOnlyDeleted) {
				if (isDeleted &&
						pset.hasUserPermission(rwsi, Permission.OWNER)) {
					ret.add(generateWSInfo(rwsi, pset, w));
				}
			} else if (!isDeleted || (showDeleted &&
					pset.hasUserPermission(rwsi, Permission.OWNER))) {
				ret.add(generateWSInfo(rwsi, pset, w));
			}
		}
		return ret;
	}

	private List<String> convertWorkspaceUsers(final List<WorkspaceUser> owners) {
		final List<String> own = new ArrayList<String>();
		for (final WorkspaceUser wu: owners) {
			own.add(wu.getUser());
		}
		return own;
	}
	
	@Override
	public WorkspaceInformation getWorkspaceInformation(
			final WorkspaceUser user, final ResolvedWorkspaceID rwsi)
			throws WorkspaceCommunicationException,
			CorruptWorkspaceDBException {
		final ResolvedMongoWSID m = query.convertResolvedWSID(rwsi);
		final Map<String, Object> ws = query.queryWorkspace(m,
				FLDS_WS_NO_DESC);
		final PermissionSet perms = getPermissions(user, m);
		return generateWSInfo(rwsi, perms, ws);
	}

	private WorkspaceInformation generateWSInfo(final ResolvedWorkspaceID rwsi,
			final PermissionSet perms, final Map<String, Object> wsdata) {
		return new MongoWSInfo((Long) wsdata.get(Fields.WS_ID),
				(String) wsdata.get(Fields.WS_NAME),
				new WorkspaceUser((String) wsdata.get(Fields.WS_OWNER)),
				(Date) wsdata.get(Fields.WS_MODDATE),
				(Long) wsdata.get(Fields.WS_NUMOBJ),
				perms.getUserPermission(rwsi),
				perms.isWorldReadable(rwsi),
				(Boolean) wsdata.get(Fields.WS_LOCKED));
	}
	
	private Map<ObjectIDNoWSNoVer, ResolvedMongoObjectID> resolveObjectIDs(
			final ResolvedMongoWSID workspaceID,
			final Set<ObjectIDNoWSNoVer> objects) throws
			WorkspaceCommunicationException {
		
		final Map<ObjectIDNoWSNoVer, ObjectIDResolvedWS> queryobjs = 
				new HashMap<ObjectIDNoWSNoVer, ObjectIDResolvedWS>();
		for (final ObjectIDNoWSNoVer o: objects) {
			queryobjs.put(o, new ObjectIDResolvedWS(workspaceID, o));
		}
		final Map<ObjectIDResolvedWS, ResolvedMongoObjectID> res;
		try {
			res = resolveObjectIDs(
					new HashSet<ObjectIDResolvedWS>(queryobjs.values()),
					false, false);
		} catch (NoSuchObjectException nsoe) {
			throw new RuntimeException(
					"Threw a NoSuchObjectException when explicitly told not to");
		}
		final Map<ObjectIDNoWSNoVer, ResolvedMongoObjectID> ret = 
				new HashMap<ObjectIDNoWSNoVer, ResolvedMongoObjectID>();
		for (final ObjectIDNoWSNoVer o: objects) {
			if (res.containsKey(queryobjs.get(o))) {
				ret.put(o, res.get(queryobjs.get(o)));
			}
		}
		return ret;
	}
	
	// save object in preexisting object container
	private ObjectInformation saveObjectVersion(final WorkspaceUser user,
			final ResolvedMongoWSID wsid, final long objectid,
			final ObjectSavePackage pkg)
			throws WorkspaceCommunicationException {
		final Map<String, Object> version = new HashMap<String, Object>();
		version.put(Fields.VER_SAVEDBY, user.getUser());
		version.put(Fields.VER_CHKSUM, pkg.td.getChksum());
		version.put(Fields.VER_META, metaHashToMongoArray(
				pkg.wo.getUserMeta()));
		version.put(Fields.VER_REF, pkg.refs);
		version.put(Fields.VER_PROVREF, pkg.provrefs);
		version.put(Fields.VER_PROV, pkg.mprov.getMongoId());
		version.put(Fields.VER_TYPE, pkg.wo.getRep().getValidationTypeDefId()
				.getTypeString());
		version.put(Fields.VER_SIZE, pkg.td.getSize());
		version.put(Fields.VER_RVRT, null);
		version.put(Fields.VER_COPIED, null);
		saveObjectVersions(user, wsid, objectid, Arrays.asList(version),
				pkg.wo.isHidden());
		
		return new MongoObjectInfo(objectid, pkg.name,
				pkg.wo.getRep().getValidationTypeDefId().getTypeString(),
				(Date) version.get(Fields.VER_SAVEDATE),
				(Integer) version.get(Fields.VER_VER),
				user, wsid, pkg.td.getChksum(), pkg.td.getSize(),
				pkg.wo.getUserMeta() == null ? new HashMap<String, String>() :
						pkg.wo.getUserMeta());
	}

	private List<Map<String, String>> metaHashToMongoArray(
			final Map<String, String> usermeta) {
		final List<Map<String, String>> meta = 
				new ArrayList<Map<String, String>>();
		if (usermeta != null) {
			for (String key: usermeta.keySet()) {
				Map<String, String> m = new LinkedHashMap<String, String>(2);
				m.put(Fields.META_KEY, key);
				m.put(Fields.META_VALUE, usermeta.get(key));
				meta.add(m);
			}
		}
		return meta;
	}
	

	private static final String M_SAVEINS_QRY = String.format("{%s: #, %s: #}",
			Fields.OBJ_WS_ID, Fields.OBJ_ID);
	private static final String M_SAVEINS_PROJ = String.format("{%s: 1, %s: 0}",
			Fields.OBJ_VCNT, Fields.MONGO_ID);
	private static final String M_SAVEINS_WTH = String.format(
			"{$inc: {%s: #}, $set: {%s: false, %s: #, %s: null, %s: #}, $push: {%s: {$each: #}}}",
			Fields.OBJ_VCNT, Fields.OBJ_DEL, Fields.OBJ_MODDATE,
			Fields.OBJ_LATEST, Fields.OBJ_HIDE, Fields.OBJ_REFCOUNTS);
	private static final String M_SAVEINS_NO_HIDE_WTH = String.format(
			"{$inc: {%s: #}, $set: {%s: false, %s: #, %s: null}, $push: {%s: {$each: #}}}",
			Fields.OBJ_VCNT, Fields.OBJ_DEL, Fields.OBJ_MODDATE,
			Fields.OBJ_LATEST, Fields.OBJ_REFCOUNTS);
	
	private void saveObjectVersions(final WorkspaceUser user,
			final ResolvedMongoWSID wsid, final long objectid,
			final List<Map<String, Object>> versions, final Boolean hidden)
			throws WorkspaceCommunicationException {
		// collection objects might be batchable if saves are slow
		/* TODO deal with rare failure modes below as much as possible at some point. Not high prio since rare
		 * 1) save an object, crash w/ 0 versions. 2) increment versions, crash w/o saving
		 * check all places counter incremented (ws, obj, ver) to see if any other problems
		 * known issues in resolveObjects and listObjects
		 * can't necc count on the fact that vercount or latestVersion is accurate
		 * ignore listObjs for now, in resolveObjs mark vers with class and
		 * have queryVersions pull the right version if it's missing. Make a test for this.
		 * Have queryVersions revert to the newest version if the latest is missing, autorevert
		 * 
		 * None of the above addresses the object w/ 0 versions failure. Not sure what to do about that.
		 * 
		*/
		int ver;
		final List<Integer> zeros = new LinkedList<Integer>();
		for (int i = 0; i < versions.size(); i++) {
			zeros.add(0);
		}
		final Date saved = new Date();
		try {
			FindAndModify q = wsjongo.getCollection(COL_WORKSPACE_OBJS)
					.findAndModify(M_SAVEINS_QRY, wsid.getID(), objectid)
					.returnNew();
			if (hidden == null) {
				q = q.with(M_SAVEINS_NO_HIDE_WTH, versions.size(),
						saved, zeros);
			} else {
				q = q.with(M_SAVEINS_WTH, versions.size(), saved,
						hidden, zeros);
			}
			ver = (Integer) q
					.projection(M_SAVEINS_PROJ).as(DBObject.class)
					.get(Fields.OBJ_VCNT)
					- versions.size() + 1;
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		//TODO look into why saving array of maps via List.ToArray() /w Jongo makes Lazy?Objects return, which screw up everything
		final List<DBObject> dbo = new LinkedList<DBObject>();
		for (final Map<String, Object> v: versions) {
			v.put(Fields.VER_SAVEDATE, saved);
			v.put(Fields.VER_WS_ID, wsid.getID());
			v.put(Fields.VER_ID, objectid);
			v.put(Fields.VER_VER, ver++);
			final DBObject d = new BasicDBObject();
			for (final Entry<String, Object> e: v.entrySet()) {
				d.put(e.getKey(), e.getValue());
			}
			dbo.add(d);
		}

		try {
			wsmongo.getCollection(COL_WORKSPACE_VERS).insert(dbo);
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
	}
	
	//TODO make all projections not include _id unless specified
	
	private static final String M_UNIQ_NAME_QRY = String.format(
			"{%s: #, %s: {$regex: '^#(-\\\\d+)?$'}}", Fields.OBJ_WS_ID,
			Fields.OBJ_NAME);
	private static final String M_UNIQ_NAME_PROJ = String.format(
			"{%s: 1, %s: 0}", Fields.OBJ_NAME, Fields.MONGO_ID);
	
	private String generateUniqueNameForObject(final ResolvedWorkspaceID wsid,
			final long objectid) throws WorkspaceCommunicationException {
		final String prefix = "auto" + objectid;
		@SuppressWarnings("rawtypes")
		Iterable<Map> ids;
		try {
			ids = wsjongo.getCollection(COL_WORKSPACE_OBJS)
					.find(M_UNIQ_NAME_QRY, wsid.getID(), prefix)
					.projection(M_UNIQ_NAME_PROJ).as(Map.class);
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		boolean exact = false;
		final Set<Long> suffixes = new HashSet<Long>();
		for (@SuppressWarnings("rawtypes") Map m: ids) {
			
			final String[] id = ((String) m.get(Fields.OBJ_NAME)).split("-");
			if (id.length == 2) {
				try {
					suffixes.add(Long.parseLong(id[1]));
				} catch (NumberFormatException e) {
					// do nothing
				}
			} else if (id.length == 1) {
				try {
					exact = exact || prefix.equals(id[0]);
				} catch (NumberFormatException e) {
					// do nothing
				}
			}
		}
		if (!exact) {
			return prefix;
		}
		long counter = 1;
		while (suffixes.contains(counter)) {
			counter++;
		}
		return prefix + "-" + counter;
	}
	
	//save brand new object - create container
	//objectid *must not exist* in the workspace otherwise this method will recurse indefinitely
	//the workspace must exist
	private IDName saveWorkspaceObject(
			final ResolvedMongoWSID wsid, final long objectid,
			final String name)
			throws WorkspaceCommunicationException {
		String newName = name;
		if (name == null) {
			newName = generateUniqueNameForObject(wsid, objectid);
		}
		final DBObject dbo = new BasicDBObject();
		dbo.put(Fields.OBJ_WS_ID, wsid.getID());
		dbo.put(Fields.OBJ_ID, objectid);
		dbo.put(Fields.OBJ_VCNT, 0); //Integer
		dbo.put(Fields.OBJ_REFCOUNTS, new LinkedList<Integer>());
		dbo.put(Fields.OBJ_NAME, newName);
		dbo.put(Fields.OBJ_LATEST, null);
		dbo.put(Fields.OBJ_DEL, false);
		dbo.put(Fields.OBJ_HIDE, false);
		try {
			//maybe could speed things up with batch inserts but dealing with
			//errors would really suck
			//do this later if it becomes a bottleneck
			wsmongo.getCollection(COL_WORKSPACE_OBJS).insert(dbo);
		} catch (MongoException.DuplicateKey dk) {
			//ok, someone must've just this second added this name to an object
			//asshole
			//this should be a rare event
			//TODO is this a name or id clash? if the latter, something is broken
			if (name == null) {
				//not much chance of this happening again, let's just recurse
				//and make a new name again
				return saveWorkspaceObject(wsid, objectid, name);
			}
			final ObjectIDNoWSNoVer o = new ObjectIDNoWSNoVer(name);
			final Map<ObjectIDNoWSNoVer, ResolvedMongoObjectID> objID =
					resolveObjectIDs(wsid,
							new HashSet<ObjectIDNoWSNoVer>(Arrays.asList(o)));
			if (objID.isEmpty()) {
				//oh ffs, name deleted again, try again
				return saveWorkspaceObject(wsid, objectid, name);
			}
			//save version via the id associated with our name which already exists
			return new IDName(objID.get(o).getId(), objID.get(o).getName());
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		return new IDName(objectid, newName);
	}
	
	private class IDName {
		
		public long id;
		public String name;
		
		public IDName(long id, String name) {
			super();
			this.id = id;
			this.name = name;
		}

		@Override
		public String toString() {
			return "IDName [id=" + id + ", name=" + name + "]";
		}
	}
	
	private static class ObjectSavePackage {
		
		public ResolvedSaveObject wo;
		public String name;
		public TypeData td;
		public Set<String> refs;
		public List<String> provrefs;
		public MongoProvenance mprov;
		
		@Override
		public String toString() {
			return "ObjectSavePackage [wo=" + wo + ", name=" + name + ", td="
					+ td + ", mprov =" + mprov +  "]";
		}
	}
	
	private static final ObjectMapper MAPPER = new ObjectMapper();
	
	private static String getObjectErrorId(final ObjectIDNoWSNoVer oi,
			final int objcount) {
		String objErrId = "#" + objcount;
		objErrId += oi == null ? "" : ", " + oi.getIdentifierString();
		return objErrId;
	}
	
	//at this point the objects are expected to be validated and references rewritten
	private List<ObjectSavePackage> saveObjectsBuildPackages(
			final List<ResolvedSaveObject> objects) {
		//this method must maintain the order of the objects
		int objnum = 1;
		final List<ObjectSavePackage> ret = new LinkedList<ObjectSavePackage>();
		for (ResolvedSaveObject o: objects) {
			if (o.getRep().getValidationTypeDefId().getMd5() != null) {
				throw new RuntimeException("MD5 types are not accepted");
			}
			final ObjectSavePackage pkg = new ObjectSavePackage();
			pkg.refs = checkRefsAreMongo(o.getRefs());
			//cannot do by combining in one set since a non-MongoReference
			//could be overwritten by a MongoReference if they have the same
			//hash
			pkg.provrefs = checkRefsAreMongo(o.getProvRefs());
			pkg.wo = o;
			checkObjectLength(o.getProvenance(), MAX_PROV_SIZE,
					o.getObjectIdentifier(), objnum, "provenance");
			
			final Map<String, Object> subdata;
			try {
				@SuppressWarnings("unchecked")
				final Map<String, Object> subdata2 = (Map<String, Object>)
						MAPPER.treeToValue(
								o.getRep().extractSearchableWsSubset(),
								Map.class);
				subdata = subdata2;
			} catch (JsonProcessingException jpe) {
				throw new RuntimeException(
						"Should never get a JSON exception here", jpe);
			}
			
			escapeSubdata(subdata);
			checkObjectLength(subdata, MAX_SUBDATA_SIZE,
					o.getObjectIdentifier(), objnum, "subdata");
			//could save time by making type->data->TypeData map and reusing
			//already calced TDs, but hardly seems worth it - unlikely event
			pkg.td = new TypeData(o.getRep().getJsonInstance(),
					o.getRep().getValidationTypeDefId(), subdata);
			if (pkg.td.getSize() > MAX_OBJECT_SIZE) {
				throw new IllegalArgumentException(String.format(
						"Object %s data size %s exceeds limit of %s",
						getObjectErrorId(o.getObjectIdentifier(), objnum),
						pkg.td.getSize(), MAX_OBJECT_SIZE));
			}
			ret.add(pkg);
			objnum++;
		}
		return ret;
	}
	
	//is there some way to combine these with generics?
	private Set<String> checkRefsAreMongo(final Set<Reference> refs) {
		final Set<String> newrefs = new HashSet<String>();
		checkRefsAreMongoInternal(refs, newrefs);
		return newrefs;
	}
	
	//order must be maintained
	private List<String> checkRefsAreMongo(final List<Reference> refs) {
		final List<String> newrefs = new LinkedList<String>();
		checkRefsAreMongoInternal(refs, newrefs);
		return newrefs;
	}

	private void checkRefsAreMongoInternal(final Collection<Reference> refs,
			final Collection<String> newrefs) {
		for (final Reference r: refs) {
			if (!(r instanceof MongoReference)) {
				throw new RuntimeException(
						"Improper reference implementation: " +
						(r == null ? null : r.getClass()));
			}
			newrefs.add(r.toString());
		}
	}

	private void checkObjectLength(final Object o, final long max,
			final ObjectIDNoWSNoVer oi, final int objnum,
			final String objtype) {
		final CountingOutputStream cos = new CountingOutputStream();
		try {
			//writes in UTF8
			MAPPER.writeValue(cos, o);
		} catch (IOException ioe) {
			throw new RuntimeException("something's broken", ioe);
		} finally {
			try {
				cos.close();
			} catch (IOException ioe) {
				throw new RuntimeException("something's broken", ioe);
			}
		}
		if (cos.getSize() > max) {
			throw new IllegalArgumentException(String.format(
					"Object %s %s size %s exceeds limit of %s",
					getObjectErrorId(oi, objnum), objtype, cos.getSize(), max));
		}
	}
	
	private void escapeSubdata(final Map<String, Object> subdata) {
		escapeSubdataInternal(subdata);
	}

	//rewrite w/o recursion?
	private Object escapeSubdataInternal(final Object o) {
		if (o instanceof String || o instanceof Number ||
				o instanceof Boolean || o == null) {
			return o;
		} else if (o instanceof List) {
			@SuppressWarnings("unchecked")
			final List<Object> l = (List<Object>)o;
			for (Object lo: l) {
				escapeSubdataInternal(lo);
			}
			return o;
		} else if (o instanceof Map) {
			@SuppressWarnings("unchecked")
			final Map<String, Object> m = (Map<String, Object>)o;
			//save updated keys in separate map so we don't overwrite
			//keys before they're escaped
			final Map<String, Object> newm = new HashMap<String, Object>();
			final Iterator<Entry<String, Object>> iter = m.entrySet().iterator();
			while (iter.hasNext()) {
				final Entry<String, Object> e = iter.next();
				final String key = e.getKey();
				//need side effect
				final Object value = escapeSubdataInternal(e.getValue());
				final String newkey = mongoHTMLEscape(key);
				//works since mongoHTMLEscape returns same string object if no change
				if (key != newkey) {
					iter.remove();
					newm.put(newkey, value);
				}
			}
			m.putAll(newm);
			return o;
		} else {
			throw new RuntimeException("Unsupported class: " + o.getClass());
		}
	}
	
	private static final int CODEPOINT_PERC = new String("%").codePointAt(0);
	private static final int CODEPOINT_DLR = new String("$").codePointAt(0);
	private static final int CODEPOINT_PNT = new String(".").codePointAt(0);
	
	//might be faster just using std string replace() method
	private String mongoHTMLEscape(final String s) {
		final StringBuilder ret = new StringBuilder();
		boolean mod = false;
		for (int offset = 0; offset < s.length(); ) {
			final int codepoint = s.codePointAt(offset);
			if (codepoint == CODEPOINT_PERC) {
				ret.append("%25");
				mod = true;
			} else if (codepoint == CODEPOINT_DLR) {
				ret.append("%24");
				mod = true;
			} else if (codepoint == CODEPOINT_PNT) {
				ret.append("%2e");
				mod = true;
			} else {
				ret.appendCodePoint(codepoint);
			}
			offset += Character.charCount(codepoint);
		}
		if (mod) {
			return ret.toString();
		} else {
			return s;
		}
	}
	
	private static final String M_SAVE_QRY = String.format("{%s: #}",
					Fields.WS_ID);
	private static final String M_SAVE_WTH = String.format("{$inc: {%s: #}}",
					Fields.WS_NUMOBJ);
	private static final String M_SAVE_PROJ = String.format("{%s: 1, %s: 0}",
			Fields.WS_NUMOBJ, Fields.MONGO_ID);
			
	//at this point the objects are expected to be validated and references rewritten
	@Override
	public List<ObjectInformation> saveObjects(final WorkspaceUser user, 
			final ResolvedWorkspaceID rwsi,
			final List<ResolvedSaveObject> objects)
			throws WorkspaceCommunicationException,
			NoSuchObjectException {
		//TODO break this up
		//this method must maintain the order of the objects
		
		final ResolvedMongoWSID wsidmongo = query.convertResolvedWSID(rwsi);
		final List<ObjectSavePackage> packages = saveObjectsBuildPackages(
				objects);
		final Map<ObjectIDNoWSNoVer, List<ObjectSavePackage>> idToPkg =
				new HashMap<ObjectIDNoWSNoVer, List<ObjectSavePackage>>();
		int newobjects = 0;
		for (final ObjectSavePackage p: packages) {
			final ObjectIDNoWSNoVer o = p.wo.getObjectIdentifier();
			if (o != null) {
				if (idToPkg.get(o) == null) {
					idToPkg.put(o, new ArrayList<ObjectSavePackage>());
				}
				idToPkg.get(o).add(p);
			} else {
				newobjects++;
			}
		}
		final Map<ObjectIDNoWSNoVer, ResolvedMongoObjectID> objIDs =
				resolveObjectIDs(wsidmongo, idToPkg.keySet());
		for (ObjectIDNoWSNoVer o: idToPkg.keySet()) {
			if (!objIDs.containsKey(o)) {
				if (o.getId() != null) {
					throw new NoSuchObjectException(
							"There is no object with id " + o.getId());
				} else {
					for (ObjectSavePackage pkg: idToPkg.get(o)) {
						pkg.name = o.getName();
					}
					newobjects++;
				}
			} else {
				for (ObjectSavePackage pkg: idToPkg.get(o)) {
					pkg.name = objIDs.get(o).getName();
				}
			}
		}
		//at this point everything should be ready to save, only comm errors
		//can stop us now, the world is doomed
		saveData(wsidmongo, packages);
		saveProvenance(packages);
		updateReferenceCounts(packages);
		long newid = incrementWorkspaceCounter(wsidmongo, newobjects);
		/*  alternate impl: 1) make all save objects 2) increment all version
		 *  counters 3) batch save versions
		 *  This probably won't help much. Firstly, saving the same object
		 *  multiple times (e.g. save over the same object in the same
		 *  saveObjects call) is going to be a rare op - who wants to do that?
		 *  Hence batching up the version increments is probably not going to
		 *  help much.
		 *  Secondly, the write lock is on a per document basis, so batching
		 *  writes has no effect on write locking.
		 *  That means that the gain from batching writes is removal of the 
		 *  flight time to/from the server between each object. This may
		 *  be significant for many small objects, but is probably
		 *  insignificant for a few objects, or many large objects.
		 *  Summary: probably not worth the trouble and increase in code
		 *  complexity.
		 */
		final List<ObjectInformation> ret = new ArrayList<ObjectInformation>();
		final Map<String, Long> seenNames = new HashMap<String, Long>();
		for (final ObjectSavePackage p: packages) {
			final ObjectIDNoWSNoVer oi = p.wo.getObjectIdentifier();
			if (oi == null) { //no name given, need to generate one
				final IDName obj = saveWorkspaceObject(wsidmongo, newid++,
						null);
				p.name = obj.name;
				ret.add(saveObjectVersion(user, wsidmongo, obj.id, p));
			} else if (oi.getId() != null) { //confirmed ok id
				ret.add(saveObjectVersion(user, wsidmongo, oi.getId(), p));
			} else if (objIDs.get(oi) != null) {//given name translated to id
				ret.add(saveObjectVersion(user, wsidmongo, objIDs.get(oi).getId(), p));
			} else if (seenNames.containsKey(oi.getName())) {
				//we've already generated an id for this name
				ret.add(saveObjectVersion(user, wsidmongo, seenNames.get(oi.getName()), p));
			} else {//new name, need to generate new id
				final IDName obj = saveWorkspaceObject(wsidmongo, newid++,
						oi.getName());
				p.name = obj.name;
				seenNames.put(obj.name, obj.id);
				ret.add(saveObjectVersion(user, wsidmongo, obj.id, p));
			}
		}
		return ret;
	}

	//returns starting object number
	private long incrementWorkspaceCounter(final ResolvedMongoWSID wsidmongo,
			final int newobjects) throws WorkspaceCommunicationException {
		final long lastid;
		try {
			lastid = ((Number) wsjongo.getCollection(COL_WORKSPACES)
					.findAndModify(M_SAVE_QRY, wsidmongo.getID())
					.returnNew().with(M_SAVE_WTH, (long) newobjects)
					.projection(M_SAVE_PROJ)
					.as(DBObject.class).get(Fields.WS_NUMOBJ)).longValue();
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		long newid = lastid - newobjects + 1;
		return newid;
	}
	
	private void saveProvenance(final List<ObjectSavePackage> packages)
			throws WorkspaceCommunicationException {
		final List<MongoProvenance> prov = new LinkedList<MongoProvenance>();
		for (final ObjectSavePackage p: packages) {
			final MongoProvenance mp = new MongoProvenance(
					p.wo.getProvenance());
			prov.add(mp);
			p.mprov = mp;
		}
		try {
			wsjongo.getCollection(COL_PROVENANCE).insert((Object[])
					prov.toArray(new MongoProvenance[prov.size()]));
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
	}

	private class VerCount {
		final public int ver;
		final public int count;

		public VerCount (final int ver, final int count) {
			this.ver = ver;
			this.count = count;
		}
		
		@Override
		public String toString() {
			return "VerCount [ver=" + ver + ", count=" + count + "]";
		}

		@Override
		public int hashCode() {
			final int prime = 31;
			int result = 1;
			result = prime * result + getOuterType().hashCode();
			result = prime * result + count;
			result = prime * result + ver;
			return result;
		}
		
		@Override
		public boolean equals(Object obj) {
			if (this == obj) {
				return true;
			}
			if (obj == null) {
				return false;
			}
			if (!(obj instanceof VerCount)) {
				return false;
			}
			VerCount other = (VerCount) obj;
			if (!getOuterType().equals(other.getOuterType())) {
				return false;
			}
			if (count != other.count) {
				return false;
			}
			if (ver != other.ver) {
				return false;
			}
			return true;
		}

		private MongoWorkspaceDB getOuterType() {
			return MongoWorkspaceDB.this;
		}
	}
	
	private void updateReferenceCounts(final List<ObjectSavePackage> packages)
			throws WorkspaceCommunicationException {
		//TODO when garbage collection working much more testing of these methods
		final Map<Long, Map<Long, Map<Integer, Counter>>> refcounts = 
				countReferences(packages);
		/* since the version numbers are probably highly skewed towards 1 and
		 * the reference counts are also highly skewed towards 1 we can 
		 * probably minimize the number of updates by running one update
		 * per version/count combination
		 */
		updateReferenceCounts(refcounts);
	}
	
	private void updateReferenceCountsForVersions(
			final List<Map<String, Object>> versions)
			throws WorkspaceCommunicationException {
		//TODO when garbage collection working much more testing of these methods
		final Map<Long, Map<Long, Map<Integer, Counter>>> refcounts = 
				countReferencesForVersions(versions);
		/* since the version numbers are probably highly skewed towards 1 and
		 * the reference counts are also highly skewed towards 1 we can 
		 * probably minimize the number of updates by running one update
		 * per version/count combination
		 */
		updateReferenceCounts(refcounts);
	}

	private void updateReferenceCounts(
			final Map<Long, Map<Long, Map<Integer, Counter>>> refcounts)
			throws WorkspaceCommunicationException {
		final Map<VerCount, Map<Long, List<Long>>> queries = 
				new HashMap<VerCount, Map<Long,List<Long>>>();
		for (final Long ws: refcounts.keySet()) {
			for (final Long obj: refcounts.get(ws).keySet()) {
				for (final Integer ver: refcounts.get(ws).get(obj).keySet()) {
					final VerCount vc = new VerCount(ver,
							refcounts.get(ws).get(obj).get(ver).getValue());
					if (!queries.containsKey(vc)) {
						queries.put(vc, new HashMap<Long, List<Long>>());
					}
					if (!queries.get(vc).containsKey(ws)) {
						queries.get(vc).put(ws, new LinkedList<Long>());
					}
					queries.get(vc).get(ws).add(obj);
				}
			}
		}
		for (final VerCount vc: queries.keySet()) {
			updateReferenceCounts(vc, queries.get(vc));
		}
	}

	private void updateReferenceCounts(final VerCount vc,
			final Map<Long, List<Long>> wsToObjs)
			throws WorkspaceCommunicationException {
		final DBObject update = new BasicDBObject("$inc",
				new BasicDBObject(Fields.OBJ_REFCOUNTS + "." + (vc.ver - 1),
						vc.count));
		final List<DBObject> orquery = new LinkedList<DBObject>();
		for (final Long ws: wsToObjs.keySet()) {
			final DBObject query = new BasicDBObject(Fields.OBJ_WS_ID, ws);
			query.put(Fields.OBJ_ID, new BasicDBObject("$in",
					wsToObjs.get(ws)));
			orquery.add(query);
		}
		try {
			wsmongo.getCollection(COL_WORKSPACE_OBJS).update(
					new BasicDBObject("$or", orquery), update, false, true);
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
	}

	private Map<Long, Map<Long, Map<Integer, Counter>>> countReferences(
			final List<ObjectSavePackage> packages) {
		final Map<Long, Map<Long, Map<Integer, Counter>>> refcounts =
				new HashMap<Long, Map<Long,Map<Integer,Counter>>>();
		for (final ObjectSavePackage p: packages) {
			//these were checked to be MongoReferences in saveObjectBuildPackages
			final Set<Reference> refs = new HashSet<Reference>();
			refs.addAll(p.wo.getRefs());
			refs.addAll(p.wo.getProvRefs());
			countReferences(refcounts, refs);
		}
		return refcounts;
	}
	
	private Map<Long, Map<Long, Map<Integer, Counter>>> countReferencesForVersions(
			final List<Map<String, Object>> versions) {
		final Map<Long, Map<Long, Map<Integer, Counter>>> refcounts =
				new HashMap<Long, Map<Long,Map<Integer,Counter>>>();
		for (final Map<String, Object> p: versions) {
			//these were checked to be MongoReferences in saveObjectBuildPackages
			final Set<Reference> refs = new HashSet<Reference>();
			@SuppressWarnings("unchecked")
			final List<String> objrefs = (List<String>) p.get(Fields.VER_REF);
			@SuppressWarnings("unchecked")
			final List<String> provrefs = (List<String>) p.get(Fields.VER_PROVREF);
//			objrefs.addAll(provrefs); //DON'T DO THIS YOU MORON
			for (final String s: objrefs) {
				refs.add(new MongoReference(s));
			}
			for (final String s: provrefs) {
				refs.add(new MongoReference(s));
			}
			countReferences(refcounts, refs);
		}
		return refcounts;
	}

	private void countReferences(
			final Map<Long, Map<Long, Map<Integer, Counter>>> refcounts,
			final Set<Reference> refs) {
		for (final Reference r: refs) {
			if (!refcounts.containsKey(r.getWorkspaceID())) {
				refcounts.put(r.getWorkspaceID(),
						new HashMap<Long, Map<Integer, Counter>>());
			}
			if (!refcounts.get(r.getWorkspaceID())
					.containsKey(r.getObjectID())) {
				refcounts.get(r.getWorkspaceID()).put(r.getObjectID(),
						new HashMap<Integer, Counter>());
			}
			if (!refcounts.get(r.getWorkspaceID()).get(r.getObjectID())
					.containsKey(r.getVersion())) {
				refcounts.get(r.getWorkspaceID()).get(r.getObjectID())
					.put(r.getVersion(), new Counter());
			}
			refcounts.get(r.getWorkspaceID()).get(r.getObjectID())
				.get(r.getVersion()).increment();
		}
	}

	private void saveData(final ResolvedMongoWSID workspaceid,
			final List<ObjectSavePackage> data) throws
			WorkspaceCommunicationException {
		final Map<TypeDefId, List<ObjectSavePackage>> pkgByType =
				new HashMap<TypeDefId, List<ObjectSavePackage>>();
		for (final ObjectSavePackage p: data) {
			if (pkgByType.get(p.td.getType()) == null) {
				pkgByType.put(p.td.getType(), new ArrayList<ObjectSavePackage>());
			}
			pkgByType.get(p.td.getType()).add(p);
		}
		for (final TypeDefId type: pkgByType.keySet()) {
			ensureTypeIndex(type);
			final String col = TypeData.getTypeCollection(type);
			final Map<String, TypeData> chksum = new HashMap<String, TypeData>();
			for (ObjectSavePackage p: pkgByType.get(type)) {
				chksum.put(p.td.getChksum(), p.td);
			}
			final DBObject query = new BasicDBObject(Fields.TYPE_CHKSUM,
					new BasicDBObject("$in", new ArrayList<String>(
							chksum.keySet())));
			final DBObject proj = new BasicDBObject(Fields.TYPE_CHKSUM, 1);
			proj.put(Fields.MONGO_ID, 0);
			DBCursor res;
			try {
				res = wsmongo.getCollection(col).find(query, proj);
			} catch (MongoException me) {
				throw new WorkspaceCommunicationException(
						"There was a problem communicating with the database", me);
			}
			final Set<String> existChksum = new HashSet<String>();
			for (DBObject dbo: res) {
				existChksum.add((String)dbo.get(Fields.TYPE_CHKSUM));
			}
			
			final List<TypeData> newdata = new ArrayList<TypeData>();
			for (String md5: chksum.keySet()) {
				if (existChksum.contains(md5)) {
					continue;
				}
				newdata.add(chksum.get(md5));
				try {
					//this is kind of stupid, but no matter how you slice it you have
					//to calc md5s before you save the data
					blob.saveBlob(new MD5(md5), chksum.get(md5).getData());
				} catch (BlobStoreCommunicationException e) {
					throw new WorkspaceCommunicationException(
							e.getLocalizedMessage(), e);
				} catch (BlobStoreAuthorizationException e) {
					throw new WorkspaceCommunicationException(
							"Authorization error communicating with the backend storage system",
							e);
				}
			}
			try {
				wsjongo.getCollection(col).insert((Object[]) newdata.toArray(
						new TypeData[newdata.size()]));
			} catch (MongoException.DuplicateKey dk) {
				//At least one of the data objects was just inserted by another
				//thread, which is fine - do nothing
			} catch (MongoException me) {
				throw new WorkspaceCommunicationException(
						"There was a problem communicating with the database", me);
			}
		}
	}
	
	private static final Set<String> FLDS_VER_GET_OBJECT_SUBDATA = newHashSet(
			Fields.VER_VER, Fields.VER_TYPE, Fields.VER_CHKSUM);
	
	private static final String M_GETOBJSUB_QRY = String.format(
			"{%s: {$in: #}}", Fields.TYPE_CHKSUM);
	private static final String M_GETOBJSUB_PROJ = String.format(
			"{%s: 1, %s: 1, %s: 0}",
			Fields.TYPE_CHKSUM, Fields.TYPE_SUBDATA, Fields.MONGO_ID);
	
	public Map<ObjectIDResolvedWS, Map<String, Object>> getObjectSubData(
			final Set<ObjectIDResolvedWS> objectIDs)
			throws NoSuchObjectException, WorkspaceCommunicationException {
		//keep doing the next two lines over and over, should probably extract
		final Map<ObjectIDResolvedWS, ResolvedMongoObjectID> oids =
				resolveObjectIDs(objectIDs);
		final Map<ResolvedMongoObjectID, Map<String, Object>> vers = 
				query.queryVersions(
						new HashSet<ResolvedMongoObjectID>(oids.values()),
						FLDS_VER_GET_OBJECT_SUBDATA);
		final Map<TypeDefId, Map<String, Set<ObjectIDResolvedWS>>> toGet =
				new HashMap<TypeDefId, Map<String,Set<ObjectIDResolvedWS>>>();
		for (final ObjectIDResolvedWS oid: objectIDs) {
			final ResolvedMongoObjectID roi = oids.get(oid);
			if (!vers.containsKey(roi)) {
				throw new NoSuchObjectException(String.format(
						"No object with id %s (name %s) and version %s exists "
						+ "in workspace %s", roi.getId(), roi.getName(), 
						roi.getVersion(), 
						roi.getWorkspaceIdentifier().getID()), oid);
			}
			final Map<String, Object> v = vers.get(roi);
			final TypeDefId type = TypeDefId.fromTypeString(
					(String) v.get(Fields.VER_TYPE));
			final String md5 = (String) v.get(Fields.VER_CHKSUM);
			if (!toGet.containsKey(type)) {
				toGet.put(type, new HashMap<String, Set<ObjectIDResolvedWS>>());
			}
			if (!toGet.get(type).containsKey(md5)) {
				toGet.get(type).put(md5, new HashSet<ObjectIDResolvedWS>());
			}
			toGet.get(type).get(md5).add(oid);
		}
		final Map<ObjectIDResolvedWS, Map<String, Object>> ret =
				new HashMap<ObjectIDResolvedWS, Map<String,Object>>();
		for (final TypeDefId type: toGet.keySet()) {
			@SuppressWarnings("rawtypes")
			final Iterable<Map> subdata;
			try {
				subdata = wsjongo.getCollection(TypeData.getTypeCollection(type))
						.find(M_GETOBJSUB_QRY, toGet.get(type).keySet())
						.projection(M_GETOBJSUB_PROJ).as(Map.class);
			} catch (MongoException me) {
				throw new WorkspaceCommunicationException(
						"There was a problem communicating with the database", me);
			}
			for (@SuppressWarnings("rawtypes") final Map m: subdata) {
				final String md5 = (String) m.get(Fields.TYPE_CHKSUM);
				@SuppressWarnings("unchecked")
				final Map<String, Object> sd =
						(Map<String, Object>) m.get(Fields.TYPE_SUBDATA);
				for (final ObjectIDResolvedWS o: toGet.get(type).get(md5)) {
					ret.put(o, sd);
				}
			}
		}
		return ret;
	}
	
	private static final Set<String> FLDS_VER_GET_OBJECT = newHashSet(
			Fields.VER_VER, Fields.VER_META, Fields.VER_TYPE,
			Fields.VER_SAVEDATE, Fields.VER_SAVEDBY,
			Fields.VER_CHKSUM, Fields.VER_SIZE, Fields.VER_PROV,
			Fields.VER_PROVREF, Fields.VER_REF);
	
	@Override
	public Map<ObjectIDResolvedWS, WorkspaceObjectData> getObjects(
			final Set<ObjectIDResolvedWS> objectIDs) throws
			NoSuchObjectException, WorkspaceCommunicationException,
			CorruptWorkspaceDBException {
		final Map<ObjectIDResolvedWS, ObjectPaths> paths =
				new HashMap<ObjectIDResolvedWS, ObjectPaths>();
		for (final ObjectIDResolvedWS o: objectIDs) {
			paths.put(o, null);
		}
		try {
			return getObjects(paths);
		} catch (TypedObjectExtractionException toee) {
			throw new RuntimeException(
					"No extraction done, so something's very wrong here", toee);
		}
	}
	
	@Override
	public Map<ObjectIDResolvedWS, WorkspaceObjectData> getObjects(
			final Map<ObjectIDResolvedWS, ObjectPaths> objects) throws
			NoSuchObjectException, WorkspaceCommunicationException,
			CorruptWorkspaceDBException, TypedObjectExtractionException {
		final Map<ObjectIDResolvedWS, ResolvedMongoObjectID> oids =
				resolveObjectIDs(objects.keySet());
		final Map<ResolvedMongoObjectID, Map<String, Object>> vers = 
				query.queryVersions(
						new HashSet<ResolvedMongoObjectID>(oids.values()),
						FLDS_VER_GET_OBJECT);
		final Map<ObjectId, MongoProvenance> provs = getProvenance(vers);
		final Map<String, JsonNode> chksumToData = new HashMap<String, JsonNode>();
		final Map<ObjectIDResolvedWS, WorkspaceObjectData> ret =
				new HashMap<ObjectIDResolvedWS, WorkspaceObjectData>();
		for (ObjectIDResolvedWS o: objects.keySet()) {
			final ResolvedMongoObjectID roi = oids.get(o);
			if (!vers.containsKey(roi)) {
				throw new NoSuchObjectException(String.format(
						"No object with id %s (name %s) and version %s exists "
						+ "in workspace %s", roi.getId(), roi.getName(), 
						roi.getVersion(), 
						roi.getWorkspaceIdentifier().getID()), o);
			}
			final MongoProvenance prov = provs.get((ObjectId) vers.get(roi)
					.get(Fields.VER_PROV));
			@SuppressWarnings("unchecked")
			final List<String> refs =
					(List<String>) vers.get(roi).get(Fields.VER_REF);
			final MongoObjectInfo meta = generateObjectInfo(
					roi, vers.get(roi));
			if (chksumToData.containsKey(meta.getCheckSum())) {
				/* might be subsetting the same object the same way multiple
				 * times, but probably unlikely. If it becomes a problem
				 * memoize the subset
				 */
				ret.put(o, new WorkspaceObjectData(getDataSubSet(
						chksumToData.get(meta.getCheckSum()), objects.get(o)),
						meta, prov, refs));
			} else {
				final JsonNode data;
				try {
					data = blob.getBlob(new MD5(meta.getCheckSum()));
				} catch (BlobStoreCommunicationException e) {
					throw new WorkspaceCommunicationException(
							e.getLocalizedMessage(), e);
				} catch (BlobStoreAuthorizationException e) {
					throw new WorkspaceCommunicationException(
							"Authorization error communicating with the backend storage system",
							e);
				} catch (NoSuchBlobException e) {
					throw new CorruptWorkspaceDBException(String.format(
							"No data present for valid object %s.%s.%s",
							meta.getWorkspaceId(), meta.getObjectId(),
							meta.getVersion()), e);
				}
				chksumToData.put(meta.getCheckSum(), data);
				ret.put(o, new WorkspaceObjectData(getDataSubSet(
						data, objects.get(o)), meta, prov, refs));
			}
		}
		return ret;
	}
	
	private JsonNode getDataSubSet(final JsonNode data,
			final ObjectPaths paths)
			throws TypedObjectExtractionException {
		if (paths == null || paths.isEmpty()) {
			return data;
		}
		return TypedObjectExtractor.extract(paths, data);
	}

	private static final Set<String> FLDS_GETREFOBJ = newHashSet(
			Fields.VER_WS_ID, Fields.VER_ID, Fields.VER_VER,
			Fields.VER_VER, Fields.VER_TYPE, Fields.VER_META,
			Fields.VER_SAVEDATE, Fields.VER_SAVEDBY,
			Fields.VER_CHKSUM, Fields.VER_SIZE,
			Fields.VER_PROVREF, Fields.VER_REF);
	
	@Override
	public Map<ObjectIDResolvedWS, Set<ObjectInformation>>
			getReferencingObjects(final PermissionSet perms,
					final Set<ObjectIDResolvedWS> objs)
		throws NoSuchObjectException, WorkspaceCommunicationException {
		final List<Long> wsids = new LinkedList<Long>();
		for (final ResolvedWorkspaceID ws: perms.getWorkspaces()) {
			wsids.add(ws.getID());
		}
		final Map<ObjectIDResolvedWS, ResolvedMongoObjectID> resobjs =
				resolveObjectIDs(objs);
		verifyVersions(new HashSet<ResolvedMongoObjectID>(resobjs.values()));
		final Map<String, Set<ObjectIDResolvedWS>> ref2id =
				new HashMap<String, Set<ObjectIDResolvedWS>>();
		for (final ObjectIDResolvedWS oi: objs) {
			final ResolvedMongoObjectID r = resobjs.get(oi);
			final String ref = r.getReference().toString();
			if (!ref2id.containsKey(ref)) {
				ref2id.put(ref, new HashSet<ObjectIDResolvedWS>());
			}
			ref2id.get(ref).add(oi);
		}
		final DBObject q = new BasicDBObject(Fields.VER_WS_ID,
				new BasicDBObject("$in", wsids));
		q.put("$or", Arrays.asList(
				new BasicDBObject(Fields.VER_REF,
						new BasicDBObject("$in", ref2id.keySet())),
				new BasicDBObject(Fields.VER_PROVREF,
						new BasicDBObject("$in", ref2id.keySet()))));
		final List<Map<String, Object>> vers = query.queryCollection(
				COL_WORKSPACE_VERS, q, FLDS_GETREFOBJ);
		final Map<Map<String, Object>, ObjectInformation> voi =
				generateObjectInfo(perms, vers, true, false, false, true);
		final Map<ObjectIDResolvedWS, Set<ObjectInformation>> ret = 
				new HashMap<ObjectIDResolvedWS, Set<ObjectInformation>>();
		for (final ObjectIDResolvedWS o: objs) {
			ret.put(o, new HashSet<ObjectInformation>());
		}
		for (final Map<String, Object> ver: voi.keySet()) {
			@SuppressWarnings("unchecked")
			final List<String> refs = (List<String>) ver.get(Fields.VER_REF);
			@SuppressWarnings("unchecked")
			final List<String> provrefs = (List<String>) ver.get(
					Fields.VER_PROVREF);
			final Set<String> allrefs = new HashSet<String>();
			allrefs.addAll(refs);
			allrefs.addAll(provrefs);
			for (final String ref: allrefs) {
				if (ref2id.containsKey(ref)) {
					for (final ObjectIDResolvedWS oi: ref2id.get(ref)) {
						ret.get(oi).add(voi.get(ver));
					}
				}
			}
		}
		return ret;
	}
	
	private Map<ObjectId, MongoProvenance> getProvenance(
			final Map<ResolvedMongoObjectID, Map<String, Object>> vers)
			throws WorkspaceCommunicationException {
		final Map<ObjectId, Map<String, Object>> provIDs =
				new HashMap<ObjectId, Map<String,Object>>();
		for (final ResolvedMongoObjectID id: vers.keySet()) {
			provIDs.put((ObjectId) vers.get(id).get(Fields.VER_PROV),
					vers.get(id));
		}
		final Iterable<MongoProvenance> provs;
		try {
			provs = wsjongo.getCollection(COL_PROVENANCE)
					.find("{_id: {$in: #}}", provIDs.keySet())
					.as(MongoProvenance.class);
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		final Map<ObjectId, MongoProvenance> ret =
				new HashMap<ObjectId, MongoProvenance>();
		for (MongoProvenance p: provs) {
			@SuppressWarnings("unchecked")
			final List<String> resolvedRefs = (List<String>) provIDs
					.get(p.getMongoId()).get(Fields.VER_PROVREF);
			ret.put(p.getMongoId(), p);
			p.resolveReferences(resolvedRefs); //this is a gross hack. I'm rather proud of it actually
		}
		return ret;
	}
	
	private MongoObjectInfo generateObjectInfo(
			final ResolvedMongoObjectID roi, final Map<String, Object> ver) {
		return generateObjectInfo(roi.getWorkspaceIdentifier(), roi.getId(),
				roi.getName(), ver);
	}

	private MongoObjectInfo generateObjectInfo(
			final ResolvedMongoWSID rwsi, final long objid, final String name,
			final Map<String, Object> ver) {
		@SuppressWarnings("unchecked")
		final List<Map<String, String>> meta =
				(List<Map<String, String>>) ver.get(Fields.VER_META);
		return new MongoObjectInfo(
				objid,
				name,
				(String) ver.get(Fields.VER_TYPE),
				(Date) ver.get(Fields.VER_SAVEDATE),
				(Integer) ver.get(Fields.VER_VER),
				new WorkspaceUser((String) ver.get(Fields.VER_SAVEDBY)),
				rwsi,
				(String) ver.get(Fields.VER_CHKSUM),
				(Long) ver.get(Fields.VER_SIZE),
				meta == null ? null : metaMongoArrayToHash(meta));
	}
	
	private static final Set<String> FLDS_VER_TYPE = newHashSet(
			Fields.VER_TYPE, Fields.VER_VER);
	
	public Map<ObjectIDResolvedWS, TypeAndReference> getObjectType(
			final Set<ObjectIDResolvedWS> objectIDs) throws
			NoSuchObjectException, WorkspaceCommunicationException {
		//this method is a pattern - generalize somehow?
		final Map<ObjectIDResolvedWS, ResolvedMongoObjectID> oids =
				resolveObjectIDs(objectIDs);
		final Map<ResolvedMongoObjectID, Map<String, Object>> vers = 
				query.queryVersions(
						new HashSet<ResolvedMongoObjectID>(oids.values()),
						FLDS_VER_TYPE);
		final Map<ObjectIDResolvedWS, TypeAndReference> ret =
				new HashMap<ObjectIDResolvedWS, TypeAndReference>();
		for (ObjectIDResolvedWS o: objectIDs) {
			final ResolvedMongoObjectID roi = oids.get(o);
			if (!vers.containsKey(roi)) {
				throw new NoSuchObjectException(String.format(
						"No object with id %s (name %s) and version %s exists "
						+ "in workspace %s", roi.getId(), roi.getName(), 
						roi.getVersion(), 
						roi.getWorkspaceIdentifier().getID()), o);
			}
			ret.put(o, new TypeAndReference(
					AbsoluteTypeDefId.fromAbsoluteTypeString(
							(String) vers.get(roi).get(Fields.VER_TYPE)),
					new MongoReference(roi.getWorkspaceIdentifier().getID(),
							roi.getId(),
							(Integer) vers.get(roi).get(Fields.VER_VER))));
		}
		return ret;
	}
	
	private static final Set<String> FLDS_LIST_OBJ_VER = newHashSet(
			Fields.VER_VER, Fields.VER_TYPE, Fields.VER_SAVEDATE,
			Fields.VER_SAVEDBY, Fields.VER_VER, Fields.VER_CHKSUM,
			Fields.VER_SIZE, Fields.VER_ID, Fields.VER_WS_ID);
	
	private static final Set<String> FLDS_LIST_OBJ = newHashSet(
			Fields.OBJ_ID, Fields.OBJ_NAME, Fields.OBJ_DEL, Fields.OBJ_HIDE,
			Fields.OBJ_LATEST, Fields.OBJ_VCNT, Fields.OBJ_WS_ID);
	
	private static final String LATEST_VERSION = "latestVersion";

	@Override
	public List<ObjectInformation> getObjectInformation(
			final PermissionSet pset, final TypeDefId type,
			final List<WorkspaceUser> savedby, final Map<String, String> meta,
			final boolean showHidden, final boolean showDeleted,
			final boolean showOnlyDeleted, final boolean showAllVers,
			final boolean includeMetadata)
			throws WorkspaceCommunicationException {
		/* Could make this method more efficient by doing different queries
		 * based on the filters. If there's no filters except the workspace,
		 * for example, just grab all the objects for the workspaces,
		 * filtering out hidden and deleted in the query and pull the most
		 * recent versions for the remaining objects. For now, just go
		 * with a dumb general method and add smarter heuristics as needed.
		 */
		if (!(pset instanceof MongoPermissionSet)) {
			throw new IllegalArgumentException(
					"Illegal implementation of PermissionSet: " +
					pset.getClass().getName());
		}
		if (pset.isEmpty()) {
			return new LinkedList<ObjectInformation>();
		}
		final Set<Long> ids = new HashSet<Long>();
		for (final ResolvedWorkspaceID rwsi: pset.getWorkspaces()) {
			ids.add(rwsi.getID());
		}
		final DBObject verq = new BasicDBObject();
		verq.put(Fields.VER_WS_ID, new BasicDBObject("$in", ids));
		if (type != null) {
			verq.put(Fields.VER_TYPE,
					new BasicDBObject("$regex", "^" + type.getTypePrefix()));
		}
		if (savedby != null && !savedby.isEmpty()) {
			verq.put(Fields.VER_SAVEDBY,
					new BasicDBObject("$in", convertWorkspaceUsers(savedby)));
		}
		if (meta != null && !meta.isEmpty()) {
			final List<DBObject> andmetaq = new LinkedList<DBObject>();
			for (final Entry<String, String> e: meta.entrySet()) {
				final DBObject mentry = new BasicDBObject();
				mentry.put(Fields.META_KEY, e.getKey());
				mentry.put(Fields.META_VALUE, e.getValue());
				andmetaq.add(new BasicDBObject(Fields.VER_META, mentry));
			}
			verq.put("$and", andmetaq); //note more than one entry is untested
		}
		final Set<String> fields;
		if (includeMetadata) {
			fields = new HashSet<String>(FLDS_LIST_OBJ_VER);
			fields.add(Fields.VER_META);
		} else {
			fields = FLDS_LIST_OBJ_VER;
		}
		final List<Map<String, Object>> verobjs = query.queryCollection(
				COL_WORKSPACE_VERS, verq, fields);
		if (verobjs.isEmpty()) {
			return new LinkedList<ObjectInformation>();
		}
		return new LinkedList<ObjectInformation>(
				generateObjectInfo(pset, verobjs, showHidden, showDeleted,
				showOnlyDeleted, showAllVers).values());
	}

	private Map<Map<String, Object>, ObjectInformation> generateObjectInfo(
			final PermissionSet pset, final List<Map<String, Object>> verobjs,
			final boolean includeHidden, final boolean includeDeleted,
			final boolean onlyIncludeDeleted, final boolean includeAllVers)
			throws WorkspaceCommunicationException {
		final Map<Long, ResolvedWorkspaceID> ids =
				new HashMap<Long, ResolvedWorkspaceID>();
		for (final ResolvedWorkspaceID rwsi: pset.getWorkspaces()) {
			final ResolvedMongoWSID rm = query.convertResolvedWSID(rwsi);
			ids.put(rm.getID(), rm);
		}
		final Map<Long, Set<Long>> verdata = getObjectIDsFromVersions(verobjs);
		//TODO This $or query might be better as multiple individual queries, test
		final List<DBObject> orquery = new LinkedList<DBObject>();
		for (final Long wsid: verdata.keySet()) {
			final DBObject query = new BasicDBObject(Fields.VER_WS_ID, wsid);
			query.put(Fields.VER_ID, new BasicDBObject(
					"$in", verdata.get(wsid)));
			orquery.add(query);
		}
		final DBObject objq = new BasicDBObject("$or", orquery);
		//could include / exclude hidden and deleted objects here? Prob
		// not worth the effort
		final Map<Long, Map<Long, Map<String, Object>>> objdata =
				organizeObjData(query.queryCollection(
						COL_WORKSPACE_OBJS, objq, FLDS_LIST_OBJ));
		final Map<Map<String, Object>, ObjectInformation> ret =
				new HashMap<Map<String, Object>, ObjectInformation>();
		for (final Map<String, Object> vo: verobjs) {
			final long wsid = (Long) vo.get(Fields.VER_WS_ID);
			final long id = (Long) vo.get(Fields.VER_ID);
			final int ver = (Integer) vo.get(Fields.VER_VER);
			final Map<String, Object> obj = objdata.get(wsid).get(id);
			final int lastver = (Integer) obj.get(LATEST_VERSION);
			final ResolvedMongoWSID rwsi = (ResolvedMongoWSID) ids.get(wsid);
			boolean isDeleted = (Boolean) obj.get(Fields.OBJ_DEL);
			if (!includeAllVers && lastver != ver) {
				/* this is tricky. As is, if there's a failure between incrementing
				 * an object ver count and saving the object version no latest
				 * ver will be listed. On the other hand, if we just take
				 * the max ver we'd be adding incorrect latest vers when filters
				 * exclude the real max ver. To do this correctly we've have to
				 * get the max ver for all objects which is really expensive.
				 * Since the failure mode should be very rare and it fixable
				 * by simply reverting the object do nothing for now.
				 */
				continue;
			}
			if ((Boolean) obj.get(Fields.OBJ_HIDE) && !includeHidden) {
				continue;
			}
			if (onlyIncludeDeleted) {
				if (isDeleted && pset.hasPermission(rwsi, Permission.WRITE)) {
					ret.put(vo, generateObjectInfo(rwsi, id,
							(String) obj.get(Fields.OBJ_NAME), vo));
				}
				continue;
			}
			if (isDeleted && (!includeDeleted ||
					!pset.hasPermission(rwsi, Permission.WRITE))) {
				continue;
			}
			ret.put(vo, generateObjectInfo(rwsi, id,
					(String) obj.get(Fields.OBJ_NAME), vo));
		}
		return ret;
	}
	
	private static final Set<String> FLDS_VER_OBJ_HIST = newHashSet(
			Fields.VER_WS_ID, Fields.VER_ID, Fields.VER_VER,
			Fields.VER_TYPE, Fields.VER_CHKSUM, Fields.VER_SIZE,
			Fields.VER_META, Fields.VER_SAVEDATE, Fields.VER_SAVEDBY);
	
	@Override
	public List<ObjectInformation> getObjectHistory(
			final ObjectIDResolvedWS oi)
		throws NoSuchObjectException, WorkspaceCommunicationException {
		final ResolvedMongoObjectID roi = resolveObjectIDs(
				new HashSet<ObjectIDResolvedWS>(Arrays.asList(oi))).get(oi);
		final ResolvedMongoObjectIDNoVer o =
				new ResolvedMongoObjectIDNoVer(roi);
		final List<Map<String, Object>> versions = query.queryAllVersions(
				new HashSet<ResolvedMongoObjectIDNoVer>(Arrays.asList(o)),
				FLDS_VER_OBJ_HIST).get(o);
		final LinkedList<ObjectInformation> ret =
				new LinkedList<ObjectInformation>();
		for (final Map<String, Object> v: versions) {
			ret.add(generateObjectInfo(roi, v));
		}
		return ret;
	}
	
	private Map<Long, Map<Long, Map<String, Object>>> organizeObjData(
			final List<Map<String, Object>> objs) {
		final Map<Long, Map<Long, Map<String, Object>>> ret =
				new HashMap<Long, Map<Long,Map<String,Object>>>();
		for (final Map<String, Object> o: objs) {
			final long wsid = (Long) o.get(Fields.OBJ_WS_ID);
			final long objid = (Long) o.get(Fields.OBJ_ID);
			final int latestVersion;
			if ((Integer) o.get(Fields.OBJ_LATEST) == null) {
				latestVersion = (Integer) o.get(Fields.OBJ_VCNT);
			} else {
				//TODO check this works with GC
				latestVersion = (Integer) o.get(Fields.OBJ_LATEST);
			}
			o.put(LATEST_VERSION, latestVersion);
			if (!ret.containsKey(wsid)) {
				ret.put(wsid, new HashMap<Long, Map<String, Object>>());
			}
			ret.get(wsid).put(objid, o);
		}
		return ret;
	}

	private Map<Long, Set<Long>> getObjectIDsFromVersions(
			final List<Map<String, Object>> objs) {
		final Map<Long, Set<Long>> ret = new HashMap<Long, Set<Long>>();
		for (final Map<String, Object> o: objs) {
			final long wsid = (Long) o.get(Fields.VER_WS_ID);
			final long objid = (Long) o.get(Fields.VER_ID);
			if (!ret.containsKey(wsid)) {
				ret.put(wsid, new HashSet<Long>());
			}
			ret.get(wsid).add(objid);
		}
		return ret;
	}

	private static final Set<String> FLDS_VER_META = newHashSet(
			Fields.VER_VER, Fields.VER_TYPE,
			Fields.VER_SAVEDATE, Fields.VER_SAVEDBY,
			Fields.VER_CHKSUM, Fields.VER_SIZE);
	
	@Override
	public Map<ObjectIDResolvedWS, ObjectInformation> getObjectInformation(
			final Set<ObjectIDResolvedWS> objectIDs,
			final boolean includeMetadata) throws
			NoSuchObjectException, WorkspaceCommunicationException {
		final Map<ObjectIDResolvedWS, ResolvedMongoObjectID> oids =
				resolveObjectIDs(objectIDs);
		final Set<String> fields;
		if (includeMetadata) {
			fields = new HashSet<String>(FLDS_VER_META);
			fields.add(Fields.VER_META);
		} else {
			fields = FLDS_VER_META;
		}
		final Map<ResolvedMongoObjectID, Map<String, Object>> vers = 
				query.queryVersions(
						new HashSet<ResolvedMongoObjectID>(oids.values()),
						fields);
		final Map<ObjectIDResolvedWS, ObjectInformation> ret =
				new HashMap<ObjectIDResolvedWS, ObjectInformation>();
		for (ObjectIDResolvedWS o: objectIDs) {
			final ResolvedMongoObjectID roi = oids.get(o);
			if (!vers.containsKey(roi)) {
				throw new NoSuchObjectException(String.format(
						"No object with id %s (name %s) and version %s exists "
						+ "in workspace %s", roi.getId(), roi.getName(), 
						roi.getVersion(), 
						roi.getWorkspaceIdentifier().getID()), o);
			}
			ret.put(o, generateObjectInfo(roi, vers.get(roi)));
		}
		return ret;
	}
	
	private Map<String, String> metaMongoArrayToHash(
			final List<Map<String, String>> meta) {
		final Map<String, String> ret = new HashMap<String, String>();
		for (final Map<String, String> m: meta) {
			ret.put(m.get(Fields.META_KEY),
					m.get(Fields.META_VALUE));
		}
		return ret;
	}
	
	private static final Set<String> FLDS_RESOLVE_OBJS =
			newHashSet(Fields.OBJ_ID, Fields.OBJ_NAME, Fields.OBJ_DEL,
					Fields.OBJ_LATEST, Fields.OBJ_VCNT);
	
	private Map<ObjectIDResolvedWS, ResolvedMongoObjectID> resolveObjectIDs(
			final Set<ObjectIDResolvedWS> objectIDs)
			throws NoSuchObjectException, WorkspaceCommunicationException {
		return resolveObjectIDs(objectIDs, true, true);
	}
	
	private Map<ObjectIDResolvedWS, ResolvedMongoObjectID> resolveObjectIDs(
			final Set<ObjectIDResolvedWS> objectIDs,
			final boolean exceptIfDeleted, final boolean exceptIfMissing)
			throws NoSuchObjectException, WorkspaceCommunicationException {
		final Map<ObjectIDResolvedWS, ObjectIDResolvedWSNoVer> nover =
				new HashMap<ObjectIDResolvedWS, ObjectIDResolvedWSNoVer>();
		for (final ObjectIDResolvedWS o: objectIDs) {
			nover.put(o, new ObjectIDResolvedWSNoVer(o));
		}
		final Map<ObjectIDResolvedWSNoVer, Map<String, Object>> ids = 
				query.queryObjects(
						new HashSet<ObjectIDResolvedWSNoVer>(nover.values()),
						FLDS_RESOLVE_OBJS);
		final Map<ObjectIDResolvedWS, ResolvedMongoObjectID> ret =
				new HashMap<ObjectIDResolvedWS, ResolvedMongoObjectID>();
		for (final ObjectIDResolvedWS oid: nover.keySet()) {
			final ObjectIDResolvedWSNoVer o = nover.get(oid);
			if (!ids.containsKey(o)) {
				if (exceptIfMissing) {
					final String err = oid.getId() == null ? "name" : "id";
					throw new NoSuchObjectException(String.format(
							"No object with %s %s exists in workspace %s",
							err, oid.getIdentifierString(),
							oid.getWorkspaceIdentifier().getID()), oid);
				} else {
					continue;
				}
			}
			final String name = (String) ids.get(o).get(Fields.OBJ_NAME);
			final long id = (Long) ids.get(o).get(Fields.OBJ_ID);
			if (exceptIfDeleted && (Boolean) ids.get(o).get(Fields.OBJ_DEL)) {
				throw new NoSuchObjectException(String.format(
						"Object %s (name %s) in workspace %s has been deleted",
						id, name, oid.getWorkspaceIdentifier().getID()), oid);
			}
			final Integer latestVersion;
			if ((Integer) ids.get(o).get(Fields.OBJ_LATEST) == null) {
				latestVersion = (Integer) ids.get(o).get(Fields.OBJ_VCNT);
			} else {
				//TODO check this works with GC
				latestVersion = (Integer) ids.get(o).get(Fields.OBJ_LATEST);
			}
			if (oid.getVersion() == null ||
					oid.getVersion().equals(latestVersion)) {
				//TODO this could be wrong if the vercount was incremented without a ver save, should verify and then sort if needed
				ret.put(oid, new ResolvedMongoOIDWithObjLastVer(
						query.convertResolvedWSID(oid.getWorkspaceIdentifier()),
						name, id, latestVersion));
			} else {
				if (oid.getVersion().compareTo(latestVersion) > 0) {
					throw new NoSuchObjectException(String.format(
							"No object with id %s (name %s) and version %s" +
							" exists in workspace %s", id, name,
							oid.getVersion(), 
							oid.getWorkspaceIdentifier().getID()), oid);
				} else {
					ret.put(oid, new ResolvedMongoObjectID(
							query.convertResolvedWSID(
									oid.getWorkspaceIdentifier()),
									name, id, oid.getVersion().intValue()));
				}
			}
		}
		return ret;
	}
	
	private void verifyVersions(final Set<ResolvedMongoObjectID> objs)
			throws WorkspaceCommunicationException, NoSuchObjectException {
		final Map<ResolvedMongoObjectID, Map<String, Object>> vers =
				query.queryVersions(objs, new HashSet<String>()); //don't actually need the data
		for (final ResolvedMongoObjectID o: objs) {
			if (!vers.containsKey(o)) {
				throw new NoSuchObjectException(String.format(
						"No object with id %s (name %s) and version %s exists "
						+ "in workspace %s", o.getId(), o.getName(), 
						o.getVersion(), 
						o.getWorkspaceIdentifier().getID()));
			}
		}
	}

	@Override
	public void setObjectsHidden(final Set<ObjectIDResolvedWS> objectIDs,
			final boolean hide)
			throws NoSuchObjectException, WorkspaceCommunicationException {
		//TODO nearly identical to delete objects, generalize
		final Map<ObjectIDResolvedWS, ResolvedMongoObjectID> ids =
				resolveObjectIDs(objectIDs);
		final Map<ResolvedMongoWSID, List<Long>> toModify =
				new HashMap<ResolvedMongoWSID, List<Long>>();
		for (final ObjectIDResolvedWS o: objectIDs) {
			final ResolvedMongoWSID ws = query.convertResolvedWSID(
					o.getWorkspaceIdentifier());
			if (!toModify.containsKey(ws)) {
				toModify.put(ws, new ArrayList<Long>());
			}
			toModify.get(ws).add(ids.get(o).getId());
		}
		//Do this by workspace since per mongo docs nested $ors are crappy
		for (final ResolvedMongoWSID ws: toModify.keySet()) {
			setObjectsHidden(ws, toModify.get(ws), hide);
		}
	}
	
	private static final String M_HIDOBJ_WTH = String.format(
			"{$set: {%s: #}}", Fields.OBJ_HIDE);
	private static final String M_HIDOBJ_QRY = String.format(
			"{%s: #, %s: {$in: #}}", Fields.OBJ_WS_ID, Fields.OBJ_ID);
	
	private void setObjectsHidden(final ResolvedMongoWSID ws,
			final List<Long> objectIDs, final boolean hide)
			throws WorkspaceCommunicationException {
		//TODO make general set field method?
		if (objectIDs.isEmpty()) {
			throw new IllegalArgumentException("Object IDs cannot be empty");
		}
		try {
			wsjongo.getCollection(COL_WORKSPACE_OBJS)
					.update(M_HIDOBJ_QRY, ws.getID(), objectIDs).multi()
					.with(M_HIDOBJ_WTH, hide);
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
	}
	
	@Override
	public void setObjectsDeleted(final Set<ObjectIDResolvedWS> objectIDs,
			final boolean delete)
			throws NoSuchObjectException, WorkspaceCommunicationException {
		final Map<ObjectIDResolvedWS, ResolvedMongoObjectID> ids =
				resolveObjectIDs(objectIDs, delete, true);
		final Map<ResolvedMongoWSID, List<Long>> toModify =
				new HashMap<ResolvedMongoWSID, List<Long>>();
		for (final ObjectIDResolvedWS o: objectIDs) {
			final ResolvedMongoWSID ws = query.convertResolvedWSID(
					o.getWorkspaceIdentifier());
			if (!toModify.containsKey(ws)) {
				toModify.put(ws, new ArrayList<Long>());
			}
			toModify.get(ws).add(ids.get(o).getId());
		}
		//Do this by workspace since per mongo docs nested $ors are crappy
		for (final ResolvedMongoWSID ws: toModify.keySet()) {
			setObjectsDeleted(ws, toModify.get(ws), delete);
		}
	}
	
	private static final String M_DELOBJ_WTH = String.format(
			"{$set: {%s: #, %s: #}}", Fields.OBJ_DEL, Fields.OBJ_MODDATE);
	
	private void setObjectsDeleted(final ResolvedMongoWSID ws,
			final List<Long> objectIDs, final boolean delete)
			throws WorkspaceCommunicationException {
		final String query;
		if (objectIDs.isEmpty()) {
			query = String.format(
					"{%s: %s, %s: %s}", Fields.OBJ_WS_ID, ws.getID(),
					Fields.OBJ_DEL, !delete);
		} else {
			query = String.format(
					"{%s: %s, %s: {$in: [%s]}, %s: %s}",
					Fields.OBJ_WS_ID, ws.getID(), Fields.OBJ_ID,
					StringUtils.join(objectIDs, ", "), Fields.OBJ_DEL, !delete);
		}
		try {
			wsjongo.getCollection(COL_WORKSPACE_OBJS).update(query).multi()
					.with(M_DELOBJ_WTH, delete, new Date());
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
	}
	
	private static final String M_DELWS_UPD = String.format("{%s: #}",
						Fields.WS_ID);
	private static final String M_DELWS_WTH = String.format(
			"{$set: {%s: #, %s: #}}", Fields.WS_DEL, Fields.WS_MODDATE);
	
	public void setWorkspaceDeleted(final ResolvedWorkspaceID rwsi,
			final boolean delete) throws WorkspaceCommunicationException {
		//there's a possibility of a race condition here if a workspace is
		//deleted and undeleted or vice versa in a very short amount of time,
		//but that seems so unlikely it's not worth the code
		final ResolvedMongoWSID mrwsi = query.convertResolvedWSID(rwsi);
		try {
			wsjongo.getCollection(COL_WORKSPACES).update(
							M_DELWS_UPD, mrwsi.getID())
					.with(M_DELWS_WTH, delete, new Date());
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		setObjectsDeleted(mrwsi, new ArrayList<Long>(), delete);
	}
	

	private static final String M_ADMIN_QRY = String.format(
			"{%s: #}", Fields.ADMIN_NAME);
	
	@Override
	public boolean isAdmin(WorkspaceUser putativeAdmin)
			throws WorkspaceCommunicationException {
		try {
			return wsjongo.getCollection(COL_ADMINS).count(M_ADMIN_QRY,
					putativeAdmin.getUser()) > 0;
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
	}

	@Override
	public Set<WorkspaceUser> getAdmins()
			throws WorkspaceCommunicationException {
		final Set<WorkspaceUser> ret = new HashSet<WorkspaceUser>();
		final DBCursor cur;
		try {
			cur = wsmongo.getCollection(COL_ADMINS).find();
			for (final DBObject dbo: cur) {
				ret.add(new WorkspaceUser((String) dbo.get(Fields.ADMIN_NAME)));
			}
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
		return ret;
	}

	@Override
	public void removeAdmin(WorkspaceUser user)
			throws WorkspaceCommunicationException {
		try {
			wsjongo.getCollection(COL_ADMINS).remove(M_ADMIN_QRY,
					user.getUser());
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
	}

	@Override
	public void addAdmin(WorkspaceUser user)
			throws WorkspaceCommunicationException {
		try {
			wsjongo.getCollection(COL_ADMINS).update(M_ADMIN_QRY,
					user.getUser()).upsert().with(M_ADMIN_QRY, user.getUser());
		} catch (MongoException me) {
			throw new WorkspaceCommunicationException(
					"There was a problem communicating with the database", me);
		}
	}
	
	public static class TestMongoSuperInternals {
		
		//screwy tests for methods that can't be tested in a black box manner
	
		private static MongoWorkspaceDB testdb;
		
		@BeforeClass
		public static void setUpClass() throws Exception {
			WorkspaceTestCommon.destroyAndSetupDB(1, "gridFS", "foo");
			String host = WorkspaceTestCommon.getHost();
			String db1 = WorkspaceTestCommon.getDB1();
			String mUser = WorkspaceTestCommon.getMongoUser();
			String mPwd = WorkspaceTestCommon.getMongoPwd();
			final String kidlpath = new Util().getKIDLpath();
			if (mUser == null || mUser == "") {
				testdb = new MongoWorkspaceDB(host, db1, kidlpath, "foo", "foo",
						"foo", null);
			} else {
				testdb = new MongoWorkspaceDB(host, db1, kidlpath, mUser, mPwd,
						"foo", null);
			}
		}
		
		@Test
		public void createObject() throws Exception {
			testdb.createWorkspace(new WorkspaceUser("u"), "ws", false, null, null);
			Map<String, Object> data = new HashMap<String, Object>();
			Map<String, String> meta = new HashMap<String, String>();
			Map<String, Object> moredata = new HashMap<String, Object>();
			moredata.put("foo", "bar");
			data.put("fubar", moredata);
			meta.put("metastuff", "meta");
			Provenance p = new Provenance(new WorkspaceUser("kbasetest2"));
			TypeDefId t = new TypeDefId(new TypeDefName("SomeModule", "AType"), 0, 1);
			AbsoluteTypeDefId at = new AbsoluteTypeDefId(new TypeDefName("SomeModule", "AType"), 0, 1);
			WorkspaceSaveObject wo = new WorkspaceSaveObject(
					new ObjectIDNoWSNoVer("testobj"),
					MAPPER.valueToTree(data), t, meta, p, false);
			List<ResolvedSaveObject> wco = new ArrayList<ResolvedSaveObject>();
			wco.add(wo.resolve(new DummyTypedObjectValidationReport(at, wo.getData()),
					new HashSet<Reference>(), new LinkedList<Reference>()));
			ObjectSavePackage pkg = new ObjectSavePackage();
			pkg.wo = wo.resolve(new DummyTypedObjectValidationReport(at, wo.getData()),
					new HashSet<Reference>(), new LinkedList<Reference>());
			ResolvedMongoWSID rwsi = new ResolvedMongoWSID("ws", 1, false);
			pkg.td = new TypeData(MAPPER.valueToTree(data), at, data);
			testdb.saveObjects(new WorkspaceUser("u"), rwsi, wco);
			IDName r = testdb.saveWorkspaceObject(rwsi, 3, "testobj");
			pkg.name = r.name;
			testdb.saveProvenance(Arrays.asList(pkg));
			ObjectInformation md = testdb.saveObjectVersion(new WorkspaceUser("u"), rwsi, r.id, pkg);
			assertThat("objectid is revised to existing object", md.getObjectId(), is(1L));
		}
	}
}
